<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
    "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
<title>sched_prim.c</title>
<style type="text/css">
.enscript-comment { font-style: italic; color: rgb(178,34,34); }
.enscript-function-name { font-weight: bold; color: rgb(0,0,255); }
.enscript-variable-name { font-weight: bold; color: rgb(184,134,11); }
.enscript-keyword { font-weight: bold; color: rgb(160,32,240); }
.enscript-reference { font-weight: bold; color: rgb(95,158,160); }
.enscript-string { font-weight: bold; color: rgb(188,143,143); }
.enscript-builtin { font-weight: bold; color: rgb(218,112,214); }
.enscript-type { font-weight: bold; color: rgb(34,139,34); }
.enscript-highlight { text-decoration: underline; color: 0; }
</style>
</head>
<body id="top">
<h1 style="margin:8px;" id="f1">sched_prim.c&nbsp;&nbsp;&nbsp;<span style="font-weight: normal; font-size: 0.5em;">[<a href="?txt">plain text</a>]</span></h1>
<hr/>
<div></div>
<pre>
<span class="enscript-comment">/*
 * Copyright (c) 2000-2012 Apple Inc. All rights reserved.
 *
 * @APPLE_OSREFERENCE_LICENSE_HEADER_START@
 * 
 * This file contains Original Code and/or Modifications of Original Code
 * as defined in and that are subject to the Apple Public Source License
 * Version 2.0 (the 'License'). You may not use this file except in
 * compliance with the License. The rights granted to you under the License
 * may not be used to create, or enable the creation or redistribution of,
 * unlawful or unlicensed copies of an Apple operating system, or to
 * circumvent, violate, or enable the circumvention or violation of, any
 * terms of an Apple operating system software license agreement.
 * 
 * Please obtain a copy of the License at
 * <a href="http://www.opensource.apple.com/apsl/">http://www.opensource.apple.com/apsl/</a> and read it before using this file.
 * 
 * The Original Code and all software distributed under the License are
 * distributed on an 'AS IS' basis, WITHOUT WARRANTY OF ANY KIND, EITHER
 * EXPRESS OR IMPLIED, AND APPLE HEREBY DISCLAIMS ALL SUCH WARRANTIES,
 * INCLUDING WITHOUT LIMITATION, ANY WARRANTIES OF MERCHANTABILITY,
 * FITNESS FOR A PARTICULAR PURPOSE, QUIET ENJOYMENT OR NON-INFRINGEMENT.
 * Please see the License for the specific language governing rights and
 * limitations under the License.
 * 
 * @APPLE_OSREFERENCE_LICENSE_HEADER_END@
 */</span>
<span class="enscript-comment">/*
 * @OSF_FREE_COPYRIGHT@
 */</span>
<span class="enscript-comment">/* 
 * Mach Operating System
 * Copyright (c) 1991,1990,1989,1988,1987 Carnegie Mellon University
 * All Rights Reserved.
 * 
 * Permission to use, copy, modify and distribute this software and its
 * documentation is hereby granted, provided that both the copyright
 * notice and this permission notice appear in all copies of the
 * software, derivative works or modified versions, and any portions
 * thereof, and that both notices appear in supporting documentation.
 * 
 * CARNEGIE MELLON ALLOWS FREE USE OF THIS SOFTWARE IN ITS &quot;AS IS&quot;
 * CONDITION.  CARNEGIE MELLON DISCLAIMS ANY LIABILITY OF ANY KIND FOR
 * ANY DAMAGES WHATSOEVER RESULTING FROM THE USE OF THIS SOFTWARE.
 * 
 * Carnegie Mellon requests users of this software to return to
 * 
 *  Software Distribution Coordinator  or  <a href="mailto:Software.Distribution@CS.CMU.EDU">Software.Distribution@CS.CMU.EDU</a>
 *  School of Computer Science
 *  Carnegie Mellon University
 *  Pittsburgh PA 15213-3890
 * 
 * any improvements or extensions that they make and grant Carnegie Mellon
 * the rights to redistribute these changes.
 */</span>
<span class="enscript-comment">/*
 */</span>
<span class="enscript-comment">/*
 *	File:	sched_prim.c
 *	Author:	Avadis Tevanian, Jr.
 *	Date:	1986
 *
 *	Scheduling primitives
 *
 */</span>

#<span class="enscript-reference">include</span> <span class="enscript-string">&lt;debug.h&gt;</span>

#<span class="enscript-reference">include</span> <span class="enscript-string">&lt;mach/mach_types.h&gt;</span>
#<span class="enscript-reference">include</span> <span class="enscript-string">&lt;mach/machine.h&gt;</span>
#<span class="enscript-reference">include</span> <span class="enscript-string">&lt;mach/policy.h&gt;</span>
#<span class="enscript-reference">include</span> <span class="enscript-string">&lt;mach/sync_policy.h&gt;</span>
#<span class="enscript-reference">include</span> <span class="enscript-string">&lt;mach/thread_act.h&gt;</span>

#<span class="enscript-reference">include</span> <span class="enscript-string">&lt;machine/machine_routines.h&gt;</span>
#<span class="enscript-reference">include</span> <span class="enscript-string">&lt;machine/sched_param.h&gt;</span>
#<span class="enscript-reference">include</span> <span class="enscript-string">&lt;machine/machine_cpu.h&gt;</span>
#<span class="enscript-reference">include</span> <span class="enscript-string">&lt;machine/machlimits.h&gt;</span>

#<span class="enscript-reference">ifdef</span> <span class="enscript-variable-name">CONFIG_MACH_APPROXIMATE_TIME</span>
#<span class="enscript-reference">include</span> <span class="enscript-string">&lt;machine/commpage.h&gt;</span>
#<span class="enscript-reference">endif</span>

#<span class="enscript-reference">include</span> <span class="enscript-string">&lt;kern/kern_types.h&gt;</span>
#<span class="enscript-reference">include</span> <span class="enscript-string">&lt;kern/clock.h&gt;</span>
#<span class="enscript-reference">include</span> <span class="enscript-string">&lt;kern/counters.h&gt;</span>
#<span class="enscript-reference">include</span> <span class="enscript-string">&lt;kern/cpu_number.h&gt;</span>
#<span class="enscript-reference">include</span> <span class="enscript-string">&lt;kern/cpu_data.h&gt;</span>
#<span class="enscript-reference">include</span> <span class="enscript-string">&lt;kern/smp.h&gt;</span>
#<span class="enscript-reference">include</span> <span class="enscript-string">&lt;kern/debug.h&gt;</span>
#<span class="enscript-reference">include</span> <span class="enscript-string">&lt;kern/macro_help.h&gt;</span>
#<span class="enscript-reference">include</span> <span class="enscript-string">&lt;kern/machine.h&gt;</span>
#<span class="enscript-reference">include</span> <span class="enscript-string">&lt;kern/misc_protos.h&gt;</span>
#<span class="enscript-reference">include</span> <span class="enscript-string">&lt;kern/processor.h&gt;</span>
#<span class="enscript-reference">include</span> <span class="enscript-string">&lt;kern/queue.h&gt;</span>
#<span class="enscript-reference">include</span> <span class="enscript-string">&lt;kern/sched.h&gt;</span>
#<span class="enscript-reference">include</span> <span class="enscript-string">&lt;kern/sched_prim.h&gt;</span>
#<span class="enscript-reference">include</span> <span class="enscript-string">&lt;kern/sfi.h&gt;</span>
#<span class="enscript-reference">include</span> <span class="enscript-string">&lt;kern/syscall_subr.h&gt;</span>
#<span class="enscript-reference">include</span> <span class="enscript-string">&lt;kern/task.h&gt;</span>
#<span class="enscript-reference">include</span> <span class="enscript-string">&lt;kern/thread.h&gt;</span>
#<span class="enscript-reference">include</span> <span class="enscript-string">&lt;kern/ledger.h&gt;</span>
#<span class="enscript-reference">include</span> <span class="enscript-string">&lt;kern/timer_queue.h&gt;</span>
#<span class="enscript-reference">include</span> <span class="enscript-string">&lt;kern/waitq.h&gt;</span>

#<span class="enscript-reference">include</span> <span class="enscript-string">&lt;vm/pmap.h&gt;</span>
#<span class="enscript-reference">include</span> <span class="enscript-string">&lt;vm/vm_kern.h&gt;</span>
#<span class="enscript-reference">include</span> <span class="enscript-string">&lt;vm/vm_map.h&gt;</span>

#<span class="enscript-reference">include</span> <span class="enscript-string">&lt;mach/sdt.h&gt;</span>

#<span class="enscript-reference">include</span> <span class="enscript-string">&lt;sys/kdebug.h&gt;</span>

#<span class="enscript-reference">include</span> <span class="enscript-string">&lt;kern/pms.h&gt;</span>

#<span class="enscript-reference">if</span> <span class="enscript-reference">defined</span>(<span class="enscript-variable-name">CONFIG_TELEMETRY</span>) &amp;&amp; <span class="enscript-reference">defined</span>(<span class="enscript-variable-name">CONFIG_SCHED_TIMESHARE_CORE</span>)
#<span class="enscript-reference">include</span> <span class="enscript-string">&lt;kern/telemetry.h&gt;</span>
#<span class="enscript-reference">endif</span>

<span class="enscript-type">struct</span> rt_queue	rt_runq;

uintptr_t sched_thread_on_rt_queue = (uintptr_t)0xDEAFBEE0;

<span class="enscript-comment">/* Lock RT runq, must be done with interrupts disabled (under splsched()) */</span>
#<span class="enscript-reference">if</span> <span class="enscript-variable-name">__SMP__</span>
<span class="enscript-function-name">decl_simple_lock_data</span>(<span class="enscript-type">static</span>,rt_lock);
#<span class="enscript-reference">define</span> <span class="enscript-function-name">rt_lock_init</span>()		simple_lock_init(&amp;rt_lock, 0)
#<span class="enscript-reference">define</span> <span class="enscript-function-name">rt_lock_lock</span>()		simple_lock(&amp;rt_lock)
#<span class="enscript-reference">define</span> <span class="enscript-function-name">rt_lock_unlock</span>()	simple_unlock(&amp;rt_lock)
#<span class="enscript-reference">else</span>
#<span class="enscript-reference">define</span> <span class="enscript-function-name">rt_lock_init</span>()		do { } while(0)
#<span class="enscript-reference">define</span> <span class="enscript-function-name">rt_lock_lock</span>()		do { } while(0)
#<span class="enscript-reference">define</span> <span class="enscript-function-name">rt_lock_unlock</span>()	do { } while(0)
#<span class="enscript-reference">endif</span>

#<span class="enscript-reference">define</span>		<span class="enscript-variable-name">DEFAULT_PREEMPTION_RATE</span>		100		<span class="enscript-comment">/* (1/s) */</span>
<span class="enscript-type">int</span>			default_preemption_rate = DEFAULT_PREEMPTION_RATE;

#<span class="enscript-reference">define</span>		<span class="enscript-variable-name">DEFAULT_BG_PREEMPTION_RATE</span>	400		<span class="enscript-comment">/* (1/s) */</span>
<span class="enscript-type">int</span>			default_bg_preemption_rate = DEFAULT_BG_PREEMPTION_RATE;

#<span class="enscript-reference">define</span>		<span class="enscript-variable-name">MAX_UNSAFE_QUANTA</span>			800
<span class="enscript-type">int</span>			max_unsafe_quanta = MAX_UNSAFE_QUANTA;

#<span class="enscript-reference">define</span>		<span class="enscript-variable-name">MAX_POLL_QUANTA</span>				2
<span class="enscript-type">int</span>			max_poll_quanta = MAX_POLL_QUANTA;

#<span class="enscript-reference">define</span>		<span class="enscript-variable-name">SCHED_POLL_YIELD_SHIFT</span>		4		<span class="enscript-comment">/* 1/16 */</span>
<span class="enscript-type">int</span>			sched_poll_yield_shift = SCHED_POLL_YIELD_SHIFT;

uint64_t	max_poll_computation;

uint64_t	max_unsafe_computation;
uint64_t	sched_safe_duration;

#<span class="enscript-reference">if</span> <span class="enscript-reference">defined</span>(<span class="enscript-variable-name">CONFIG_SCHED_TIMESHARE_CORE</span>)

uint32_t	std_quantum;
uint32_t	min_std_quantum;
uint32_t	bg_quantum;

uint32_t	std_quantum_us;
uint32_t	bg_quantum_us;

#<span class="enscript-reference">endif</span> <span class="enscript-comment">/* CONFIG_SCHED_TIMESHARE_CORE */</span>

uint32_t	thread_depress_time;
uint32_t	default_timeshare_computation;
uint32_t	default_timeshare_constraint;

uint32_t	max_rt_quantum;
uint32_t	min_rt_quantum;

#<span class="enscript-reference">if</span> <span class="enscript-reference">defined</span>(<span class="enscript-variable-name">CONFIG_SCHED_TIMESHARE_CORE</span>)

<span class="enscript-type">unsigned</span>	sched_tick;
uint32_t	sched_tick_interval;
#<span class="enscript-reference">if</span> <span class="enscript-reference">defined</span>(<span class="enscript-variable-name">CONFIG_TELEMETRY</span>)
uint32_t	sched_telemetry_interval;
#<span class="enscript-reference">endif</span> <span class="enscript-comment">/* CONFIG_TELEMETRY */</span>

uint32_t	sched_pri_shift = INT8_MAX;
uint32_t	sched_background_pri_shift = INT8_MAX;
uint32_t	sched_combined_fgbg_pri_shift = INT8_MAX;
uint32_t	sched_fixed_shift;
uint32_t	sched_use_combined_fgbg_decay = 0;

uint32_t	sched_decay_usage_age_factor = 1; <span class="enscript-comment">/* accelerate 5/8^n usage aging */</span>

<span class="enscript-comment">/* Allow foreground to decay past default to resolve inversions */</span>
#<span class="enscript-reference">define</span> <span class="enscript-variable-name">DEFAULT_DECAY_BAND_LIMIT</span> ((BASEPRI_FOREGROUND - BASEPRI_DEFAULT) + 2)
<span class="enscript-type">int</span> 		sched_pri_decay_band_limit = DEFAULT_DECAY_BAND_LIMIT;

<span class="enscript-comment">/* Defaults for timer deadline profiling */</span>
#<span class="enscript-reference">define</span> <span class="enscript-variable-name">TIMER_DEADLINE_TRACKING_BIN_1_DEFAULT</span> 2000000 <span class="enscript-comment">/* Timers with deadlines &lt;=
							* 2ms */</span>
#<span class="enscript-reference">define</span> <span class="enscript-variable-name">TIMER_DEADLINE_TRACKING_BIN_2_DEFAULT</span> 5000000 <span class="enscript-comment">/* Timers with deadlines
							  &lt;= 5ms */</span>

uint64_t timer_deadline_tracking_bin_1;
uint64_t timer_deadline_tracking_bin_2;

thread_t sched_maintenance_thread;

#<span class="enscript-reference">endif</span> <span class="enscript-comment">/* CONFIG_SCHED_TIMESHARE_CORE */</span>

uint64_t	sched_one_second_interval;

uint32_t	sched_run_count, sched_share_count, sched_background_count;
uint32_t	sched_load_average, sched_mach_factor;

<span class="enscript-comment">/* Forwards */</span>

#<span class="enscript-reference">if</span> <span class="enscript-reference">defined</span>(<span class="enscript-variable-name">CONFIG_SCHED_TIMESHARE_CORE</span>)

<span class="enscript-type">static</span> <span class="enscript-type">void</span> <span class="enscript-function-name">load_shift_init</span>(<span class="enscript-type">void</span>);
<span class="enscript-type">static</span> <span class="enscript-type">void</span> <span class="enscript-function-name">preempt_pri_init</span>(<span class="enscript-type">void</span>);

#<span class="enscript-reference">endif</span> <span class="enscript-comment">/* CONFIG_SCHED_TIMESHARE_CORE */</span>

<span class="enscript-type">static</span> thread_t	thread_select(
					thread_t			thread,
					processor_t			processor,
					ast_t				reason);

#<span class="enscript-reference">if</span> <span class="enscript-variable-name">CONFIG_SCHED_IDLE_IN_PLACE</span>
<span class="enscript-type">static</span> thread_t	thread_select_idle(
					thread_t			thread,
					processor_t			processor);
#<span class="enscript-reference">endif</span>

thread_t	processor_idle(
					thread_t			thread,
					processor_t			processor);

ast_t
<span class="enscript-function-name">csw_check_locked</span>(	processor_t		processor,
					processor_set_t	pset,
					ast_t			check_reason);

<span class="enscript-type">static</span> <span class="enscript-type">void</span> <span class="enscript-function-name">processor_setrun</span>(
				 processor_t			processor,
				 thread_t			thread,
				 integer_t			options);

<span class="enscript-type">static</span> <span class="enscript-type">void</span>
<span class="enscript-function-name">sched_realtime_init</span>(<span class="enscript-type">void</span>);

<span class="enscript-type">static</span> <span class="enscript-type">void</span>
<span class="enscript-function-name">sched_realtime_timebase_init</span>(<span class="enscript-type">void</span>);

<span class="enscript-type">static</span> <span class="enscript-type">void</span>
<span class="enscript-function-name">sched_timer_deadline_tracking_init</span>(<span class="enscript-type">void</span>);

#<span class="enscript-reference">if</span>	<span class="enscript-variable-name">DEBUG</span>
<span class="enscript-type">extern</span> <span class="enscript-type">int</span> debug_task;
#<span class="enscript-reference">define</span> <span class="enscript-function-name">TLOG</span>(a, fmt, args...) if(debug_task &amp; a) kprintf(fmt, ## args)
#<span class="enscript-reference">else</span>
#<span class="enscript-reference">define</span> <span class="enscript-function-name">TLOG</span>(a, fmt, args...) do {} while (0)
#<span class="enscript-reference">endif</span>

<span class="enscript-type">static</span> processor_t
<span class="enscript-function-name">thread_bind_internal</span>(
	thread_t		thread,
	processor_t		processor);

<span class="enscript-type">static</span> <span class="enscript-type">void</span>
<span class="enscript-function-name">sched_vm_group_maintenance</span>(<span class="enscript-type">void</span>);

#<span class="enscript-reference">if</span> <span class="enscript-reference">defined</span>(<span class="enscript-variable-name">CONFIG_SCHED_TIMESHARE_CORE</span>)
int8_t		sched_load_shifts[NRQS];
<span class="enscript-type">int</span>		sched_preempt_pri[NRQBM];
#<span class="enscript-reference">endif</span> <span class="enscript-comment">/* CONFIG_SCHED_TIMESHARE_CORE */</span>

<span class="enscript-type">const</span> <span class="enscript-type">struct</span> sched_dispatch_table *sched_current_dispatch = NULL;

<span class="enscript-comment">/*
 * Statically allocate a buffer to hold the longest possible
 * scheduler description string, as currently implemented.
 * bsd/kern/kern_sysctl.c has a corresponding definition in bsd/
 * to export to userspace via sysctl(3). If either version
 * changes, update the other.
 *
 * Note that in addition to being an upper bound on the strings
 * in the kernel, it's also an exact parameter to PE_get_default(),
 * which interrogates the device tree on some platforms. That
 * API requires the caller know the exact size of the device tree
 * property, so we need both a legacy size (32) and the current size
 * (48) to deal with old and new device trees. The device tree property
 * is similarly padded to a fixed size so that the same kernel image
 * can run on multiple devices with different schedulers configured
 * in the device tree.
 */</span>
<span class="enscript-type">char</span> sched_string[SCHED_STRING_MAX_LENGTH];

uint32_t sched_debug_flags;

<span class="enscript-comment">/* Global flag which indicates whether Background Stepper Context is enabled */</span>
<span class="enscript-type">static</span> <span class="enscript-type">int</span> cpu_throttle_enabled = 1;

<span class="enscript-type">void</span>
<span class="enscript-function-name">sched_init</span>(<span class="enscript-type">void</span>)
{
	<span class="enscript-type">char</span> sched_arg[SCHED_STRING_MAX_LENGTH] = { <span class="enscript-string">'\0'</span> };

	<span class="enscript-comment">/* Check for runtime selection of the scheduler algorithm */</span>
	<span class="enscript-keyword">if</span> (!PE_parse_boot_argn(<span class="enscript-string">&quot;sched&quot;</span>, sched_arg, <span class="enscript-keyword">sizeof</span> (sched_arg))) {
		<span class="enscript-comment">/* If no boot-args override, look in device tree */</span>
		<span class="enscript-keyword">if</span> (!PE_get_default(<span class="enscript-string">&quot;kern.sched&quot;</span>, sched_arg,
							SCHED_STRING_MAX_LENGTH)) {
			sched_arg[0] = <span class="enscript-string">'\0'</span>;
		}
	}

	
	<span class="enscript-keyword">if</span> (!PE_parse_boot_argn(<span class="enscript-string">&quot;sched_pri_decay_limit&quot;</span>, &amp;sched_pri_decay_band_limit, <span class="enscript-keyword">sizeof</span>(sched_pri_decay_band_limit))) {
		<span class="enscript-comment">/* No boot-args, check in device tree */</span>
		<span class="enscript-keyword">if</span> (!PE_get_default(<span class="enscript-string">&quot;kern.sched_pri_decay_limit&quot;</span>,
							&amp;sched_pri_decay_band_limit,
							<span class="enscript-keyword">sizeof</span>(sched_pri_decay_band_limit))) {
			<span class="enscript-comment">/* Allow decay all the way to normal limits */</span>
			sched_pri_decay_band_limit = DEFAULT_DECAY_BAND_LIMIT;
		}
	}

	kprintf(<span class="enscript-string">&quot;Setting scheduler priority decay band limit %d\n&quot;</span>, sched_pri_decay_band_limit);

	<span class="enscript-keyword">if</span> (strlen(sched_arg) &gt; 0) {
		<span class="enscript-keyword">if</span> (0) {
			<span class="enscript-comment">/* Allow pattern below */</span>
#<span class="enscript-reference">if</span> <span class="enscript-reference">defined</span>(<span class="enscript-variable-name">CONFIG_SCHED_TRADITIONAL</span>)
		} <span class="enscript-keyword">else</span> <span class="enscript-keyword">if</span> (0 == strcmp(sched_arg, sched_traditional_dispatch.sched_name)) {
			sched_current_dispatch = &amp;sched_traditional_dispatch;
		} <span class="enscript-keyword">else</span> <span class="enscript-keyword">if</span> (0 == strcmp(sched_arg, sched_traditional_with_pset_runqueue_dispatch.sched_name)) {
			sched_current_dispatch = &amp;sched_traditional_with_pset_runqueue_dispatch;
#<span class="enscript-reference">endif</span>
#<span class="enscript-reference">if</span> <span class="enscript-reference">defined</span>(<span class="enscript-variable-name">CONFIG_SCHED_PROTO</span>)
		} <span class="enscript-keyword">else</span> <span class="enscript-keyword">if</span> (0 == strcmp(sched_arg, sched_proto_dispatch.sched_name)) {
			sched_current_dispatch = &amp;sched_proto_dispatch;
#<span class="enscript-reference">endif</span>
#<span class="enscript-reference">if</span> <span class="enscript-reference">defined</span>(<span class="enscript-variable-name">CONFIG_SCHED_GRRR</span>)
		} <span class="enscript-keyword">else</span> <span class="enscript-keyword">if</span> (0 == strcmp(sched_arg, sched_grrr_dispatch.sched_name)) {
			sched_current_dispatch = &amp;sched_grrr_dispatch;
#<span class="enscript-reference">endif</span>
#<span class="enscript-reference">if</span> <span class="enscript-reference">defined</span>(<span class="enscript-variable-name">CONFIG_SCHED_MULTIQ</span>)
		} <span class="enscript-keyword">else</span> <span class="enscript-keyword">if</span> (0 == strcmp(sched_arg, sched_multiq_dispatch.sched_name)) {
			sched_current_dispatch = &amp;sched_multiq_dispatch;
		} <span class="enscript-keyword">else</span> <span class="enscript-keyword">if</span> (0 == strcmp(sched_arg, sched_dualq_dispatch.sched_name)) {
			sched_current_dispatch = &amp;sched_dualq_dispatch;
#<span class="enscript-reference">endif</span>
		} <span class="enscript-keyword">else</span> {
#<span class="enscript-reference">if</span> <span class="enscript-reference">defined</span>(<span class="enscript-variable-name">CONFIG_SCHED_TRADITIONAL</span>)
			printf(<span class="enscript-string">&quot;Unrecognized scheduler algorithm: %s\n&quot;</span>, sched_arg);
			printf(<span class="enscript-string">&quot;Scheduler: Using instead: %s\n&quot;</span>, sched_traditional_with_pset_runqueue_dispatch.sched_name);
			sched_current_dispatch = &amp;sched_traditional_with_pset_runqueue_dispatch;
#<span class="enscript-reference">else</span>
			panic(<span class="enscript-string">&quot;Unrecognized scheduler algorithm: %s&quot;</span>, sched_arg);
#<span class="enscript-reference">endif</span>
		}
		kprintf(<span class="enscript-string">&quot;Scheduler: Runtime selection of %s\n&quot;</span>, SCHED(sched_name));
	} <span class="enscript-keyword">else</span> {
#<span class="enscript-reference">if</span>   <span class="enscript-reference">defined</span>(<span class="enscript-variable-name">CONFIG_SCHED_MULTIQ</span>)
		sched_current_dispatch = &amp;sched_multiq_dispatch;
#<span class="enscript-reference">elif</span> <span class="enscript-reference">defined</span>(<span class="enscript-variable-name">CONFIG_SCHED_TRADITIONAL</span>)
		sched_current_dispatch = &amp;sched_traditional_with_pset_runqueue_dispatch;
#<span class="enscript-reference">elif</span> <span class="enscript-reference">defined</span>(<span class="enscript-variable-name">CONFIG_SCHED_PROTO</span>)
		sched_current_dispatch = &amp;sched_proto_dispatch;
#<span class="enscript-reference">elif</span> <span class="enscript-reference">defined</span>(<span class="enscript-variable-name">CONFIG_SCHED_GRRR</span>)
		sched_current_dispatch = &amp;sched_grrr_dispatch;
#<span class="enscript-reference">else</span>
#<span class="enscript-reference">error</span> <span class="enscript-variable-name">No</span> <span class="enscript-variable-name">default</span> <span class="enscript-variable-name">scheduler</span> <span class="enscript-variable-name">implementation</span>
#<span class="enscript-reference">endif</span>
		kprintf(<span class="enscript-string">&quot;Scheduler: Default of %s\n&quot;</span>, SCHED(sched_name));
	}

	strlcpy(sched_string, SCHED(sched_name), <span class="enscript-keyword">sizeof</span>(sched_string));

	<span class="enscript-keyword">if</span> (PE_parse_boot_argn(<span class="enscript-string">&quot;sched_debug&quot;</span>, &amp;sched_debug_flags, <span class="enscript-keyword">sizeof</span>(sched_debug_flags))) {
		kprintf(<span class="enscript-string">&quot;Scheduler: Debug flags 0x%08x\n&quot;</span>, sched_debug_flags);
	}
	
	SCHED(init)();
	sched_realtime_init();
	ast_init();
	sched_timer_deadline_tracking_init();

	SCHED(pset_init)(&amp;pset0);
	SCHED(processor_init)(master_processor);
}

<span class="enscript-type">void</span>
<span class="enscript-function-name">sched_timebase_init</span>(<span class="enscript-type">void</span>)
{
	uint64_t	abstime;
	
	clock_interval_to_absolutetime_interval(1, NSEC_PER_SEC, &amp;abstime);
	sched_one_second_interval = abstime;
	
	SCHED(timebase_init)();
	sched_realtime_timebase_init();
}

#<span class="enscript-reference">if</span> <span class="enscript-reference">defined</span>(<span class="enscript-variable-name">CONFIG_SCHED_TIMESHARE_CORE</span>)

<span class="enscript-type">void</span>
<span class="enscript-function-name">sched_timeshare_init</span>(<span class="enscript-type">void</span>)
{
	<span class="enscript-comment">/*
	 * Calculate the timeslicing quantum
	 * in us.
	 */</span>
	<span class="enscript-keyword">if</span> (default_preemption_rate &lt; 1)
		default_preemption_rate = DEFAULT_PREEMPTION_RATE;
	std_quantum_us = (1000 * 1000) / default_preemption_rate;

	printf(<span class="enscript-string">&quot;standard timeslicing quantum is %d us\n&quot;</span>, std_quantum_us);

	<span class="enscript-keyword">if</span> (default_bg_preemption_rate &lt; 1)
		default_bg_preemption_rate = DEFAULT_BG_PREEMPTION_RATE;
	bg_quantum_us = (1000 * 1000) / default_bg_preemption_rate;

	printf(<span class="enscript-string">&quot;standard background quantum is %d us\n&quot;</span>, bg_quantum_us);

	load_shift_init();
	preempt_pri_init();
	sched_tick = 0;
}

<span class="enscript-type">void</span>
<span class="enscript-function-name">sched_timeshare_timebase_init</span>(<span class="enscript-type">void</span>)
{
	uint64_t	abstime;
	uint32_t	shift;

	<span class="enscript-comment">/* standard timeslicing quantum */</span>
	clock_interval_to_absolutetime_interval(
							std_quantum_us, NSEC_PER_USEC, &amp;abstime);
	assert((abstime &gt;&gt; 32) == 0 &amp;&amp; (uint32_t)abstime != 0);
	std_quantum = (uint32_t)abstime;

	<span class="enscript-comment">/* smallest remaining quantum (250 us) */</span>
	clock_interval_to_absolutetime_interval(250, NSEC_PER_USEC, &amp;abstime);
	assert((abstime &gt;&gt; 32) == 0 &amp;&amp; (uint32_t)abstime != 0);
	min_std_quantum = (uint32_t)abstime;

	<span class="enscript-comment">/* quantum for background tasks */</span>
	clock_interval_to_absolutetime_interval(
							bg_quantum_us, NSEC_PER_USEC, &amp;abstime);
	assert((abstime &gt;&gt; 32) == 0 &amp;&amp; (uint32_t)abstime != 0);
	bg_quantum = (uint32_t)abstime;

	<span class="enscript-comment">/* scheduler tick interval */</span>
	clock_interval_to_absolutetime_interval(USEC_PER_SEC &gt;&gt; SCHED_TICK_SHIFT,
													NSEC_PER_USEC, &amp;abstime);
	assert((abstime &gt;&gt; 32) == 0 &amp;&amp; (uint32_t)abstime != 0);
	sched_tick_interval = (uint32_t)abstime;

	<span class="enscript-comment">/*
	 * Compute conversion factor from usage to
	 * timesharing priorities with 5/8 ** n aging.
	 */</span>
	abstime = (abstime * 5) / 3;
	<span class="enscript-keyword">for</span> (shift = 0; abstime &gt; BASEPRI_DEFAULT; ++shift)
		abstime &gt;&gt;= 1;
	sched_fixed_shift = shift;

	max_unsafe_computation = ((uint64_t)max_unsafe_quanta) * std_quantum;
	sched_safe_duration = 2 * ((uint64_t)max_unsafe_quanta) * std_quantum;
	
	max_poll_computation = ((uint64_t)max_poll_quanta) * std_quantum;
	thread_depress_time = 1 * std_quantum;
	default_timeshare_computation = std_quantum / 2;
	default_timeshare_constraint = std_quantum;

#<span class="enscript-reference">if</span> <span class="enscript-reference">defined</span>(<span class="enscript-variable-name">CONFIG_TELEMETRY</span>)
	<span class="enscript-comment">/* interval for high frequency telemetry */</span>
	clock_interval_to_absolutetime_interval(10, NSEC_PER_MSEC, &amp;abstime);
	assert((abstime &gt;&gt; 32) == 0 &amp;&amp; (uint32_t)abstime != 0);
	sched_telemetry_interval = (uint32_t)abstime;
#<span class="enscript-reference">endif</span>
}

#<span class="enscript-reference">endif</span> <span class="enscript-comment">/* CONFIG_SCHED_TIMESHARE_CORE */</span>

<span class="enscript-type">static</span> <span class="enscript-type">void</span>
<span class="enscript-function-name">sched_realtime_init</span>(<span class="enscript-type">void</span>)
{
	rt_lock_init();

	rt_runq.count = 0;
	queue_init(&amp;rt_runq.queue);
}

<span class="enscript-type">static</span> <span class="enscript-type">void</span>
<span class="enscript-function-name">sched_realtime_timebase_init</span>(<span class="enscript-type">void</span>)
{
	uint64_t abstime;

	<span class="enscript-comment">/* smallest rt computaton (50 us) */</span>
	clock_interval_to_absolutetime_interval(50, NSEC_PER_USEC, &amp;abstime);
	assert((abstime &gt;&gt; 32) == 0 &amp;&amp; (uint32_t)abstime != 0);
	min_rt_quantum = (uint32_t)abstime;

	<span class="enscript-comment">/* maximum rt computation (50 ms) */</span>
	clock_interval_to_absolutetime_interval(
		50, 1000*NSEC_PER_USEC, &amp;abstime);
	assert((abstime &gt;&gt; 32) == 0 &amp;&amp; (uint32_t)abstime != 0);
	max_rt_quantum = (uint32_t)abstime;

}

#<span class="enscript-reference">if</span> <span class="enscript-reference">defined</span>(<span class="enscript-variable-name">CONFIG_SCHED_TIMESHARE_CORE</span>)

<span class="enscript-comment">/*
 * Set up values for timeshare
 * loading factors.
 */</span>
<span class="enscript-type">static</span> <span class="enscript-type">void</span>
<span class="enscript-function-name">load_shift_init</span>(<span class="enscript-type">void</span>)
{
	int8_t		k, *p = sched_load_shifts;
	uint32_t	i, j;

	uint32_t	sched_decay_penalty = 1;

	<span class="enscript-keyword">if</span> (PE_parse_boot_argn(<span class="enscript-string">&quot;sched_decay_penalty&quot;</span>, &amp;sched_decay_penalty, <span class="enscript-keyword">sizeof</span> (sched_decay_penalty))) {
		kprintf(<span class="enscript-string">&quot;Overriding scheduler decay penalty %u\n&quot;</span>, sched_decay_penalty);
	}

	<span class="enscript-keyword">if</span> (PE_parse_boot_argn(<span class="enscript-string">&quot;sched_decay_usage_age_factor&quot;</span>, &amp;sched_decay_usage_age_factor, <span class="enscript-keyword">sizeof</span> (sched_decay_usage_age_factor))) {
		kprintf(<span class="enscript-string">&quot;Overriding scheduler decay usage age factor %u\n&quot;</span>, sched_decay_usage_age_factor);
	}

	<span class="enscript-keyword">if</span> (PE_parse_boot_argn(<span class="enscript-string">&quot;sched_use_combined_fgbg_decay&quot;</span>, &amp;sched_use_combined_fgbg_decay, <span class="enscript-keyword">sizeof</span> (sched_use_combined_fgbg_decay))) {
		kprintf(<span class="enscript-string">&quot;Overriding schedule fg/bg decay calculation: %u\n&quot;</span>, sched_use_combined_fgbg_decay);
	}

	<span class="enscript-keyword">if</span> (sched_decay_penalty == 0) {
		<span class="enscript-comment">/*
		 * There is no penalty for timeshare threads for using too much
		 * CPU, so set all load shifts to INT8_MIN. Even under high load,
		 * sched_pri_shift will be &gt;INT8_MAX, and there will be no
		 * penalty applied to threads (nor will sched_usage be updated per
		 * thread).
		 */</span>
		<span class="enscript-keyword">for</span> (i = 0; i &lt; NRQS; i++) {
			sched_load_shifts[i] = INT8_MIN;
		}

		<span class="enscript-keyword">return</span>;
	}

	*p++ = INT8_MIN; *p++ = 0;

	<span class="enscript-comment">/*
	 * For a given system load &quot;i&quot;, the per-thread priority
	 * penalty per quantum of CPU usage is ~2^k priority
	 * levels. &quot;sched_decay_penalty&quot; can cause more
	 * array entries to be filled with smaller &quot;k&quot; values
	 */</span>
	<span class="enscript-keyword">for</span> (i = 2, j = 1 &lt;&lt; sched_decay_penalty, k = 1; i &lt; NRQS; ++k) {
		<span class="enscript-keyword">for</span> (j &lt;&lt;= 1; (i &lt; j) &amp;&amp; (i &lt; NRQS); ++i)
			*p++ = k;
	}
}

<span class="enscript-type">static</span> <span class="enscript-type">void</span>
<span class="enscript-function-name">preempt_pri_init</span>(<span class="enscript-type">void</span>)
{
	<span class="enscript-type">int</span>		i, *p = sched_preempt_pri;

	<span class="enscript-keyword">for</span> (i = BASEPRI_FOREGROUND; i &lt; MINPRI_KERNEL; ++i)
		setbit(i, p);

	<span class="enscript-keyword">for</span> (i = BASEPRI_PREEMPT; i &lt;= MAXPRI; ++i)
		setbit(i, p);
}

#<span class="enscript-reference">endif</span> <span class="enscript-comment">/* CONFIG_SCHED_TIMESHARE_CORE */</span>

<span class="enscript-comment">/*
 *	Thread wait timer expiration.
 */</span>
<span class="enscript-type">void</span>
<span class="enscript-function-name">thread_timer_expire</span>(
	<span class="enscript-type">void</span>			*p0,
	__unused <span class="enscript-type">void</span>	*p1)
{
	thread_t		thread = p0;
	spl_t			s;

	s = splsched();
	thread_lock(thread);
	<span class="enscript-keyword">if</span> (--thread-&gt;wait_timer_active == 0) {
		<span class="enscript-keyword">if</span> (thread-&gt;wait_timer_is_set) {
			thread-&gt;wait_timer_is_set = FALSE;
			clear_wait_internal(thread, THREAD_TIMED_OUT);
		}
	}
	thread_unlock(thread);
	splx(s);
}

<span class="enscript-comment">/*
 *	thread_unblock:
 *
 *	Unblock thread on wake up.
 *
 *	Returns TRUE if the thread should now be placed on the runqueue.
 *
 *	Thread must be locked.
 *
 *	Called at splsched().
 */</span>
boolean_t
<span class="enscript-function-name">thread_unblock</span>(
	thread_t		thread,
	wait_result_t	wresult)
{
	boolean_t		ready_for_runq = FALSE;
	thread_t		cthread = current_thread();
	uint32_t		new_run_count;

	<span class="enscript-comment">/*
	 *	Set wait_result.
	 */</span>
	thread-&gt;wait_result = wresult;

	<span class="enscript-comment">/*
	 *	Cancel pending wait timer.
	 */</span>
	<span class="enscript-keyword">if</span> (thread-&gt;wait_timer_is_set) {
		<span class="enscript-keyword">if</span> (timer_call_cancel(&amp;thread-&gt;wait_timer))
			thread-&gt;wait_timer_active--;
		thread-&gt;wait_timer_is_set = FALSE;
	}

	<span class="enscript-comment">/*
	 *	Update scheduling state: not waiting,
	 *	set running.
	 */</span>
	thread-&gt;state &amp;= ~(TH_WAIT|TH_UNINT);

	<span class="enscript-keyword">if</span> (!(thread-&gt;state &amp; TH_RUN)) {
		thread-&gt;state |= TH_RUN;
		thread-&gt;last_made_runnable_time = mach_approximate_time();

		ready_for_runq = TRUE;

		(*thread-&gt;sched_call)(SCHED_CALL_UNBLOCK, thread);

		<span class="enscript-comment">/*
		 *	Update run counts.
		 */</span>
		new_run_count = sched_run_incr(thread);
		<span class="enscript-keyword">if</span> (thread-&gt;sched_mode == TH_MODE_TIMESHARE) {
			sched_share_incr(thread);

			<span class="enscript-keyword">if</span> (thread-&gt;sched_flags &amp; TH_SFLAG_THROTTLED)
				sched_background_incr(thread);
		}
	} <span class="enscript-keyword">else</span> {
		<span class="enscript-comment">/*
		 *	Signal if idling on another processor.
		 */</span>
#<span class="enscript-reference">if</span> <span class="enscript-variable-name">CONFIG_SCHED_IDLE_IN_PLACE</span>
		<span class="enscript-keyword">if</span> (thread-&gt;state &amp; TH_IDLE) {
			processor_t		processor = thread-&gt;last_processor;

			<span class="enscript-keyword">if</span> (processor != current_processor())
				machine_signal_idle(processor);
		}
#<span class="enscript-reference">else</span>
		assert((thread-&gt;state &amp; TH_IDLE) == 0);
#<span class="enscript-reference">endif</span>

		new_run_count = sched_run_count; <span class="enscript-comment">/* updated in thread_select_idle() */</span>
	}


	<span class="enscript-comment">/*
	 * Calculate deadline for real-time threads.
	 */</span>
	<span class="enscript-keyword">if</span> (thread-&gt;sched_mode == TH_MODE_REALTIME) {
		uint64_t ctime;

		ctime = mach_absolute_time();
		thread-&gt;realtime.deadline = thread-&gt;realtime.constraint + ctime;
	}

	<span class="enscript-comment">/*
	 * Clear old quantum, fail-safe computation, etc.
	 */</span>
	thread-&gt;quantum_remaining = 0;
	thread-&gt;computation_metered = 0;
	thread-&gt;reason = AST_NONE;

	<span class="enscript-comment">/* Obtain power-relevant interrupt and &quot;platform-idle exit&quot; statistics.
	 * We also account for &quot;double hop&quot; thread signaling via
	 * the thread callout infrastructure.
	 * DRK: consider removing the callout wakeup counters in the future
	 * they're present for verification at the moment.
	 */</span>
	boolean_t aticontext, pidle;
	ml_get_power_state(&amp;aticontext, &amp;pidle);

	<span class="enscript-keyword">if</span> (__improbable(aticontext &amp;&amp; !(thread_get_tag_internal(thread) &amp; THREAD_TAG_CALLOUT))) {
		ledger_credit(thread-&gt;t_ledger, task_ledgers.interrupt_wakeups, 1);
		DTRACE_SCHED2(iwakeup, <span class="enscript-type">struct</span> thread *, thread, <span class="enscript-type">struct</span> proc *, thread-&gt;task-&gt;bsd_info);

		uint64_t ttd = PROCESSOR_DATA(current_processor(), timer_call_ttd);

		<span class="enscript-keyword">if</span> (ttd) {
			<span class="enscript-keyword">if</span> (ttd &lt;= timer_deadline_tracking_bin_1)
				thread-&gt;thread_timer_wakeups_bin_1++;
			<span class="enscript-keyword">else</span>
				<span class="enscript-keyword">if</span> (ttd &lt;= timer_deadline_tracking_bin_2)
					thread-&gt;thread_timer_wakeups_bin_2++;
		}

		<span class="enscript-keyword">if</span> (pidle) {
			ledger_credit(thread-&gt;t_ledger, task_ledgers.platform_idle_wakeups, 1);
		}

	} <span class="enscript-keyword">else</span> <span class="enscript-keyword">if</span> (thread_get_tag_internal(cthread) &amp; THREAD_TAG_CALLOUT) {
		<span class="enscript-keyword">if</span> (cthread-&gt;callout_woken_from_icontext) {
			ledger_credit(thread-&gt;t_ledger, task_ledgers.interrupt_wakeups, 1);
			thread-&gt;thread_callout_interrupt_wakeups++;
			<span class="enscript-keyword">if</span> (cthread-&gt;callout_woken_from_platform_idle) {
				ledger_credit(thread-&gt;t_ledger, task_ledgers.platform_idle_wakeups, 1);
				thread-&gt;thread_callout_platform_idle_wakeups++;
			}
			
			cthread-&gt;callout_woke_thread = TRUE;
		}
	}
	
	<span class="enscript-keyword">if</span> (thread_get_tag_internal(thread) &amp; THREAD_TAG_CALLOUT) {
		thread-&gt;callout_woken_from_icontext = aticontext;
		thread-&gt;callout_woken_from_platform_idle = pidle;
		thread-&gt;callout_woke_thread = FALSE;
	}

	KERNEL_DEBUG_CONSTANT_IST(KDEBUG_TRACE,
		MACHDBG_CODE(DBG_MACH_SCHED,MACH_MAKE_RUNNABLE) | DBG_FUNC_NONE,
		(uintptr_t)thread_tid(thread), thread-&gt;sched_pri, thread-&gt;wait_result, new_run_count, 0);

	DTRACE_SCHED2(wakeup, <span class="enscript-type">struct</span> thread *, thread, <span class="enscript-type">struct</span> proc *, thread-&gt;task-&gt;bsd_info);

	<span class="enscript-keyword">return</span> (ready_for_runq);
}

<span class="enscript-comment">/*
 *	Routine:	thread_go
 *	Purpose:
 *		Unblock and dispatch thread.
 *	Conditions:
 *		thread lock held, IPC locks may be held.
 *		thread must have been pulled from wait queue under same lock hold.
 *		thread must have been waiting
 *	Returns:
 *		KERN_SUCCESS - Thread was set running
 *
 * TODO: This should return void
 */</span>
kern_return_t
<span class="enscript-function-name">thread_go</span>(
          thread_t        thread,
          wait_result_t   wresult)
{
	assert(thread-&gt;at_safe_point == FALSE);
	assert(thread-&gt;wait_event == NO_EVENT64);
	assert(thread-&gt;waitq == NULL);

	assert(!(thread-&gt;state &amp; (TH_TERMINATE|TH_TERMINATE2)));
	assert(thread-&gt;state &amp; TH_WAIT);


	<span class="enscript-keyword">if</span> (thread_unblock(thread, wresult))
		thread_setrun(thread, SCHED_PREEMPT | SCHED_TAILQ);

	<span class="enscript-keyword">return</span> (KERN_SUCCESS);
}

<span class="enscript-comment">/*
 *	Routine:	thread_mark_wait_locked
 *	Purpose:
 *		Mark a thread as waiting.  If, given the circumstances,
 *		it doesn't want to wait (i.e. already aborted), then
 *		indicate that in the return value.
 *	Conditions:
 *		at splsched() and thread is locked.
 */</span>
__private_extern__
wait_result_t
<span class="enscript-function-name">thread_mark_wait_locked</span>(
	thread_t			thread,
	wait_interrupt_t 	interruptible)
{
	boolean_t		at_safe_point;

	assert(thread == current_thread());
	assert(!(thread-&gt;state &amp; (TH_WAIT|TH_IDLE|TH_UNINT|TH_TERMINATE2)));

	<span class="enscript-comment">/*
	 *	The thread may have certain types of interrupts/aborts masked
	 *	off.  Even if the wait location says these types of interrupts
	 *	are OK, we have to honor mask settings (outer-scoped code may
	 *	not be able to handle aborts at the moment).
	 */</span>
	<span class="enscript-keyword">if</span> (interruptible &gt; (thread-&gt;options &amp; TH_OPT_INTMASK))
		interruptible = thread-&gt;options &amp; TH_OPT_INTMASK;

	at_safe_point = (interruptible == THREAD_ABORTSAFE);

	<span class="enscript-keyword">if</span> (	interruptible == THREAD_UNINT			||
			!(thread-&gt;sched_flags &amp; TH_SFLAG_ABORT)	||
			(!at_safe_point &amp;&amp;
				(thread-&gt;sched_flags &amp; TH_SFLAG_ABORTSAFELY))) {

		<span class="enscript-keyword">if</span> ( !(thread-&gt;state &amp; TH_TERMINATE))
			DTRACE_SCHED(sleep);

		thread-&gt;state |= (interruptible) ? TH_WAIT : (TH_WAIT | TH_UNINT);
		thread-&gt;at_safe_point = at_safe_point;
		<span class="enscript-keyword">return</span> (thread-&gt;wait_result = THREAD_WAITING);
	}
	<span class="enscript-keyword">else</span>
	<span class="enscript-keyword">if</span> (thread-&gt;sched_flags &amp; TH_SFLAG_ABORTSAFELY)
		thread-&gt;sched_flags &amp;= ~TH_SFLAG_ABORTED_MASK;

	<span class="enscript-keyword">return</span> (thread-&gt;wait_result = THREAD_INTERRUPTED);
}

<span class="enscript-comment">/*
 *	Routine:	thread_interrupt_level
 *	Purpose:
 *	        Set the maximum interruptible state for the
 *		current thread.  The effective value of any
 *		interruptible flag passed into assert_wait
 *		will never exceed this.
 *
 *		Useful for code that must not be interrupted,
 *		but which calls code that doesn't know that.
 *	Returns:
 *		The old interrupt level for the thread.
 */</span>
__private_extern__ 
wait_interrupt_t
<span class="enscript-function-name">thread_interrupt_level</span>(
	wait_interrupt_t new_level)
{
	thread_t thread = current_thread();
	wait_interrupt_t result = thread-&gt;options &amp; TH_OPT_INTMASK;

	thread-&gt;options = (thread-&gt;options &amp; ~TH_OPT_INTMASK) | (new_level &amp; TH_OPT_INTMASK);

	<span class="enscript-keyword">return</span> result;
}

<span class="enscript-comment">/*
 * Check to see if an assert wait is possible, without actually doing one.
 * This is used by debug code in locks and elsewhere to verify that it is
 * always OK to block when trying to take a blocking lock (since waiting
 * for the actual assert_wait to catch the case may make it hard to detect
 * this case.
 */</span>
boolean_t
<span class="enscript-function-name">assert_wait_possible</span>(<span class="enscript-type">void</span>)
{

	thread_t thread;

#<span class="enscript-reference">if</span>	<span class="enscript-variable-name">DEBUG</span>
	<span class="enscript-keyword">if</span>(debug_mode) <span class="enscript-keyword">return</span> TRUE;		<span class="enscript-comment">/* Always succeed in debug mode */</span>
#<span class="enscript-reference">endif</span>
	
	thread = current_thread();

	<span class="enscript-keyword">return</span> (thread == NULL || waitq_wait_possible(thread));
}

<span class="enscript-comment">/*
 *	assert_wait:
 *
 *	Assert that the current thread is about to go to
 *	sleep until the specified event occurs.
 */</span>
wait_result_t
<span class="enscript-function-name">assert_wait</span>(
	event_t				event,
	wait_interrupt_t	interruptible)
{
	<span class="enscript-keyword">if</span> (__improbable(event == NO_EVENT))
		panic(<span class="enscript-string">&quot;%s() called with NO_EVENT&quot;</span>, __func__);

	KERNEL_DEBUG_CONSTANT_IST(KDEBUG_TRACE,
		MACHDBG_CODE(DBG_MACH_SCHED, MACH_WAIT)|DBG_FUNC_NONE,
		VM_KERNEL_UNSLIDE(event), 0, 0, 0, 0);

	<span class="enscript-type">struct</span> waitq *waitq;
	waitq = global_eventq(event);
	<span class="enscript-keyword">return</span> waitq_assert_wait64(waitq, CAST_EVENT64_T(event), interruptible, TIMEOUT_WAIT_FOREVER);
}

wait_result_t
<span class="enscript-function-name">assert_wait_timeout</span>(
	event_t				event,
	wait_interrupt_t	interruptible,
	uint32_t			interval,
	uint32_t			scale_factor)
{
	thread_t			thread = current_thread();
	wait_result_t		wresult;
	uint64_t			deadline;
	spl_t				s;

	<span class="enscript-keyword">if</span> (__improbable(event == NO_EVENT))
		panic(<span class="enscript-string">&quot;%s() called with NO_EVENT&quot;</span>, __func__);

	<span class="enscript-type">struct</span> waitq *waitq;
	waitq = global_eventq(event);

	s = splsched();
	waitq_lock(waitq);
	thread_lock(thread);

	clock_interval_to_deadline(interval, scale_factor, &amp;deadline);

	KERNEL_DEBUG_CONSTANT_IST(KDEBUG_TRACE,
				  MACHDBG_CODE(DBG_MACH_SCHED, MACH_WAIT)|DBG_FUNC_NONE,
				  VM_KERNEL_UNSLIDE(event), interruptible, deadline, 0, 0);

	wresult = waitq_assert_wait64_locked(waitq, CAST_EVENT64_T(event),
					     interruptible,
					     TIMEOUT_URGENCY_SYS_NORMAL,
					     deadline, TIMEOUT_NO_LEEWAY,
					     thread);

	thread_unlock(thread);
	waitq_unlock(waitq);
	splx(s);
	<span class="enscript-keyword">return</span> wresult;
}

wait_result_t
<span class="enscript-function-name">assert_wait_timeout_with_leeway</span>(
	event_t				event,
	wait_interrupt_t	interruptible,
	wait_timeout_urgency_t	urgency,
	uint32_t			interval,
	uint32_t			leeway,
	uint32_t			scale_factor)
{
	thread_t			thread = current_thread();
	wait_result_t		wresult;
	uint64_t			deadline;
	uint64_t			abstime;
	uint64_t			slop;
	uint64_t			now;
	spl_t				s;

	<span class="enscript-keyword">if</span> (__improbable(event == NO_EVENT))
		panic(<span class="enscript-string">&quot;%s() called with NO_EVENT&quot;</span>, __func__);

	now = mach_absolute_time();
	clock_interval_to_absolutetime_interval(interval, scale_factor, &amp;abstime);
	deadline = now + abstime;

	clock_interval_to_absolutetime_interval(leeway, scale_factor, &amp;slop);

	<span class="enscript-type">struct</span> waitq *waitq;
	waitq = global_eventq(event);

	s = splsched();
	waitq_lock(waitq);
	thread_lock(thread);

	KERNEL_DEBUG_CONSTANT_IST(KDEBUG_TRACE,
				  MACHDBG_CODE(DBG_MACH_SCHED, MACH_WAIT)|DBG_FUNC_NONE,
				  VM_KERNEL_UNSLIDE(event), interruptible, deadline, 0, 0);

	wresult = waitq_assert_wait64_locked(waitq, CAST_EVENT64_T(event),
					     interruptible,
					     urgency, deadline, slop,
					     thread);

	thread_unlock(thread);
	waitq_unlock(waitq);
	splx(s);
	<span class="enscript-keyword">return</span> wresult;
}

wait_result_t
<span class="enscript-function-name">assert_wait_deadline</span>(
	event_t				event,
	wait_interrupt_t	interruptible,
	uint64_t			deadline)
{
	thread_t			thread = current_thread();
	wait_result_t		wresult;
	spl_t				s;

	<span class="enscript-keyword">if</span> (__improbable(event == NO_EVENT))
		panic(<span class="enscript-string">&quot;%s() called with NO_EVENT&quot;</span>, __func__);

	<span class="enscript-type">struct</span> waitq *waitq;
	waitq = global_eventq(event);

	s = splsched();
	waitq_lock(waitq);
	thread_lock(thread);

	KERNEL_DEBUG_CONSTANT_IST(KDEBUG_TRACE,
				  MACHDBG_CODE(DBG_MACH_SCHED, MACH_WAIT)|DBG_FUNC_NONE,
				  VM_KERNEL_UNSLIDE(event), interruptible, deadline, 0, 0);

	wresult = waitq_assert_wait64_locked(waitq, CAST_EVENT64_T(event),
					     interruptible,
					     TIMEOUT_URGENCY_SYS_NORMAL, deadline,
					     TIMEOUT_NO_LEEWAY, thread);
	thread_unlock(thread);
	waitq_unlock(waitq);
	splx(s);
	<span class="enscript-keyword">return</span> wresult;
}

wait_result_t
<span class="enscript-function-name">assert_wait_deadline_with_leeway</span>(
	event_t				event,
	wait_interrupt_t	interruptible,
	wait_timeout_urgency_t	urgency,
	uint64_t			deadline,
	uint64_t			leeway)
{
	thread_t			thread = current_thread();
	wait_result_t		wresult;
	spl_t				s;

	<span class="enscript-keyword">if</span> (__improbable(event == NO_EVENT))
		panic(<span class="enscript-string">&quot;%s() called with NO_EVENT&quot;</span>, __func__);

	<span class="enscript-type">struct</span> waitq *waitq;
	waitq = global_eventq(event);

	s = splsched();
	waitq_lock(waitq);
	thread_lock(thread);

	KERNEL_DEBUG_CONSTANT_IST(KDEBUG_TRACE,
				  MACHDBG_CODE(DBG_MACH_SCHED, MACH_WAIT)|DBG_FUNC_NONE,
				  VM_KERNEL_UNSLIDE(event), interruptible, deadline, 0, 0);

	wresult = waitq_assert_wait64_locked(waitq, CAST_EVENT64_T(event),
					     interruptible,
					     urgency, deadline, leeway,
					     thread);

	thread_unlock(thread);
	waitq_unlock(waitq);
	splx(s);
	<span class="enscript-keyword">return</span> wresult;
}

<span class="enscript-comment">/*
 * thread_isoncpu:
 *
 * Return TRUE if a thread is running on a processor such that an AST
 * is needed to pull it out of userspace execution, or if executing in
 * the kernel, bring to a context switch boundary that would cause
 * thread state to be serialized in the thread PCB.
 * 
 * Thread locked, returns the same way. While locked, fields
 * like &quot;state&quot; cannot change. &quot;runq&quot; can change only from set to unset.
 */</span>
<span class="enscript-type">static</span> inline boolean_t
<span class="enscript-function-name">thread_isoncpu</span>(thread_t thread)
{
	<span class="enscript-comment">/* Not running or runnable */</span>
	<span class="enscript-keyword">if</span> (!(thread-&gt;state &amp; TH_RUN))
		<span class="enscript-keyword">return</span> (FALSE);

	<span class="enscript-comment">/* Waiting on a runqueue, not currently running */</span>
	<span class="enscript-comment">/* TODO: This is invalid - it can get dequeued without thread lock, but not context switched. */</span>
	<span class="enscript-keyword">if</span> (thread-&gt;runq != PROCESSOR_NULL)
		<span class="enscript-keyword">return</span> (FALSE);

	<span class="enscript-comment">/*
	 * Thread does not have a stack yet
	 * It could be on the stack alloc queue or preparing to be invoked
	 */</span>
	<span class="enscript-keyword">if</span> (!thread-&gt;kernel_stack)
		<span class="enscript-keyword">return</span> (FALSE);

	<span class="enscript-comment">/*
	 * Thread must be running on a processor, or
	 * about to run, or just did run. In all these
	 * cases, an AST to the processor is needed
	 * to guarantee that the thread is kicked out
	 * of userspace and the processor has
	 * context switched (and saved register state).
	 */</span>
	<span class="enscript-keyword">return</span> (TRUE);
}

<span class="enscript-comment">/*
 * thread_stop:
 *
 * Force a preemption point for a thread and wait
 * for it to stop running on a CPU. If a stronger
 * guarantee is requested, wait until no longer
 * runnable. Arbitrates access among
 * multiple stop requests. (released by unstop)
 *
 * The thread must enter a wait state and stop via a
 * separate means.
 *
 * Returns FALSE if interrupted.
 */</span>
boolean_t
<span class="enscript-function-name">thread_stop</span>(
	thread_t		thread,
	boolean_t	until_not_runnable)
{
	wait_result_t	wresult;
	spl_t			s = splsched();
	boolean_t		oncpu;

	wake_lock(thread);
	thread_lock(thread);

	<span class="enscript-keyword">while</span> (thread-&gt;state &amp; TH_SUSP) {
		thread-&gt;wake_active = TRUE;
		thread_unlock(thread);

		wresult = assert_wait(&amp;thread-&gt;wake_active, THREAD_ABORTSAFE);
		wake_unlock(thread);
		splx(s);

		<span class="enscript-keyword">if</span> (wresult == THREAD_WAITING)
			wresult = thread_block(THREAD_CONTINUE_NULL);

		<span class="enscript-keyword">if</span> (wresult != THREAD_AWAKENED)
			<span class="enscript-keyword">return</span> (FALSE);

		s = splsched();
		wake_lock(thread);
		thread_lock(thread);
	}

	thread-&gt;state |= TH_SUSP;

	<span class="enscript-keyword">while</span> ((oncpu = thread_isoncpu(thread)) ||
		   (until_not_runnable &amp;&amp; (thread-&gt;state &amp; TH_RUN))) {
		processor_t		processor;
		
		<span class="enscript-keyword">if</span> (oncpu) {
			assert(thread-&gt;state &amp; TH_RUN);
			processor = thread-&gt;chosen_processor;
			cause_ast_check(processor);
		}

		thread-&gt;wake_active = TRUE;
		thread_unlock(thread);

		wresult = assert_wait(&amp;thread-&gt;wake_active, THREAD_ABORTSAFE);
		wake_unlock(thread);
		splx(s);

		<span class="enscript-keyword">if</span> (wresult == THREAD_WAITING)
			wresult = thread_block(THREAD_CONTINUE_NULL);

		<span class="enscript-keyword">if</span> (wresult != THREAD_AWAKENED) {
			thread_unstop(thread);
			<span class="enscript-keyword">return</span> (FALSE);
		}

		s = splsched();
		wake_lock(thread);
		thread_lock(thread);
	}

	thread_unlock(thread);
	wake_unlock(thread);
	splx(s);
	
	<span class="enscript-comment">/*
	 * We return with the thread unlocked. To prevent it from
	 * transitioning to a runnable state (or from TH_RUN to
	 * being on the CPU), the caller must ensure the thread
	 * is stopped via an external means (such as an AST)
	 */</span>

	<span class="enscript-keyword">return</span> (TRUE);
}

<span class="enscript-comment">/*
 * thread_unstop:
 *
 * Release a previous stop request and set
 * the thread running if appropriate.
 *
 * Use only after a successful stop operation.
 */</span>
<span class="enscript-type">void</span>
<span class="enscript-function-name">thread_unstop</span>(
	thread_t	thread)
{
	spl_t		s = splsched();

	wake_lock(thread);
	thread_lock(thread);

	assert((thread-&gt;state &amp; (TH_RUN|TH_WAIT|TH_SUSP)) != TH_SUSP);

	<span class="enscript-keyword">if</span> (thread-&gt;state &amp; TH_SUSP) {
		thread-&gt;state &amp;= ~TH_SUSP;

		<span class="enscript-keyword">if</span> (thread-&gt;wake_active) {
			thread-&gt;wake_active = FALSE;
			thread_unlock(thread);

			thread_wakeup(&amp;thread-&gt;wake_active);
			wake_unlock(thread);
			splx(s);

			<span class="enscript-keyword">return</span>;
		}
	}

	thread_unlock(thread);
	wake_unlock(thread);
	splx(s);
}

<span class="enscript-comment">/*
 * thread_wait:
 *
 * Wait for a thread to stop running. (non-interruptible)
 *
 */</span>
<span class="enscript-type">void</span>
<span class="enscript-function-name">thread_wait</span>(
	thread_t	thread,
	boolean_t	until_not_runnable)
{
	wait_result_t	wresult;
	boolean_t 	oncpu;
	processor_t	processor;
	spl_t		s = splsched();

	wake_lock(thread);
	thread_lock(thread);

	<span class="enscript-comment">/*
	 * Wait until not running on a CPU.  If stronger requirement
	 * desired, wait until not runnable.  Assumption: if thread is
	 * on CPU, then TH_RUN is set, so we're not waiting in any case
	 * where the original, pure &quot;TH_RUN&quot; check would have let us 
	 * finish.
	 */</span>
	<span class="enscript-keyword">while</span> ((oncpu = thread_isoncpu(thread)) ||
			(until_not_runnable &amp;&amp; (thread-&gt;state &amp; TH_RUN))) {

		<span class="enscript-keyword">if</span> (oncpu) {
			assert(thread-&gt;state &amp; TH_RUN);
			processor = thread-&gt;chosen_processor;
			cause_ast_check(processor);
		}

		thread-&gt;wake_active = TRUE;
		thread_unlock(thread);

		wresult = assert_wait(&amp;thread-&gt;wake_active, THREAD_UNINT);
		wake_unlock(thread);
		splx(s);

		<span class="enscript-keyword">if</span> (wresult == THREAD_WAITING)
			thread_block(THREAD_CONTINUE_NULL);

		s = splsched();
		wake_lock(thread);
		thread_lock(thread);
	}

	thread_unlock(thread);
	wake_unlock(thread);
	splx(s);
}

<span class="enscript-comment">/*
 *	Routine: clear_wait_internal
 *
 *		Clear the wait condition for the specified thread.
 *		Start the thread executing if that is appropriate.
 *	Arguments:
 *		thread		thread to awaken
 *		result		Wakeup result the thread should see
 *	Conditions:
 *		At splsched
 *		the thread is locked.
 *	Returns:
 *		KERN_SUCCESS		thread was rousted out a wait
 *		KERN_FAILURE		thread was waiting but could not be rousted
 *		KERN_NOT_WAITING	thread was not waiting
 */</span>
__private_extern__ kern_return_t
<span class="enscript-function-name">clear_wait_internal</span>(
	thread_t		thread,
	wait_result_t	wresult)
{
	uint32_t	i = LockTimeOut;
	<span class="enscript-type">struct</span> waitq *waitq = thread-&gt;waitq;

	<span class="enscript-keyword">do</span> {
		<span class="enscript-keyword">if</span> (wresult == THREAD_INTERRUPTED &amp;&amp; (thread-&gt;state &amp; TH_UNINT))
			<span class="enscript-keyword">return</span> (KERN_FAILURE);

		<span class="enscript-keyword">if</span> (waitq != NULL) {
			assert(waitq_irq_safe(waitq)); <span class="enscript-comment">//irqs are already disabled!
</span>			<span class="enscript-keyword">if</span> (waitq_lock_try(waitq)) {
				waitq_pull_thread_locked(waitq, thread);
				waitq_unlock(waitq);
			} <span class="enscript-keyword">else</span> {
				thread_unlock(thread);
				delay(1);
				thread_lock(thread);
				<span class="enscript-keyword">if</span> (waitq != thread-&gt;waitq)
					<span class="enscript-keyword">return</span> KERN_NOT_WAITING;
				<span class="enscript-keyword">continue</span>;
			}
		}

		<span class="enscript-comment">/* TODO: Can we instead assert TH_TERMINATE is not set?  */</span>
		<span class="enscript-keyword">if</span> ((thread-&gt;state &amp; (TH_WAIT|TH_TERMINATE)) == TH_WAIT)
			<span class="enscript-keyword">return</span> (thread_go(thread, wresult));
		<span class="enscript-keyword">else</span>
			<span class="enscript-keyword">return</span> (KERN_NOT_WAITING);
	} <span class="enscript-keyword">while</span> ((--i &gt; 0) || machine_timeout_suspended());

	panic(<span class="enscript-string">&quot;clear_wait_internal: deadlock: thread=%p, wq=%p, cpu=%d\n&quot;</span>,
		  thread, waitq, cpu_number());

	<span class="enscript-keyword">return</span> (KERN_FAILURE);
}


<span class="enscript-comment">/*
 *	clear_wait:
 *
 *	Clear the wait condition for the specified thread.  Start the thread
 *	executing if that is appropriate.
 *
 *	parameters:
 *	  thread		thread to awaken
 *	  result		Wakeup result the thread should see
 */</span>
kern_return_t
<span class="enscript-function-name">clear_wait</span>(
	thread_t		thread,
	wait_result_t	result)
{
	kern_return_t ret;
	spl_t		s;

	s = splsched();
	thread_lock(thread);
	ret = clear_wait_internal(thread, result);
	thread_unlock(thread);
	splx(s);
	<span class="enscript-keyword">return</span> ret;
}


<span class="enscript-comment">/*
 *	thread_wakeup_prim:
 *
 *	Common routine for thread_wakeup, thread_wakeup_with_result,
 *	and thread_wakeup_one.
 *
 */</span>
kern_return_t
<span class="enscript-function-name">thread_wakeup_prim</span>(
	event_t			event,
	boolean_t		one_thread,
	wait_result_t		result)
{
	<span class="enscript-keyword">return</span> (thread_wakeup_prim_internal(event, one_thread, result, -1));
}


kern_return_t
<span class="enscript-function-name">thread_wakeup_prim_internal</span>(
	event_t			event,
	boolean_t		one_thread,
	wait_result_t		result,
	<span class="enscript-type">int</span>			priority)
{
	<span class="enscript-keyword">if</span> (__improbable(event == NO_EVENT))
		panic(<span class="enscript-string">&quot;%s() called with NO_EVENT&quot;</span>, __func__);

	<span class="enscript-type">struct</span> waitq *wq;

	wq = global_eventq(event);
	priority = (priority == -1 ? WAITQ_ALL_PRIORITIES : priority);

	<span class="enscript-keyword">if</span> (one_thread)
		<span class="enscript-keyword">return</span> waitq_wakeup64_one(wq, CAST_EVENT64_T(event), result, priority);
	<span class="enscript-keyword">else</span>
		<span class="enscript-keyword">return</span> waitq_wakeup64_all(wq, CAST_EVENT64_T(event), result, priority);
}

<span class="enscript-comment">/*
 *	thread_bind:
 *
 *	Force the current thread to execute on the specified processor.
 *	Takes effect after the next thread_block().
 *
 *	Returns the previous binding.  PROCESSOR_NULL means
 *	not bound.
 *
 *	XXX - DO NOT export this to users - XXX
 */</span>
processor_t
<span class="enscript-function-name">thread_bind</span>(
	processor_t		processor)
{
	thread_t		self = current_thread();
	processor_t		prev;
	spl_t			s;

	s = splsched();
	thread_lock(self);

	prev = thread_bind_internal(self, processor);

	thread_unlock(self);
	splx(s);

	<span class="enscript-keyword">return</span> (prev);
}

<span class="enscript-comment">/*
 * thread_bind_internal:
 *
 * If the specified thread is not the current thread, and it is currently
 * running on another CPU, a remote AST must be sent to that CPU to cause
 * the thread to migrate to its bound processor. Otherwise, the migration
 * will occur at the next quantum expiration or blocking point.
 *
 * When the thread is the current thread, and explicit thread_block() should
 * be used to force the current processor to context switch away and
 * let the thread migrate to the bound processor.
 *
 * Thread must be locked, and at splsched.
 */</span>

<span class="enscript-type">static</span> processor_t
<span class="enscript-function-name">thread_bind_internal</span>(
	thread_t		thread,
	processor_t		processor)
{
	processor_t		prev;

	<span class="enscript-comment">/* &lt;rdar://problem/15102234&gt; */</span>
	assert(thread-&gt;sched_pri &lt; BASEPRI_RTQUEUES);
	<span class="enscript-comment">/* A thread can't be bound if it's sitting on a (potentially incorrect) runqueue */</span>
	assert(thread-&gt;runq == PROCESSOR_NULL);

	KERNEL_DEBUG_CONSTANT(MACHDBG_CODE(DBG_MACH_SCHED, MACH_THREAD_BIND), thread_tid(thread), processor ? (uintptr_t)processor-&gt;cpu_id : (uintptr_t)-1, 0, 0, 0);

	prev = thread-&gt;bound_processor;
	thread-&gt;bound_processor = processor;

	<span class="enscript-keyword">return</span> (prev);
}

<span class="enscript-comment">/*
 * thread_vm_bind_group_add:
 *
 * The &quot;VM bind group&quot; is a special mechanism to mark a collection
 * of threads from the VM subsystem that, in general, should be scheduled
 * with only one CPU of parallelism. To accomplish this, we initially
 * bind all the threads to the master processor, which has the effect
 * that only one of the threads in the group can execute at once, including
 * preempting threads in the group that are a lower priority. Future
 * mechanisms may use more dynamic mechanisms to prevent the collection
 * of VM threads from using more CPU time than desired.
 *
 * The current implementation can result in priority inversions where
 * compute-bound priority 95 or realtime threads that happen to have
 * landed on the master processor prevent the VM threads from running.
 * When this situation is detected, we unbind the threads for one
 * scheduler tick to allow the scheduler to run the threads an
 * additional CPUs, before restoring the binding (assuming high latency
 * is no longer a problem).
 */</span>

<span class="enscript-comment">/*
 * The current max is provisioned for:
 * vm_compressor_swap_trigger_thread (92)
 * 2 x vm_pageout_iothread_internal (92) when vm_restricted_to_single_processor==TRUE
 * vm_pageout_continue (92)
 * memorystatus_thread (95)
 */</span>
#<span class="enscript-reference">define</span> <span class="enscript-variable-name">MAX_VM_BIND_GROUP_COUNT</span> (5)
<span class="enscript-function-name">decl_simple_lock_data</span>(<span class="enscript-type">static</span>,sched_vm_group_list_lock);
<span class="enscript-type">static</span> thread_t sched_vm_group_thread_list[MAX_VM_BIND_GROUP_COUNT];
<span class="enscript-type">static</span> <span class="enscript-type">int</span> sched_vm_group_thread_count;
<span class="enscript-type">static</span> boolean_t sched_vm_group_temporarily_unbound = FALSE;

<span class="enscript-type">void</span>
<span class="enscript-function-name">thread_vm_bind_group_add</span>(<span class="enscript-type">void</span>)
{
	thread_t self = current_thread();

	thread_reference_internal(self);
	self-&gt;options |= TH_OPT_SCHED_VM_GROUP;

	simple_lock(&amp;sched_vm_group_list_lock);
	assert(sched_vm_group_thread_count &lt; MAX_VM_BIND_GROUP_COUNT);
	sched_vm_group_thread_list[sched_vm_group_thread_count++] = self;
	simple_unlock(&amp;sched_vm_group_list_lock);

	thread_bind(master_processor);

	<span class="enscript-comment">/* Switch to bound processor if not already there */</span>
	thread_block(THREAD_CONTINUE_NULL);
}

<span class="enscript-type">static</span> <span class="enscript-type">void</span>
<span class="enscript-function-name">sched_vm_group_maintenance</span>(<span class="enscript-type">void</span>)
{
	uint64_t ctime = mach_absolute_time();
	uint64_t longtime = ctime - sched_tick_interval;
	<span class="enscript-type">int</span> i;
	spl_t s;
	boolean_t high_latency_observed = FALSE;
	boolean_t runnable_and_not_on_runq_observed = FALSE;
	boolean_t bind_target_changed = FALSE;
	processor_t bind_target = PROCESSOR_NULL;

	<span class="enscript-comment">/* Make sure nobody attempts to add new threads while we are enumerating them */</span>
	simple_lock(&amp;sched_vm_group_list_lock);

	s = splsched();

	<span class="enscript-keyword">for</span> (i=0; i &lt; sched_vm_group_thread_count; i++) {
		thread_t thread = sched_vm_group_thread_list[i];
		assert(thread != THREAD_NULL);
		thread_lock(thread);
		<span class="enscript-keyword">if</span> ((thread-&gt;state &amp; (TH_RUN|TH_WAIT)) == TH_RUN) {
			<span class="enscript-keyword">if</span> (thread-&gt;runq != PROCESSOR_NULL &amp;&amp; thread-&gt;last_made_runnable_time &lt; longtime) {
				high_latency_observed = TRUE;
			} <span class="enscript-keyword">else</span> <span class="enscript-keyword">if</span> (thread-&gt;runq == PROCESSOR_NULL) {
				<span class="enscript-comment">/* There are some cases where a thread be transitiong that also fall into this case */</span>
				runnable_and_not_on_runq_observed = TRUE;
			}
		}
		thread_unlock(thread);

		<span class="enscript-keyword">if</span> (high_latency_observed &amp;&amp; runnable_and_not_on_runq_observed) {
			<span class="enscript-comment">/* All the things we are looking for are true, stop looking */</span>
			<span class="enscript-keyword">break</span>;
		}
	}

	splx(s);

	<span class="enscript-keyword">if</span> (sched_vm_group_temporarily_unbound) {
		<span class="enscript-comment">/* If we turned off binding, make sure everything is OK before rebinding */</span>
		<span class="enscript-keyword">if</span> (!high_latency_observed) {
			<span class="enscript-comment">/* rebind */</span>
			bind_target_changed = TRUE;
			bind_target = master_processor;
			sched_vm_group_temporarily_unbound = FALSE; <span class="enscript-comment">/* might be reset to TRUE if change cannot be completed */</span>
		}
	} <span class="enscript-keyword">else</span> {
		<span class="enscript-comment">/*
		 * Check if we're in a bad state, which is defined by high
		 * latency with no core currently executing a thread. If a
		 * single thread is making progress on a CPU, that means the
		 * binding concept to reduce parallelism is working as
		 * designed.
		 */</span>
		<span class="enscript-keyword">if</span> (high_latency_observed &amp;&amp; !runnable_and_not_on_runq_observed) {
			<span class="enscript-comment">/* unbind */</span>
			bind_target_changed = TRUE;
			bind_target = PROCESSOR_NULL;
			sched_vm_group_temporarily_unbound = TRUE;
		}
	}

	<span class="enscript-keyword">if</span> (bind_target_changed) {
		s = splsched();
		<span class="enscript-keyword">for</span> (i=0; i &lt; sched_vm_group_thread_count; i++) {
			thread_t thread = sched_vm_group_thread_list[i];
			boolean_t removed;
			assert(thread != THREAD_NULL);

			thread_lock(thread);
			removed = thread_run_queue_remove(thread);
			<span class="enscript-keyword">if</span> (removed || ((thread-&gt;state &amp; (TH_RUN | TH_WAIT)) == TH_WAIT)) {
				thread_bind_internal(thread, bind_target);
			} <span class="enscript-keyword">else</span> {
				<span class="enscript-comment">/*
				 * Thread was in the middle of being context-switched-to,
				 * or was in the process of blocking. To avoid switching the bind
				 * state out mid-flight, defer the change if possible.
				 */</span>
				<span class="enscript-keyword">if</span> (bind_target == PROCESSOR_NULL) {
					thread_bind_internal(thread, bind_target);
				} <span class="enscript-keyword">else</span> {
					sched_vm_group_temporarily_unbound = TRUE; <span class="enscript-comment">/* next pass will try again */</span>
				}
			}

			<span class="enscript-keyword">if</span> (removed) {
				thread_run_queue_reinsert(thread, SCHED_PREEMPT | SCHED_TAILQ);
			}
			thread_unlock(thread);
		}
		splx(s);
	}

	simple_unlock(&amp;sched_vm_group_list_lock);
}

<span class="enscript-comment">/* Invoked prior to idle entry to determine if, on SMT capable processors, an SMT
 * rebalancing opportunity exists when a core is (instantaneously) idle, but
 * other SMT-capable cores may be over-committed. TODO: some possible negatives:
 * IPI thrash if this core does not remain idle following the load balancing ASTs
 * Idle &quot;thrash&quot;, when IPI issue is followed by idle entry/core power down
 * followed by a wakeup shortly thereafter.
 */</span>

#<span class="enscript-reference">if</span> (<span class="enscript-variable-name">DEVELOPMENT</span> || <span class="enscript-variable-name">DEBUG</span>)
<span class="enscript-type">int</span> sched_smt_balance = 1;
#<span class="enscript-reference">endif</span>

#<span class="enscript-reference">if</span> <span class="enscript-variable-name">__SMP__</span>
<span class="enscript-comment">/* Invoked with pset locked, returns with pset unlocked */</span>
<span class="enscript-type">static</span> <span class="enscript-type">void</span>
<span class="enscript-function-name">sched_SMT_balance</span>(processor_t cprocessor, processor_set_t cpset) {
	processor_t ast_processor = NULL;

#<span class="enscript-reference">if</span> (<span class="enscript-variable-name">DEVELOPMENT</span> || <span class="enscript-variable-name">DEBUG</span>)
	<span class="enscript-keyword">if</span> (__improbable(sched_smt_balance == 0))
		<span class="enscript-keyword">goto</span> <span class="enscript-reference">smt_balance_exit</span>;
#<span class="enscript-reference">endif</span>
	
	assert(cprocessor == current_processor());
	<span class="enscript-keyword">if</span> (cprocessor-&gt;is_SMT == FALSE)
		<span class="enscript-keyword">goto</span> <span class="enscript-reference">smt_balance_exit</span>;

	processor_t sib_processor = cprocessor-&gt;processor_secondary ? cprocessor-&gt;processor_secondary : cprocessor-&gt;processor_primary;

	<span class="enscript-comment">/* Determine if both this processor and its sibling are idle,
	 * indicating an SMT rebalancing opportunity.
	 */</span>
	<span class="enscript-keyword">if</span> (sib_processor-&gt;state != PROCESSOR_IDLE)
		<span class="enscript-keyword">goto</span> <span class="enscript-reference">smt_balance_exit</span>;

	processor_t sprocessor;

	sprocessor = (processor_t)queue_first(&amp;cpset-&gt;active_queue);

	<span class="enscript-keyword">while</span> (!queue_end(&amp;cpset-&gt;active_queue, (queue_entry_t)sprocessor)) {
		<span class="enscript-keyword">if</span> ((sprocessor-&gt;state == PROCESSOR_RUNNING) &amp;&amp;
		    (sprocessor-&gt;processor_primary != sprocessor) &amp;&amp;
		    (sprocessor-&gt;processor_primary-&gt;state == PROCESSOR_RUNNING) &amp;&amp;
		    (sprocessor-&gt;current_pri &lt; BASEPRI_RTQUEUES) &amp;&amp;
		    ((cpset-&gt;pending_AST_cpu_mask &amp; (1ULL &lt;&lt; sprocessor-&gt;cpu_id)) == 0)) {
			assert(sprocessor != cprocessor);
			ast_processor = sprocessor;
			<span class="enscript-keyword">break</span>;
		}
		sprocessor = (processor_t)queue_next((queue_entry_t)sprocessor);
	}

<span class="enscript-reference">smt_balance_exit</span>:
	pset_unlock(cpset);

	<span class="enscript-keyword">if</span> (ast_processor) {
		KERNEL_DEBUG_CONSTANT(MACHDBG_CODE(DBG_MACH_SCHED, MACH_SCHED_SMT_BALANCE), ast_processor-&gt;cpu_id, ast_processor-&gt;state, ast_processor-&gt;processor_primary-&gt;state, 0, 0);
		cause_ast_check(ast_processor);
	}
}
#<span class="enscript-reference">endif</span> <span class="enscript-comment">/* __SMP__ */</span>

<span class="enscript-comment">/*
 *	thread_select:
 *
 *	Select a new thread for the current processor to execute.
 *
 *	May select the current thread, which must be locked.
 */</span>
<span class="enscript-type">static</span> thread_t
<span class="enscript-function-name">thread_select</span>(
	thread_t			thread,
	processor_t			processor,
	ast_t				reason)
{
	processor_set_t		pset = processor-&gt;processor_set;
	thread_t			new_thread = THREAD_NULL;

	assert(processor == current_processor());
	assert((thread-&gt;state &amp; (TH_RUN|TH_TERMINATE2)) == TH_RUN);

	<span class="enscript-keyword">do</span> {
		<span class="enscript-comment">/*
		 *	Update the priority.
		 */</span>
		<span class="enscript-keyword">if</span> (SCHED(can_update_priority)(thread))
			SCHED(update_priority)(thread);
		
		processor-&gt;current_pri = thread-&gt;sched_pri;
		processor-&gt;current_thmode = thread-&gt;sched_mode;
		processor-&gt;current_sfi_class = thread-&gt;sfi_class;

		pset_lock(pset);

		assert(processor-&gt;state != PROCESSOR_OFF_LINE);

		<span class="enscript-keyword">if</span> (!processor-&gt;is_recommended) {
			<span class="enscript-comment">/*
			 * The performance controller has provided a hint to not dispatch more threads,
			 * unless they are bound to us (and thus we are the only option
			 */</span>
			<span class="enscript-keyword">if</span> (!SCHED(processor_bound_count)(processor)) {
				<span class="enscript-keyword">goto</span> <span class="enscript-reference">idle</span>;
			}
		} <span class="enscript-keyword">else</span> <span class="enscript-keyword">if</span> (processor-&gt;processor_primary != processor) {
			<span class="enscript-comment">/*
			 * Should this secondary SMT processor attempt to find work? For pset runqueue systems,
			 * we should look for work only under the same conditions that choose_processor()
			 * would have assigned work, which is when all primary processors have been assigned work.
			 *
			 * An exception is that bound threads are dispatched to a processor without going through
			 * choose_processor(), so in those cases we should continue trying to dequeue work.
			 */</span>
			<span class="enscript-keyword">if</span> (!SCHED(processor_bound_count)(processor) &amp;&amp; !queue_empty(&amp;pset-&gt;idle_queue) &amp;&amp; !rt_runq.count) {
				<span class="enscript-keyword">goto</span> <span class="enscript-reference">idle</span>;
			}
		}

		rt_lock_lock();

		<span class="enscript-comment">/*
		 *	Test to see if the current thread should continue
		 *	to run on this processor.  Must not be attempting to wait, and not
		 *	bound to a different processor, nor be in the wrong
		 *	processor set, nor be forced to context switch by TH_SUSP.
		 *
		 *	Note that there are never any RT threads in the regular runqueue.
		 *
		 *	This code is very insanely tricky.
		 */</span>

		<span class="enscript-keyword">if</span> (((thread-&gt;state &amp; (TH_TERMINATE|TH_IDLE|TH_WAIT|TH_RUN|TH_SUSP)) == TH_RUN) &amp;&amp;
		    (thread-&gt;sched_pri &gt;= BASEPRI_RTQUEUES     || processor-&gt;processor_primary == processor) &amp;&amp;
		    (thread-&gt;bound_processor == PROCESSOR_NULL || thread-&gt;bound_processor == processor)      &amp;&amp;
		    (thread-&gt;affinity_set == AFFINITY_SET_NULL || thread-&gt;affinity_set-&gt;aset_pset == pset)) {
			<span class="enscript-comment">/*
			 * RT threads with un-expired quantum stay on processor,
			 * unless there's a valid RT thread with an earlier deadline.
			 */</span>
			<span class="enscript-keyword">if</span> (thread-&gt;sched_pri &gt;= BASEPRI_RTQUEUES &amp;&amp; processor-&gt;first_timeslice) {
				<span class="enscript-keyword">if</span> (rt_runq.count &gt; 0) {
					thread_t next_rt;

					next_rt = (thread_t)queue_first(&amp;rt_runq.queue);

					assert(next_rt-&gt;runq == THREAD_ON_RT_RUNQ);

					<span class="enscript-keyword">if</span> (next_rt-&gt;realtime.deadline &lt; processor-&gt;deadline &amp;&amp;
					    (next_rt-&gt;bound_processor == PROCESSOR_NULL ||
					     next_rt-&gt;bound_processor == processor)) {
						<span class="enscript-comment">/* The next RT thread is better, so pick it off the runqueue. */</span>
						<span class="enscript-keyword">goto</span> <span class="enscript-reference">pick_new_rt_thread</span>;
					}
				}

				<span class="enscript-comment">/* This is still the best RT thread to run. */</span>
				processor-&gt;deadline = thread-&gt;realtime.deadline;

				rt_lock_unlock();
				pset_unlock(pset);

				<span class="enscript-keyword">return</span> (thread);
			}

			<span class="enscript-keyword">if</span> ((rt_runq.count == 0) &amp;&amp;
			    SCHED(processor_queue_has_priority)(processor, thread-&gt;sched_pri, TRUE) == FALSE) {
				<span class="enscript-comment">/* This thread is still the highest priority runnable (non-idle) thread */</span>
				processor-&gt;deadline = UINT64_MAX;

				rt_lock_unlock();
				pset_unlock(pset);

				<span class="enscript-keyword">return</span> (thread);
			}
		}

		<span class="enscript-comment">/* OK, so we're not going to run the current thread. Look at the RT queue. */</span>
		<span class="enscript-keyword">if</span> (rt_runq.count &gt; 0) {
			thread_t next_rt = (thread_t)queue_first(&amp;rt_runq.queue);

			assert(next_rt-&gt;runq == THREAD_ON_RT_RUNQ);

			<span class="enscript-keyword">if</span> (__probable((next_rt-&gt;bound_processor == PROCESSOR_NULL ||
			               (next_rt-&gt;bound_processor == processor)))) {
<span class="enscript-reference">pick_new_rt_thread</span>:
				new_thread = (thread_t)dequeue_head(&amp;rt_runq.queue);

				new_thread-&gt;runq = PROCESSOR_NULL;
				SCHED_STATS_RUNQ_CHANGE(&amp;rt_runq.runq_stats, rt_runq.count);
				rt_runq.count--;

				processor-&gt;deadline = new_thread-&gt;realtime.deadline;

				rt_lock_unlock();
				pset_unlock(pset);

				<span class="enscript-keyword">return</span> (new_thread);
			}
		}

		processor-&gt;deadline = UINT64_MAX;
		rt_lock_unlock();

		<span class="enscript-comment">/* No RT threads, so let's look at the regular threads. */</span>
		<span class="enscript-keyword">if</span> ((new_thread = SCHED(choose_thread)(processor, MINPRI, reason)) != THREAD_NULL) {
			pset_unlock(pset);
			<span class="enscript-keyword">return</span> (new_thread);
		}

#<span class="enscript-reference">if</span> <span class="enscript-variable-name">__SMP__</span>
		<span class="enscript-keyword">if</span> (SCHED(steal_thread_enabled)) {
			<span class="enscript-comment">/*
			 * No runnable threads, attempt to steal
			 * from other processors. Returns with pset lock dropped.
			 */</span>

			<span class="enscript-keyword">if</span> ((new_thread = SCHED(steal_thread)(pset)) != THREAD_NULL) {
				<span class="enscript-keyword">return</span> (new_thread);
			}

			<span class="enscript-comment">/*
			 * If other threads have appeared, shortcut
			 * around again.
			 */</span>
			<span class="enscript-keyword">if</span> (!SCHED(processor_queue_empty)(processor) || rt_runq.count &gt; 0)
				<span class="enscript-keyword">continue</span>;

			pset_lock(pset);
		}
#<span class="enscript-reference">endif</span>

	<span class="enscript-reference">idle</span>:
		<span class="enscript-comment">/*
		 *	Nothing is runnable, so set this processor idle if it
		 *	was running.
		 */</span>
		<span class="enscript-keyword">if</span> (processor-&gt;state == PROCESSOR_RUNNING) {
			remqueue((queue_entry_t)processor);
			processor-&gt;state = PROCESSOR_IDLE;

			<span class="enscript-keyword">if</span> (processor-&gt;processor_primary == processor) {
				enqueue_head(&amp;pset-&gt;idle_queue, (queue_entry_t)processor);
			}
			<span class="enscript-keyword">else</span> {
				enqueue_head(&amp;pset-&gt;idle_secondary_queue, (queue_entry_t)processor);
			}
		}

#<span class="enscript-reference">if</span> <span class="enscript-variable-name">__SMP__</span>
		<span class="enscript-comment">/* Invoked with pset locked, returns with pset unlocked */</span>
		sched_SMT_balance(processor, pset);
#<span class="enscript-reference">else</span>
		pset_unlock(pset);
#<span class="enscript-reference">endif</span>

#<span class="enscript-reference">if</span> <span class="enscript-variable-name">CONFIG_SCHED_IDLE_IN_PLACE</span>
		<span class="enscript-comment">/*
		 *	Choose idle thread if fast idle is not possible.
		 */</span>
		<span class="enscript-keyword">if</span> (processor-&gt;processor_primary != processor)
			<span class="enscript-keyword">return</span> (processor-&gt;idle_thread);

		<span class="enscript-keyword">if</span> ((thread-&gt;state &amp; (TH_IDLE|TH_TERMINATE|TH_SUSP)) || !(thread-&gt;state &amp; TH_WAIT) || thread-&gt;wake_active || thread-&gt;sched_pri &gt;= BASEPRI_RTQUEUES)
			<span class="enscript-keyword">return</span> (processor-&gt;idle_thread);

		<span class="enscript-comment">/*
		 *	Perform idling activities directly without a
		 *	context switch.  Return dispatched thread,
		 *	else check again for a runnable thread.
		 */</span>
		new_thread = thread_select_idle(thread, processor);

#<span class="enscript-reference">else</span> <span class="enscript-comment">/* !CONFIG_SCHED_IDLE_IN_PLACE */</span>
		
		<span class="enscript-comment">/*
		 * Do a full context switch to idle so that the current
		 * thread can start running on another processor without
		 * waiting for the fast-idled processor to wake up.
		 */</span>
		new_thread = processor-&gt;idle_thread;

#<span class="enscript-reference">endif</span> <span class="enscript-comment">/* !CONFIG_SCHED_IDLE_IN_PLACE */</span>

	} <span class="enscript-keyword">while</span> (new_thread == THREAD_NULL);

	<span class="enscript-keyword">return</span> (new_thread);
}

#<span class="enscript-reference">if</span> <span class="enscript-variable-name">CONFIG_SCHED_IDLE_IN_PLACE</span>
<span class="enscript-comment">/*
 *	thread_select_idle:
 *
 *	Idle the processor using the current thread context.
 *
 *	Called with thread locked, then dropped and relocked.
 */</span>
<span class="enscript-type">static</span> thread_t
<span class="enscript-function-name">thread_select_idle</span>(
	thread_t		thread,
	processor_t		processor)
{
	thread_t		new_thread;
	uint64_t		arg1, arg2;
	<span class="enscript-type">int</span>			urgency;

	<span class="enscript-keyword">if</span> (thread-&gt;sched_mode == TH_MODE_TIMESHARE) {
		<span class="enscript-keyword">if</span> (thread-&gt;sched_flags &amp; TH_SFLAG_THROTTLED)
			sched_background_decr(thread);

		sched_share_decr(thread);
	}
	sched_run_decr(thread);

	thread-&gt;state |= TH_IDLE;
	processor-&gt;current_pri = IDLEPRI;
	processor-&gt;current_thmode = TH_MODE_NONE;
	processor-&gt;current_sfi_class = SFI_CLASS_KERNEL;

	<span class="enscript-comment">/* Reload precise timing global policy to thread-local policy */</span>
	thread-&gt;precise_user_kernel_time = use_precise_user_kernel_time(thread);
	
	thread_unlock(thread);

	<span class="enscript-comment">/*
	 *	Switch execution timing to processor idle thread.
	 */</span>
	processor-&gt;last_dispatch = mach_absolute_time();

#<span class="enscript-reference">ifdef</span> <span class="enscript-variable-name">CONFIG_MACH_APPROXIMATE_TIME</span>
	commpage_update_mach_approximate_time(processor-&gt;last_dispatch);
#<span class="enscript-reference">endif</span>

	thread-&gt;last_run_time = processor-&gt;last_dispatch;
	thread_timer_event(processor-&gt;last_dispatch, &amp;processor-&gt;idle_thread-&gt;system_timer);
	PROCESSOR_DATA(processor, kernel_timer) = &amp;processor-&gt;idle_thread-&gt;system_timer;

	<span class="enscript-comment">/*
	 *	Cancel the quantum timer while idling.
	 */</span>
	timer_call_cancel(&amp;processor-&gt;quantum_timer);
	processor-&gt;first_timeslice = FALSE;

	(*thread-&gt;sched_call)(SCHED_CALL_BLOCK, thread);

	thread_tell_urgency(THREAD_URGENCY_NONE, 0, 0, 0, NULL);

	<span class="enscript-comment">/*
	 *	Enable interrupts and perform idling activities.  No
	 *	preemption due to TH_IDLE being set.
	 */</span>
	spllo(); new_thread = processor_idle(thread, processor);

	<span class="enscript-comment">/*
	 *	Return at splsched.
	 */</span>
	(*thread-&gt;sched_call)(SCHED_CALL_UNBLOCK, thread);

	thread_lock(thread);

	<span class="enscript-comment">/*
	 *	If awakened, switch to thread timer and start a new quantum.
	 *	Otherwise skip; we will context switch to another thread or return here.
	 */</span>
	<span class="enscript-keyword">if</span> (!(thread-&gt;state &amp; TH_WAIT)) {
		processor-&gt;last_dispatch = mach_absolute_time();
		thread_timer_event(processor-&gt;last_dispatch, &amp;thread-&gt;system_timer);
		PROCESSOR_DATA(processor, kernel_timer) = &amp;thread-&gt;system_timer;

		thread_quantum_init(thread);
		processor-&gt;quantum_end = processor-&gt;last_dispatch + thread-&gt;quantum_remaining;
		timer_call_enter1(&amp;processor-&gt;quantum_timer, thread, processor-&gt;quantum_end, TIMER_CALL_SYS_CRITICAL | TIMER_CALL_LOCAL);
		processor-&gt;first_timeslice = TRUE;

		thread-&gt;computation_epoch = processor-&gt;last_dispatch;
	}

	thread-&gt;state &amp;= ~TH_IDLE;

	urgency = thread_get_urgency(thread, &amp;arg1, &amp;arg2);

	thread_tell_urgency(urgency, arg1, arg2, 0, new_thread);

	sched_run_incr(thread);
	<span class="enscript-keyword">if</span> (thread-&gt;sched_mode == TH_MODE_TIMESHARE) {
		sched_share_incr(thread);

		<span class="enscript-keyword">if</span> (thread-&gt;sched_flags &amp; TH_SFLAG_THROTTLED)
			sched_background_incr(thread);
	}

	<span class="enscript-keyword">return</span> (new_thread);
}
#<span class="enscript-reference">endif</span> <span class="enscript-comment">/* CONFIG_SCHED_IDLE_IN_PLACE */</span>

<span class="enscript-comment">/*
 * thread_invoke
 *
 * Called at splsched with neither thread locked.
 *
 * Perform a context switch and start executing the new thread.
 *
 * Returns FALSE when the context switch didn't happen.
 * The reference to the new thread is still consumed.
 *
 * &quot;self&quot; is what is currently running on the processor,
 * &quot;thread&quot; is the new thread to context switch to
 * (which may be the same thread in some cases)
 */</span>
<span class="enscript-type">static</span> boolean_t
<span class="enscript-function-name">thread_invoke</span>(
	thread_t			self,
	thread_t			thread,
	ast_t				reason)
{
	<span class="enscript-keyword">if</span> (__improbable(get_preemption_level() != 0)) {
		<span class="enscript-type">int</span> pl = get_preemption_level();
		panic(<span class="enscript-string">&quot;thread_invoke: preemption_level %d, possible cause: %s&quot;</span>,
		    pl, (pl &lt; 0 ? <span class="enscript-string">&quot;unlocking an unlocked mutex or spinlock&quot;</span> :
			<span class="enscript-string">&quot;blocking while holding a spinlock, or within interrupt context&quot;</span>));
	}

	thread_continue_t       continuation = self-&gt;continuation;
	<span class="enscript-type">void</span>                    *parameter   = self-&gt;parameter;
	processor_t             processor;

	uint64_t                ctime = mach_absolute_time();

#<span class="enscript-reference">ifdef</span> <span class="enscript-variable-name">CONFIG_MACH_APPROXIMATE_TIME</span>
	commpage_update_mach_approximate_time(ctime);
#<span class="enscript-reference">endif</span>

#<span class="enscript-reference">if</span> <span class="enscript-reference">defined</span>(<span class="enscript-variable-name">CONFIG_SCHED_TIMESHARE_CORE</span>)
	sched_timeshare_consider_maintenance(ctime);
#<span class="enscript-reference">endif</span>

	assert(self == current_thread());
	assert(self-&gt;runq == PROCESSOR_NULL);
	assert((self-&gt;state &amp; (TH_RUN|TH_TERMINATE2)) == TH_RUN);

	thread_lock(thread);

	assert((thread-&gt;state &amp; (TH_RUN|TH_WAIT|TH_UNINT|TH_TERMINATE|TH_TERMINATE2)) == TH_RUN);
	assert(thread-&gt;bound_processor == PROCESSOR_NULL || thread-&gt;bound_processor == current_processor());
	assert(thread-&gt;runq == PROCESSOR_NULL);

	<span class="enscript-comment">/* Reload precise timing global policy to thread-local policy */</span>
	thread-&gt;precise_user_kernel_time = use_precise_user_kernel_time(thread);

	<span class="enscript-comment">/* Update SFI class based on other factors */</span>
	thread-&gt;sfi_class = sfi_thread_classify(thread);

	<span class="enscript-comment">/* Allow realtime threads to hang onto a stack. */</span>
	<span class="enscript-keyword">if</span> ((self-&gt;sched_mode == TH_MODE_REALTIME) &amp;&amp; !self-&gt;reserved_stack)
		self-&gt;reserved_stack = self-&gt;kernel_stack;

	<span class="enscript-keyword">if</span> (continuation != NULL) {
		<span class="enscript-keyword">if</span> (!thread-&gt;kernel_stack) {
			<span class="enscript-comment">/*
			 * If we are using a privileged stack,
			 * check to see whether we can exchange it with
			 * that of the other thread.
			 */</span>
			<span class="enscript-keyword">if</span> (self-&gt;kernel_stack == self-&gt;reserved_stack &amp;&amp; !thread-&gt;reserved_stack)
				<span class="enscript-keyword">goto</span> <span class="enscript-reference">need_stack</span>;

			<span class="enscript-comment">/*
			 * Context switch by performing a stack handoff.
			 */</span>
			continuation = thread-&gt;continuation;
			parameter = thread-&gt;parameter;

			processor = current_processor();
			processor-&gt;active_thread = thread;
			processor-&gt;current_pri = thread-&gt;sched_pri;
			processor-&gt;current_thmode = thread-&gt;sched_mode;
			processor-&gt;current_sfi_class = thread-&gt;sfi_class;
			<span class="enscript-keyword">if</span> (thread-&gt;last_processor != processor &amp;&amp; thread-&gt;last_processor != NULL) {
				<span class="enscript-keyword">if</span> (thread-&gt;last_processor-&gt;processor_set != processor-&gt;processor_set)
					thread-&gt;ps_switch++;
				thread-&gt;p_switch++;
			}
			thread-&gt;last_processor = processor;
			thread-&gt;c_switch++;
			ast_context(thread);

			thread_unlock(thread);

			self-&gt;reason = reason;

			processor-&gt;last_dispatch = ctime;
			self-&gt;last_run_time = ctime;
			thread_timer_event(ctime, &amp;thread-&gt;system_timer);
			PROCESSOR_DATA(processor, kernel_timer) = &amp;thread-&gt;system_timer;

			<span class="enscript-comment">/*
			 * Since non-precise user/kernel time doesn't update the state timer
			 * during privilege transitions, synthesize an event now.
			 */</span>
			<span class="enscript-keyword">if</span> (!thread-&gt;precise_user_kernel_time) {
				timer_switch(PROCESSOR_DATA(processor, current_state),
							ctime,
							 PROCESSOR_DATA(processor, current_state));
			}
	
			KERNEL_DEBUG_CONSTANT_IST(KDEBUG_TRACE,
				MACHDBG_CODE(DBG_MACH_SCHED, MACH_STACK_HANDOFF)|DBG_FUNC_NONE,
				self-&gt;reason, (uintptr_t)thread_tid(thread), self-&gt;sched_pri, thread-&gt;sched_pri, 0);

			<span class="enscript-keyword">if</span> ((thread-&gt;chosen_processor != processor) &amp;&amp; (thread-&gt;chosen_processor != PROCESSOR_NULL)) {
				SCHED_DEBUG_CHOOSE_PROCESSOR_KERNEL_DEBUG_CONSTANT(MACHDBG_CODE(DBG_MACH_SCHED, MACH_MOVED)|DBG_FUNC_NONE,
						(uintptr_t)thread_tid(thread), (uintptr_t)thread-&gt;chosen_processor-&gt;cpu_id, 0, 0, 0);
			}

			DTRACE_SCHED2(off__cpu, <span class="enscript-type">struct</span> thread *, thread, <span class="enscript-type">struct</span> proc *, thread-&gt;task-&gt;bsd_info);

			SCHED_STATS_CSW(processor, self-&gt;reason, self-&gt;sched_pri, thread-&gt;sched_pri);

			TLOG(1, <span class="enscript-string">&quot;thread_invoke: calling stack_handoff\n&quot;</span>);
			stack_handoff(self, thread);

			<span class="enscript-comment">/* 'self' is now off core */</span>
			assert(thread == current_thread());

			DTRACE_SCHED(on__cpu);

			thread_dispatch(self, thread);

			thread-&gt;continuation = thread-&gt;parameter = NULL;

			counter(c_thread_invoke_hits++);

			(<span class="enscript-type">void</span>) spllo();

			assert(continuation);
			call_continuation(continuation, parameter, thread-&gt;wait_result);
			<span class="enscript-comment">/*NOTREACHED*/</span>
		}
		<span class="enscript-keyword">else</span> <span class="enscript-keyword">if</span> (thread == self) {
			<span class="enscript-comment">/* same thread but with continuation */</span>
			ast_context(self);
			counter(++c_thread_invoke_same);

			thread_unlock(self);

			KERNEL_DEBUG_CONSTANT_IST(KDEBUG_TRACE,
				MACHDBG_CODE(DBG_MACH_SCHED,MACH_SCHED) | DBG_FUNC_NONE,
				self-&gt;reason, (uintptr_t)thread_tid(thread), self-&gt;sched_pri, thread-&gt;sched_pri, 0);

			self-&gt;continuation = self-&gt;parameter = NULL;

			(<span class="enscript-type">void</span>) spllo();

			call_continuation(continuation, parameter, self-&gt;wait_result);
			<span class="enscript-comment">/*NOTREACHED*/</span>
		}
	} <span class="enscript-keyword">else</span> {
		<span class="enscript-comment">/*
		 * Check that the other thread has a stack
		 */</span>
		<span class="enscript-keyword">if</span> (!thread-&gt;kernel_stack) {
<span class="enscript-reference">need_stack</span>:
			<span class="enscript-keyword">if</span> (!stack_alloc_try(thread)) {
				counter(c_thread_invoke_misses++);
				thread_unlock(thread);
				thread_stack_enqueue(thread);
				<span class="enscript-keyword">return</span> (FALSE);
			}
		} <span class="enscript-keyword">else</span> <span class="enscript-keyword">if</span> (thread == self) {
			ast_context(self);
			counter(++c_thread_invoke_same);
			thread_unlock(self);

			KERNEL_DEBUG_CONSTANT_IST(KDEBUG_TRACE,
				MACHDBG_CODE(DBG_MACH_SCHED,MACH_SCHED) | DBG_FUNC_NONE,
				self-&gt;reason, (uintptr_t)thread_tid(thread), self-&gt;sched_pri, thread-&gt;sched_pri, 0);

			<span class="enscript-keyword">return</span> (TRUE);
		}
	}

	<span class="enscript-comment">/*
	 * Context switch by full context save.
	 */</span>
	processor = current_processor();
	processor-&gt;active_thread = thread;
	processor-&gt;current_pri = thread-&gt;sched_pri;
	processor-&gt;current_thmode = thread-&gt;sched_mode;
	processor-&gt;current_sfi_class = thread-&gt;sfi_class;
	<span class="enscript-keyword">if</span> (thread-&gt;last_processor != processor &amp;&amp; thread-&gt;last_processor != NULL) {
		<span class="enscript-keyword">if</span> (thread-&gt;last_processor-&gt;processor_set != processor-&gt;processor_set)
			thread-&gt;ps_switch++;
		thread-&gt;p_switch++;
	}
	thread-&gt;last_processor = processor;
	thread-&gt;c_switch++;
	ast_context(thread);

	thread_unlock(thread);

	counter(c_thread_invoke_csw++);

	self-&gt;reason = reason;

	processor-&gt;last_dispatch = ctime;
	self-&gt;last_run_time = ctime;
	thread_timer_event(ctime, &amp;thread-&gt;system_timer);
	PROCESSOR_DATA(processor, kernel_timer) = &amp;thread-&gt;system_timer;

	<span class="enscript-comment">/*
	 * Since non-precise user/kernel time doesn't update the state timer
	 * during privilege transitions, synthesize an event now.
	 */</span>
	<span class="enscript-keyword">if</span> (!thread-&gt;precise_user_kernel_time) {
		timer_switch(PROCESSOR_DATA(processor, current_state),
					ctime,
					 PROCESSOR_DATA(processor, current_state));
	}

	KERNEL_DEBUG_CONSTANT_IST(KDEBUG_TRACE,
		MACHDBG_CODE(DBG_MACH_SCHED,MACH_SCHED) | DBG_FUNC_NONE,
		self-&gt;reason, (uintptr_t)thread_tid(thread), self-&gt;sched_pri, thread-&gt;sched_pri, 0);

	<span class="enscript-keyword">if</span> ((thread-&gt;chosen_processor != processor) &amp;&amp; (thread-&gt;chosen_processor != NULL)) {
		SCHED_DEBUG_CHOOSE_PROCESSOR_KERNEL_DEBUG_CONSTANT(MACHDBG_CODE(DBG_MACH_SCHED, MACH_MOVED)|DBG_FUNC_NONE,
				(uintptr_t)thread_tid(thread), (uintptr_t)thread-&gt;chosen_processor-&gt;cpu_id, 0, 0, 0);
	}

	DTRACE_SCHED2(off__cpu, <span class="enscript-type">struct</span> thread *, thread, <span class="enscript-type">struct</span> proc *, thread-&gt;task-&gt;bsd_info);

	SCHED_STATS_CSW(processor, self-&gt;reason, self-&gt;sched_pri, thread-&gt;sched_pri);

	<span class="enscript-comment">/*
	 * This is where we actually switch register context,
	 * and address space if required.  We will next run
	 * as a result of a subsequent context switch.
	 *
	 * Once registers are switched and the processor is running &quot;thread&quot;,
	 * the stack variables and non-volatile registers will contain whatever
	 * was there the last time that thread blocked. No local variables should
	 * be used after this point, except for the special case of &quot;thread&quot;, which
	 * the platform layer returns as the previous thread running on the processor
	 * via the function call ABI as a return register, and &quot;self&quot;, which may have
	 * been stored on the stack or a non-volatile register, but a stale idea of
	 * what was on the CPU is newly-accurate because that thread is again
	 * running on the CPU.
	 */</span>
	assert(continuation == self-&gt;continuation);
	thread = machine_switch_context(self, continuation, thread);
	assert(self == current_thread());
	TLOG(1,<span class="enscript-string">&quot;thread_invoke: returning machine_switch_context: self %p continuation %p thread %p\n&quot;</span>, self, continuation, thread);

	DTRACE_SCHED(on__cpu);

	<span class="enscript-comment">/*
	 * We have been resumed and are set to run.
	 */</span>
	thread_dispatch(thread, self);

	<span class="enscript-keyword">if</span> (continuation) {
		self-&gt;continuation = self-&gt;parameter = NULL;

		(<span class="enscript-type">void</span>) spllo();

		call_continuation(continuation, parameter, self-&gt;wait_result);
		<span class="enscript-comment">/*NOTREACHED*/</span>
	}

	<span class="enscript-keyword">return</span> (TRUE);
}

#<span class="enscript-reference">if</span> <span class="enscript-reference">defined</span>(<span class="enscript-variable-name">CONFIG_SCHED_DEFERRED_AST</span>)
<span class="enscript-comment">/*
 *	pset_cancel_deferred_dispatch:
 *
 *	Cancels all ASTs that we can cancel for the given processor set
 *	if the current processor is running the last runnable thread in the
 *	system.
 *
 *	This function assumes the current thread is runnable.  This must
 *	be called with the pset unlocked.
 */</span>
<span class="enscript-type">static</span> <span class="enscript-type">void</span>
<span class="enscript-function-name">pset_cancel_deferred_dispatch</span>(
	processor_set_t		pset,
	processor_t		processor)
{
	processor_t		active_processor = NULL;
	uint32_t		sampled_sched_run_count;

	pset_lock(pset);
	sampled_sched_run_count = (<span class="enscript-type">volatile</span> uint32_t) sched_run_count;

	<span class="enscript-comment">/*
	 * If we have emptied the run queue, and our current thread is runnable, we
	 * should tell any processors that are still DISPATCHING that they will
	 * probably not have any work to do.  In the event that there are no
	 * pending signals that we can cancel, this is also uninteresting.
	 *
	 * In the unlikely event that another thread becomes runnable while we are
	 * doing this (sched_run_count is atomically updated, not guarded), the
	 * codepath making it runnable SHOULD (a dangerous word) need the pset lock
	 * in order to dispatch it to a processor in our pset.  So, the other
	 * codepath will wait while we squash all cancelable ASTs, get the pset
	 * lock, and then dispatch the freshly runnable thread.  So this should be
	 * correct (we won't accidentally have a runnable thread that hasn't been
	 * dispatched to an idle processor), if not ideal (we may be restarting the
	 * dispatch process, which could have some overhead).
	 *
	 */</span>
	<span class="enscript-keyword">if</span> ((sampled_sched_run_count == 1) &amp;&amp;
	    (pset-&gt;pending_deferred_AST_cpu_mask)) {
		qe_foreach_element_safe(active_processor, &amp;pset-&gt;active_queue, processor_queue) {
			<span class="enscript-comment">/*
			 * If a processor is DISPATCHING, it could be because of
			 * a cancelable signal.
			 *
			 * IF the processor is not our
			 * current processor (the current processor should not
			 * be DISPATCHING, so this is a bit paranoid), AND there
			 * is a cancelable signal pending on the processor, AND
			 * there is no non-cancelable signal pending (as there is
			 * no point trying to backtrack on bringing the processor
			 * up if a signal we cannot cancel is outstanding), THEN
			 * it should make sense to roll back the processor state
			 * to the IDLE state.
			 *
			 * If the racey nature of this approach (as the signal
			 * will be arbitrated by hardware, and can fire as we
			 * roll back state) results in the core responding
			 * despite being pushed back to the IDLE state, it
			 * should be no different than if the core took some
			 * interrupt while IDLE.
			 */</span>
			<span class="enscript-keyword">if</span> ((active_processor-&gt;state == PROCESSOR_DISPATCHING) &amp;&amp;
			    (pset-&gt;pending_deferred_AST_cpu_mask &amp; (1ULL &lt;&lt; active_processor-&gt;cpu_id)) &amp;&amp;
			    (!(pset-&gt;pending_AST_cpu_mask &amp; (1ULL &lt;&lt; active_processor-&gt;cpu_id))) &amp;&amp;
			    (active_processor != processor)) {
				<span class="enscript-comment">/*
				 * Squash all of the processor state back to some
				 * reasonable facsimile of PROCESSOR_IDLE.
				 *
				 * TODO: What queue policy do we actually want here?
				 * We want to promote selection of a good processor
				 * to run on.  Do we want to enqueue at the head?
				 * The tail?  At the (relative) old position in the
				 * queue?  Or something else entirely?
				 */</span>
				re_queue_head(&amp;pset-&gt;idle_queue, (queue_entry_t)active_processor);

				assert(active_processor-&gt;next_thread == THREAD_NULL);

				active_processor-&gt;current_pri = IDLEPRI;
				active_processor-&gt;current_thmode = TH_MODE_FIXED;
				active_processor-&gt;current_sfi_class = SFI_CLASS_KERNEL;
				active_processor-&gt;deadline = UINT64_MAX;
				active_processor-&gt;state = PROCESSOR_IDLE;
				pset-&gt;pending_deferred_AST_cpu_mask &amp;= ~(1U &lt;&lt; active_processor-&gt;cpu_id);
				machine_signal_idle_cancel(active_processor);
			}

		}
	}

	pset_unlock(pset);
}
#<span class="enscript-reference">else</span>
<span class="enscript-comment">/* We don't support deferred ASTs; everything is candycanes and sunshine. */</span>
#<span class="enscript-reference">endif</span>

<span class="enscript-comment">/*
 *	thread_dispatch:
 *
 *	Handle threads at context switch.  Re-dispatch other thread
 *	if still running, otherwise update run state and perform
 *	special actions.  Update quantum for other thread and begin
 *	the quantum for ourselves.
 *
 *      &quot;thread&quot; is the old thread that we have switched away from.
 *      &quot;self&quot; is the new current thread that we have context switched to
 *
 *	Called at splsched.
 */</span>
<span class="enscript-type">void</span>
<span class="enscript-function-name">thread_dispatch</span>(
	thread_t		thread,
	thread_t		self)
{
	processor_t		processor = self-&gt;last_processor;

	assert(processor == current_processor());
	assert(self == current_thread());
	assert(thread != self);

	<span class="enscript-keyword">if</span> (thread != THREAD_NULL) {
		<span class="enscript-comment">/*
		 *	If blocked at a continuation, discard
		 *	the stack.
		 */</span>
		<span class="enscript-keyword">if</span> (thread-&gt;continuation != NULL &amp;&amp; thread-&gt;kernel_stack != 0)
			stack_free(thread);

		<span class="enscript-keyword">if</span> (thread-&gt;state &amp; TH_IDLE) {
			KERNEL_DEBUG_CONSTANT_IST(KDEBUG_TRACE,
				MACHDBG_CODE(DBG_MACH_SCHED,MACH_DISPATCH) | DBG_FUNC_NONE,
				(uintptr_t)thread_tid(thread), 0, thread-&gt;state, sched_run_count, 0);
		} <span class="enscript-keyword">else</span> {
			int64_t consumed;
			int64_t remainder = 0;

			<span class="enscript-keyword">if</span> (processor-&gt;quantum_end &gt; processor-&gt;last_dispatch)
				remainder = processor-&gt;quantum_end -
				    processor-&gt;last_dispatch;

			consumed = thread-&gt;quantum_remaining - remainder;

			<span class="enscript-keyword">if</span> ((thread-&gt;reason &amp; AST_LEDGER) == 0) {
				<span class="enscript-comment">/*
				 * Bill CPU time to both the task and
				 * the individual thread.
				 */</span>
				ledger_credit(thread-&gt;t_ledger,
				    task_ledgers.cpu_time, consumed);
				ledger_credit(thread-&gt;t_threadledger,
				    thread_ledgers.cpu_time, consumed);
#<span class="enscript-reference">ifdef</span> <span class="enscript-variable-name">CONFIG_BANK</span>
				<span class="enscript-keyword">if</span> (thread-&gt;t_bankledger) {
					ledger_credit(thread-&gt;t_bankledger,
				    		bank_ledgers.cpu_time,
						(consumed - thread-&gt;t_deduct_bank_ledger_time));

				}
				thread-&gt;t_deduct_bank_ledger_time =0;
#<span class="enscript-reference">endif</span>
			}

			wake_lock(thread);
			thread_lock(thread);

			<span class="enscript-comment">/*
			 *	Compute remainder of current quantum.
			 */</span>
			<span class="enscript-keyword">if</span> (processor-&gt;first_timeslice &amp;&amp;
			    processor-&gt;quantum_end &gt; processor-&gt;last_dispatch)
				thread-&gt;quantum_remaining = (uint32_t)remainder;
			<span class="enscript-keyword">else</span>
				thread-&gt;quantum_remaining = 0;

			<span class="enscript-keyword">if</span> (thread-&gt;sched_mode == TH_MODE_REALTIME) {
				<span class="enscript-comment">/*
				 *	Cancel the deadline if the thread has
				 *	consumed the entire quantum.
				 */</span>
				<span class="enscript-keyword">if</span> (thread-&gt;quantum_remaining == 0) {
					thread-&gt;realtime.deadline = UINT64_MAX;
				}
			} <span class="enscript-keyword">else</span> {
#<span class="enscript-reference">if</span> <span class="enscript-reference">defined</span>(<span class="enscript-variable-name">CONFIG_SCHED_TIMESHARE_CORE</span>)
				<span class="enscript-comment">/*
				 *	For non-realtime threads treat a tiny
				 *	remaining quantum as an expired quantum
				 *	but include what's left next time.
				 */</span>
				<span class="enscript-keyword">if</span> (thread-&gt;quantum_remaining &lt; min_std_quantum) {
					thread-&gt;reason |= AST_QUANTUM;
					thread-&gt;quantum_remaining += SCHED(initial_quantum_size)(thread);
				}
#<span class="enscript-reference">endif</span> <span class="enscript-comment">/* CONFIG_SCHED_TIMESHARE_CORE */</span>
			}

			<span class="enscript-comment">/*
			 *	If we are doing a direct handoff then
			 *	take the remainder of the quantum.
			 */</span>
			<span class="enscript-keyword">if</span> ((thread-&gt;reason &amp; (AST_HANDOFF|AST_QUANTUM)) == AST_HANDOFF) {
				self-&gt;quantum_remaining = thread-&gt;quantum_remaining;
				thread-&gt;reason |= AST_QUANTUM;
				thread-&gt;quantum_remaining = 0;
			} <span class="enscript-keyword">else</span> {
#<span class="enscript-reference">if</span> <span class="enscript-reference">defined</span>(<span class="enscript-variable-name">CONFIG_SCHED_MULTIQ</span>)
				<span class="enscript-keyword">if</span> (SCHED(sched_groups_enabled) &amp;&amp;
				    thread-&gt;sched_group == self-&gt;sched_group) {
					KERNEL_DEBUG_CONSTANT_IST(KDEBUG_TRACE,
					    MACHDBG_CODE(DBG_MACH_SCHED, MACH_QUANTUM_HANDOFF),
					    self-&gt;reason, (uintptr_t)thread_tid(thread),
					    self-&gt;quantum_remaining, thread-&gt;quantum_remaining, 0);

					self-&gt;quantum_remaining = thread-&gt;quantum_remaining;
					thread-&gt;quantum_remaining = 0;
					<span class="enscript-comment">/* Don't set AST_QUANTUM here - old thread might still want to preempt someone else */</span>
				}
#<span class="enscript-reference">endif</span> <span class="enscript-comment">/* defined(CONFIG_SCHED_MULTIQ) */</span>
			}

			thread-&gt;computation_metered += (processor-&gt;last_dispatch - thread-&gt;computation_epoch);

			<span class="enscript-keyword">if</span> ((thread-&gt;rwlock_count != 0) &amp;&amp; !(LcksOpts &amp; disLkRWPrio)) {
				integer_t priority;

				priority = thread-&gt;sched_pri;

				<span class="enscript-keyword">if</span> (priority &lt; thread-&gt;base_pri)
					priority = thread-&gt;base_pri;
				<span class="enscript-keyword">if</span> (priority &lt; BASEPRI_BACKGROUND)
					priority = BASEPRI_BACKGROUND;

				<span class="enscript-keyword">if</span> ((thread-&gt;sched_pri &lt; priority) || !(thread-&gt;sched_flags &amp; TH_SFLAG_RW_PROMOTED)) {
					KERNEL_DEBUG_CONSTANT(
						MACHDBG_CODE(DBG_MACH_SCHED, MACH_RW_PROMOTE) | DBG_FUNC_NONE,
						(uintptr_t)thread_tid(thread), thread-&gt;sched_pri, thread-&gt;base_pri, priority, 0);

					thread-&gt;sched_flags |= TH_SFLAG_RW_PROMOTED;

					<span class="enscript-keyword">if</span> (thread-&gt;sched_pri &lt; priority)
						set_sched_pri(thread, priority);
				}
			}

			<span class="enscript-keyword">if</span> (!(thread-&gt;state &amp; TH_WAIT)) {
				<span class="enscript-comment">/*
				 *	Still runnable.
				 */</span>
				thread-&gt;last_made_runnable_time = mach_approximate_time();

				machine_thread_going_off_core(thread, FALSE);

				<span class="enscript-keyword">if</span> (thread-&gt;reason &amp; AST_QUANTUM)
					thread_setrun(thread, SCHED_TAILQ);
				<span class="enscript-keyword">else</span> <span class="enscript-keyword">if</span> (thread-&gt;reason &amp; AST_PREEMPT)
					thread_setrun(thread, SCHED_HEADQ);
				<span class="enscript-keyword">else</span>
					thread_setrun(thread, SCHED_PREEMPT | SCHED_TAILQ);

				KERNEL_DEBUG_CONSTANT_IST(KDEBUG_TRACE,
					MACHDBG_CODE(DBG_MACH_SCHED,MACH_DISPATCH) | DBG_FUNC_NONE,
					(uintptr_t)thread_tid(thread), thread-&gt;reason, thread-&gt;state, sched_run_count, 0);

				<span class="enscript-keyword">if</span> (thread-&gt;wake_active) {
					thread-&gt;wake_active = FALSE;
					thread_unlock(thread);

					thread_wakeup(&amp;thread-&gt;wake_active);
				} <span class="enscript-keyword">else</span> {
					thread_unlock(thread);
				}

				wake_unlock(thread);
			} <span class="enscript-keyword">else</span> {
				<span class="enscript-comment">/*
				 *	Waiting.
				 */</span>
				boolean_t should_terminate = FALSE;
				uint32_t new_run_count;

				<span class="enscript-comment">/* Only the first call to thread_dispatch
				 * after explicit termination should add
				 * the thread to the termination queue
				 */</span>
				<span class="enscript-keyword">if</span> ((thread-&gt;state &amp; (TH_TERMINATE|TH_TERMINATE2)) == TH_TERMINATE) {
					should_terminate = TRUE;
					thread-&gt;state |= TH_TERMINATE2;
				}

				thread-&gt;state &amp;= ~TH_RUN;
				thread-&gt;last_made_runnable_time = ~0ULL;
				thread-&gt;chosen_processor = PROCESSOR_NULL;

				<span class="enscript-keyword">if</span> (thread-&gt;sched_mode == TH_MODE_TIMESHARE) {
					<span class="enscript-keyword">if</span> (thread-&gt;sched_flags &amp; TH_SFLAG_THROTTLED)
						sched_background_decr(thread);

					sched_share_decr(thread);
				}
				new_run_count = sched_run_decr(thread);

#<span class="enscript-reference">if</span> <span class="enscript-variable-name">CONFIG_SCHED_SFI</span>
				<span class="enscript-keyword">if</span> ((thread-&gt;state &amp; (TH_WAIT | TH_TERMINATE)) == TH_WAIT) {
					<span class="enscript-keyword">if</span> (thread-&gt;reason &amp; AST_SFI) {
						thread-&gt;wait_sfi_begin_time = processor-&gt;last_dispatch;
					}
				}
#<span class="enscript-reference">endif</span>

				machine_thread_going_off_core(thread, should_terminate);

				KERNEL_DEBUG_CONSTANT_IST(KDEBUG_TRACE,
					MACHDBG_CODE(DBG_MACH_SCHED,MACH_DISPATCH) | DBG_FUNC_NONE,
					(uintptr_t)thread_tid(thread), thread-&gt;reason, thread-&gt;state, new_run_count, 0);

				(*thread-&gt;sched_call)(SCHED_CALL_BLOCK, thread);

				<span class="enscript-keyword">if</span> (thread-&gt;wake_active) {
					thread-&gt;wake_active = FALSE;
					thread_unlock(thread);

					thread_wakeup(&amp;thread-&gt;wake_active);
				} <span class="enscript-keyword">else</span> {
					thread_unlock(thread);
				}

				wake_unlock(thread);

				<span class="enscript-keyword">if</span> (should_terminate)
					thread_terminate_enqueue(thread);
			}
		}
	}

	<span class="enscript-comment">/* Update (new) current thread and reprogram quantum timer */</span>
	thread_lock(self);
	<span class="enscript-keyword">if</span> (!(self-&gt;state &amp; TH_IDLE)) {
		uint64_t        arg1, arg2;
		<span class="enscript-type">int</span>             urgency;
		uint64_t		latency;

#<span class="enscript-reference">if</span> <span class="enscript-variable-name">CONFIG_SCHED_SFI</span>
		ast_t			new_ast;

		new_ast = sfi_thread_needs_ast(self, NULL);

		<span class="enscript-keyword">if</span> (new_ast != AST_NONE) {
			ast_on(new_ast);
		}
#<span class="enscript-reference">endif</span>

		assert(processor-&gt;last_dispatch &gt;= self-&gt;last_made_runnable_time);
		latency = processor-&gt;last_dispatch - self-&gt;last_made_runnable_time;

		urgency = thread_get_urgency(self, &amp;arg1, &amp;arg2);

		thread_tell_urgency(urgency, arg1, arg2, latency, self);

		machine_thread_going_on_core(self, urgency, latency);
		
		<span class="enscript-comment">/*
		 *	Get a new quantum if none remaining.
		 */</span>
		<span class="enscript-keyword">if</span> (self-&gt;quantum_remaining == 0) {
			thread_quantum_init(self);
		}

		<span class="enscript-comment">/*
		 *	Set up quantum timer and timeslice.
		 */</span>
		processor-&gt;quantum_end = processor-&gt;last_dispatch + self-&gt;quantum_remaining;
		timer_call_enter1(&amp;processor-&gt;quantum_timer, self, processor-&gt;quantum_end, TIMER_CALL_SYS_CRITICAL | TIMER_CALL_LOCAL);

		processor-&gt;first_timeslice = TRUE;
	} <span class="enscript-keyword">else</span> {
		timer_call_cancel(&amp;processor-&gt;quantum_timer);
		processor-&gt;first_timeslice = FALSE;

		thread_tell_urgency(THREAD_URGENCY_NONE, 0, 0, 0, self);
		machine_thread_going_on_core(self, THREAD_URGENCY_NONE, 0);
	}

	self-&gt;computation_epoch = processor-&gt;last_dispatch;
	self-&gt;reason = AST_NONE;

	thread_unlock(self);

#<span class="enscript-reference">if</span> <span class="enscript-reference">defined</span>(<span class="enscript-variable-name">CONFIG_SCHED_DEFERRED_AST</span>)
	<span class="enscript-comment">/*
	 * TODO: Can we state that redispatching our old thread is also
	 * uninteresting?
	 */</span>
	<span class="enscript-keyword">if</span> ((((<span class="enscript-type">volatile</span> uint32_t)sched_run_count) == 1) &amp;&amp;
	    !(self-&gt;state &amp; TH_IDLE)) {
		pset_cancel_deferred_dispatch(processor-&gt;processor_set, processor);
	}
#<span class="enscript-reference">endif</span>

}

<span class="enscript-comment">/*
 *	thread_block_reason:
 *
 *	Forces a reschedule, blocking the caller if a wait
 *	has been asserted.
 *
 *	If a continuation is specified, then thread_invoke will
 *	attempt to discard the thread's kernel stack.  When the
 *	thread resumes, it will execute the continuation function
 *	on a new kernel stack.
 */</span>
<span class="enscript-function-name">counter</span>(mach_counter_t  c_thread_block_calls = 0;)
 
wait_result_t
<span class="enscript-function-name">thread_block_reason</span>(
	thread_continue_t	continuation,
	<span class="enscript-type">void</span>				*parameter,
	ast_t				reason)
{
	thread_t        self = current_thread();
	processor_t     processor;
	thread_t        new_thread;
	spl_t           s;

	counter(++c_thread_block_calls);

	s = splsched();

	processor = current_processor();

	<span class="enscript-comment">/* If we're explicitly yielding, force a subsequent quantum */</span>
	<span class="enscript-keyword">if</span> (reason &amp; AST_YIELD)
		processor-&gt;first_timeslice = FALSE;

	<span class="enscript-comment">/* We're handling all scheduling AST's */</span>
	ast_off(AST_SCHEDULING);

	self-&gt;continuation = continuation;
	self-&gt;parameter = parameter;

	<span class="enscript-keyword">if</span> (self-&gt;state &amp; ~(TH_RUN | TH_IDLE)) {
		KERNEL_DEBUG_CONSTANT_IST(KDEBUG_TRACE,
			MACHDBG_CODE(DBG_MACH_SCHED,MACH_BLOCK), 
			reason, VM_KERNEL_UNSLIDE(continuation), 0, 0, 0);
	}

	<span class="enscript-keyword">do</span> {
		thread_lock(self);
		new_thread = thread_select(self, processor, reason);
		thread_unlock(self);
	} <span class="enscript-keyword">while</span> (!thread_invoke(self, new_thread, reason));

	splx(s);

	<span class="enscript-keyword">return</span> (self-&gt;wait_result);
}

<span class="enscript-comment">/*
 *	thread_block:
 *
 *	Block the current thread if a wait has been asserted.
 */</span>
wait_result_t
<span class="enscript-function-name">thread_block</span>(
	thread_continue_t	continuation)
{
	<span class="enscript-keyword">return</span> thread_block_reason(continuation, NULL, AST_NONE);
}

wait_result_t
<span class="enscript-function-name">thread_block_parameter</span>(
	thread_continue_t	continuation,
	<span class="enscript-type">void</span>				*parameter)
{
	<span class="enscript-keyword">return</span> thread_block_reason(continuation, parameter, AST_NONE);
}

<span class="enscript-comment">/*
 *	thread_run:
 *
 *	Switch directly from the current thread to the
 *	new thread, handing off our quantum if appropriate.
 *
 *	New thread must be runnable, and not on a run queue.
 *
 *	Called at splsched.
 */</span>
<span class="enscript-type">int</span>
<span class="enscript-function-name">thread_run</span>(
	thread_t			self,
	thread_continue_t	continuation,
	<span class="enscript-type">void</span>				*parameter,
	thread_t			new_thread)
{
	ast_t		handoff = AST_HANDOFF;

	self-&gt;continuation = continuation;
	self-&gt;parameter = parameter;

	<span class="enscript-keyword">while</span> (!thread_invoke(self, new_thread, handoff)) {
		processor_t		processor = current_processor();

		thread_lock(self);
		new_thread = thread_select(self, processor, AST_NONE);
		thread_unlock(self);
		handoff = AST_NONE;
	}

	<span class="enscript-keyword">return</span> (self-&gt;wait_result);
}

<span class="enscript-comment">/*
 *	thread_continue:
 *
 *	Called at splsched when a thread first receives
 *	a new stack after a continuation.
 */</span>
<span class="enscript-type">void</span>
<span class="enscript-function-name">thread_continue</span>(
	thread_t	thread)
{
	thread_t                self = current_thread();
	thread_continue_t       continuation;
	<span class="enscript-type">void</span>                    *parameter;

	DTRACE_SCHED(on__cpu);

	continuation = self-&gt;continuation;
	parameter = self-&gt;parameter;

	thread_dispatch(thread, self);

	self-&gt;continuation = self-&gt;parameter = NULL;

	<span class="enscript-keyword">if</span> (thread != THREAD_NULL)
		(<span class="enscript-type">void</span>)spllo();

 TLOG(1, <span class="enscript-string">&quot;thread_continue: calling call_continuation \n&quot;</span>);
	call_continuation(continuation, parameter, self-&gt;wait_result);
	<span class="enscript-comment">/*NOTREACHED*/</span>
}

<span class="enscript-type">void</span>
<span class="enscript-function-name">thread_quantum_init</span>(thread_t thread)
{
	<span class="enscript-keyword">if</span> (thread-&gt;sched_mode == TH_MODE_REALTIME) {
		thread-&gt;quantum_remaining = thread-&gt;realtime.computation;
	} <span class="enscript-keyword">else</span> {
		thread-&gt;quantum_remaining = SCHED(initial_quantum_size)(thread);
	}
}

uint32_t
<span class="enscript-function-name">sched_timeshare_initial_quantum_size</span>(thread_t thread)
{
	<span class="enscript-keyword">if</span> ((thread == THREAD_NULL) || !(thread-&gt;sched_flags &amp; TH_SFLAG_THROTTLED))
		<span class="enscript-keyword">return</span> std_quantum;
	<span class="enscript-keyword">else</span>
		<span class="enscript-keyword">return</span> bg_quantum;
}

<span class="enscript-comment">/*
 *	run_queue_init:
 *
 *	Initialize a run queue before first use.
 */</span>
<span class="enscript-type">void</span>
<span class="enscript-function-name">run_queue_init</span>(
	run_queue_t		rq)
{
	<span class="enscript-type">int</span>				i;

	rq-&gt;highq = IDLEPRI;
	<span class="enscript-keyword">for</span> (i = 0; i &lt; NRQBM; i++)
		rq-&gt;bitmap[i] = 0;
	setbit(MAXPRI - IDLEPRI, rq-&gt;bitmap);
	rq-&gt;urgency = rq-&gt;count = 0;
	<span class="enscript-keyword">for</span> (i = 0; i &lt; NRQS; i++)
		queue_init(&amp;rq-&gt;queues[i]);
}

<span class="enscript-comment">/*
 *	run_queue_dequeue:
 *
 *	Perform a dequeue operation on a run queue,
 *	and return the resulting thread.
 *
 *	The run queue must be locked (see thread_run_queue_remove()
 *	for more info), and not empty.
 */</span>
thread_t
<span class="enscript-function-name">run_queue_dequeue</span>(
	run_queue_t		rq,
	integer_t		options)
{
	thread_t		thread;
	queue_t			queue = rq-&gt;queues + rq-&gt;highq;

	<span class="enscript-keyword">if</span> (options &amp; SCHED_HEADQ) {
		thread = (thread_t)dequeue_head(queue);
	}
	<span class="enscript-keyword">else</span> {
		thread = (thread_t)dequeue_tail(queue);
	}

	thread-&gt;runq = PROCESSOR_NULL;
	SCHED_STATS_RUNQ_CHANGE(&amp;rq-&gt;runq_stats, rq-&gt;count);
	rq-&gt;count--;
	<span class="enscript-keyword">if</span> (SCHED(priority_is_urgent)(rq-&gt;highq)) {
		rq-&gt;urgency--; assert(rq-&gt;urgency &gt;= 0);
	}
	<span class="enscript-keyword">if</span> (queue_empty(queue)) {
		<span class="enscript-keyword">if</span> (rq-&gt;highq != IDLEPRI)
			clrbit(MAXPRI - rq-&gt;highq, rq-&gt;bitmap);
		rq-&gt;highq = MAXPRI - ffsbit(rq-&gt;bitmap);
	}

	<span class="enscript-keyword">return</span> (thread);
}

<span class="enscript-comment">/*
 *	run_queue_enqueue:
 *
 *	Perform a enqueue operation on a run queue.
 *
 *	The run queue must be locked (see thread_run_queue_remove()
 *	for more info).
 */</span>
boolean_t
<span class="enscript-function-name">run_queue_enqueue</span>(
							  run_queue_t		rq,
							  thread_t			thread,
							  integer_t		options)
{
	queue_t			queue = rq-&gt;queues + thread-&gt;sched_pri;
	boolean_t		result = FALSE;
	
	<span class="enscript-keyword">if</span> (queue_empty(queue)) {
		enqueue_tail(queue, (queue_entry_t)thread);
		
		setbit(MAXPRI - thread-&gt;sched_pri, rq-&gt;bitmap);
		<span class="enscript-keyword">if</span> (thread-&gt;sched_pri &gt; rq-&gt;highq) {
			rq-&gt;highq = thread-&gt;sched_pri;
			result = TRUE;
		}
	} <span class="enscript-keyword">else</span> {
		<span class="enscript-keyword">if</span> (options &amp; SCHED_TAILQ)
			enqueue_tail(queue, (queue_entry_t)thread);
		<span class="enscript-keyword">else</span>
			enqueue_head(queue, (queue_entry_t)thread);
	}
	<span class="enscript-keyword">if</span> (SCHED(priority_is_urgent)(thread-&gt;sched_pri))
		rq-&gt;urgency++;
	SCHED_STATS_RUNQ_CHANGE(&amp;rq-&gt;runq_stats, rq-&gt;count);
	rq-&gt;count++;
	
	<span class="enscript-keyword">return</span> (result);
	
}

<span class="enscript-comment">/*
 *	run_queue_remove:
 *
 *	Remove a specific thread from a runqueue.
 *
 *	The run queue must be locked.
 */</span>
<span class="enscript-type">void</span>
<span class="enscript-function-name">run_queue_remove</span>(
				  run_queue_t		rq,
				  thread_t			thread)
{

	remqueue((queue_entry_t)thread);
	SCHED_STATS_RUNQ_CHANGE(&amp;rq-&gt;runq_stats, rq-&gt;count);
	rq-&gt;count--;
	<span class="enscript-keyword">if</span> (SCHED(priority_is_urgent)(thread-&gt;sched_pri)) {
		rq-&gt;urgency--; assert(rq-&gt;urgency &gt;= 0);
	}
	
	<span class="enscript-keyword">if</span> (queue_empty(rq-&gt;queues + thread-&gt;sched_pri)) {
		<span class="enscript-comment">/* update run queue status */</span>
		<span class="enscript-keyword">if</span> (thread-&gt;sched_pri != IDLEPRI)
			clrbit(MAXPRI - thread-&gt;sched_pri, rq-&gt;bitmap);
		rq-&gt;highq = MAXPRI - ffsbit(rq-&gt;bitmap);
	}
	
	thread-&gt;runq = PROCESSOR_NULL;
}

<span class="enscript-comment">/* Assumes RT lock is not held, and acquires splsched/rt_lock itself */</span>
<span class="enscript-type">void</span>
<span class="enscript-function-name">rt_runq_scan</span>(sched_update_scan_context_t scan_context)
{
	spl_t		s;
	thread_t	thread;

	s = splsched();
	rt_lock_lock();

	qe_foreach_element_safe(thread, &amp;rt_runq.queue, links) {
		<span class="enscript-keyword">if</span> (thread-&gt;last_made_runnable_time &lt; scan_context-&gt;earliest_rt_make_runnable_time) {
			scan_context-&gt;earliest_rt_make_runnable_time = thread-&gt;last_made_runnable_time;
		}
	}

	rt_lock_unlock();
	splx(s);
}


<span class="enscript-comment">/*
 *	realtime_queue_insert:
 *
 *	Enqueue a thread for realtime execution.
 */</span>
<span class="enscript-type">static</span> boolean_t
<span class="enscript-function-name">realtime_queue_insert</span>(
	thread_t			thread)
{
	queue_t				queue = &amp;rt_runq.queue;
	uint64_t			deadline = thread-&gt;realtime.deadline;
	boolean_t			preempt = FALSE;

	rt_lock_lock();

	<span class="enscript-keyword">if</span> (queue_empty(queue)) {
		enqueue_tail(queue, (queue_entry_t)thread);
		preempt = TRUE;
	}
	<span class="enscript-keyword">else</span> {
		<span class="enscript-type">register</span> thread_t	entry = (thread_t)queue_first(queue);

		<span class="enscript-keyword">while</span> (TRUE) {
			<span class="enscript-keyword">if</span> (	queue_end(queue, (queue_entry_t)entry)	||
						deadline &lt; entry-&gt;realtime.deadline		) {
				entry = (thread_t)queue_prev((queue_entry_t)entry);
				<span class="enscript-keyword">break</span>;
			}

			entry = (thread_t)queue_next((queue_entry_t)entry);
		}

		<span class="enscript-keyword">if</span> ((queue_entry_t)entry == queue)
			preempt = TRUE;

		insque((queue_entry_t)thread, (queue_entry_t)entry);
	}

	thread-&gt;runq = THREAD_ON_RT_RUNQ;
	SCHED_STATS_RUNQ_CHANGE(&amp;rt_runq.runq_stats, rt_runq.count);
	rt_runq.count++;

	rt_lock_unlock();

	<span class="enscript-keyword">return</span> (preempt);
}

<span class="enscript-comment">/*
 *	realtime_setrun:
 *
 *	Dispatch a thread for realtime execution.
 *
 *	Thread must be locked.  Associated pset must
 *	be locked, and is returned unlocked.
 */</span>
<span class="enscript-type">static</span> <span class="enscript-type">void</span>
<span class="enscript-function-name">realtime_setrun</span>(
	processor_t			processor,
	thread_t			thread)
{
	processor_set_t		pset = processor-&gt;processor_set;
	ast_t				preempt;

	boolean_t do_signal_idle = FALSE, do_cause_ast = FALSE;

	thread-&gt;chosen_processor = processor;

	<span class="enscript-comment">/* &lt;rdar://problem/15102234&gt; */</span>
	assert(thread-&gt;bound_processor == PROCESSOR_NULL);

	<span class="enscript-comment">/*
	 *	Dispatch directly onto idle processor.
	 */</span>
	<span class="enscript-keyword">if</span> ( (thread-&gt;bound_processor == processor)
		&amp;&amp; processor-&gt;state == PROCESSOR_IDLE) {
		remqueue((queue_entry_t)processor);
		enqueue_tail(&amp;pset-&gt;active_queue, (queue_entry_t)processor);

		processor-&gt;next_thread = thread;
		processor-&gt;current_pri = thread-&gt;sched_pri;
		processor-&gt;current_thmode = thread-&gt;sched_mode;
		processor-&gt;current_sfi_class = thread-&gt;sfi_class;
		processor-&gt;deadline = thread-&gt;realtime.deadline;
		processor-&gt;state = PROCESSOR_DISPATCHING;

		<span class="enscript-keyword">if</span> (processor != current_processor()) {
			<span class="enscript-keyword">if</span> (!(pset-&gt;pending_AST_cpu_mask &amp; (1ULL &lt;&lt; processor-&gt;cpu_id))) {
				<span class="enscript-comment">/* cleared on exit from main processor_idle() loop */</span>
				pset-&gt;pending_AST_cpu_mask |= (1ULL &lt;&lt; processor-&gt;cpu_id);
				do_signal_idle = TRUE;
			}
		}
		pset_unlock(pset);

		<span class="enscript-keyword">if</span> (do_signal_idle) {
			machine_signal_idle(processor);
		}
		<span class="enscript-keyword">return</span>;
	}

	<span class="enscript-keyword">if</span> (processor-&gt;current_pri &lt; BASEPRI_RTQUEUES)
		preempt = (AST_PREEMPT | AST_URGENT);
	<span class="enscript-keyword">else</span> <span class="enscript-keyword">if</span> (thread-&gt;realtime.deadline &lt; processor-&gt;deadline)
		preempt = (AST_PREEMPT | AST_URGENT);
	<span class="enscript-keyword">else</span>
		preempt = AST_NONE;

	realtime_queue_insert(thread);

	<span class="enscript-keyword">if</span> (preempt != AST_NONE) {
		<span class="enscript-keyword">if</span> (processor-&gt;state == PROCESSOR_IDLE) {
			remqueue((queue_entry_t)processor);
			enqueue_tail(&amp;pset-&gt;active_queue, (queue_entry_t)processor);
			processor-&gt;next_thread = THREAD_NULL;
			processor-&gt;current_pri = thread-&gt;sched_pri;
			processor-&gt;current_thmode = thread-&gt;sched_mode;
			processor-&gt;current_sfi_class = thread-&gt;sfi_class;
			processor-&gt;deadline = thread-&gt;realtime.deadline;
			processor-&gt;state = PROCESSOR_DISPATCHING;
			<span class="enscript-keyword">if</span> (processor == current_processor()) {
				ast_on(preempt);
			} <span class="enscript-keyword">else</span> {
				<span class="enscript-keyword">if</span> (!(pset-&gt;pending_AST_cpu_mask &amp; (1ULL &lt;&lt; processor-&gt;cpu_id))) {
					<span class="enscript-comment">/* cleared on exit from main processor_idle() loop */</span>
					pset-&gt;pending_AST_cpu_mask |= (1ULL &lt;&lt; processor-&gt;cpu_id);
					do_signal_idle = TRUE;
				}
			}
		} <span class="enscript-keyword">else</span> <span class="enscript-keyword">if</span> (processor-&gt;state == PROCESSOR_DISPATCHING) {
			<span class="enscript-keyword">if</span> ((processor-&gt;next_thread == THREAD_NULL) &amp;&amp; ((processor-&gt;current_pri &lt; thread-&gt;sched_pri) || (processor-&gt;deadline &gt; thread-&gt;realtime.deadline))) {
				processor-&gt;current_pri = thread-&gt;sched_pri;
				processor-&gt;current_thmode = thread-&gt;sched_mode;
				processor-&gt;current_sfi_class = thread-&gt;sfi_class;
				processor-&gt;deadline = thread-&gt;realtime.deadline;
			}
		} <span class="enscript-keyword">else</span> {
			<span class="enscript-keyword">if</span> (processor == current_processor()) {
				ast_on(preempt);
			} <span class="enscript-keyword">else</span> {
				<span class="enscript-keyword">if</span> (!(pset-&gt;pending_AST_cpu_mask &amp; (1ULL &lt;&lt; processor-&gt;cpu_id))) {
					<span class="enscript-comment">/* cleared after IPI causes csw_check() to be called */</span>
					pset-&gt;pending_AST_cpu_mask |= (1ULL &lt;&lt; processor-&gt;cpu_id);
					do_cause_ast = TRUE;
				}
			}
		}
	} <span class="enscript-keyword">else</span> {
		<span class="enscript-comment">/* Selected processor was too busy, just keep thread enqueued and let other processors drain it naturally. */</span>
	}

	pset_unlock(pset);

	<span class="enscript-keyword">if</span> (do_signal_idle) {
		machine_signal_idle(processor);
	} <span class="enscript-keyword">else</span> <span class="enscript-keyword">if</span> (do_cause_ast) {
		cause_ast_check(processor);
	}
}


#<span class="enscript-reference">if</span> <span class="enscript-reference">defined</span>(<span class="enscript-variable-name">CONFIG_SCHED_TIMESHARE_CORE</span>)

boolean_t
<span class="enscript-function-name">priority_is_urgent</span>(<span class="enscript-type">int</span> priority)
{
	<span class="enscript-keyword">return</span> testbit(priority, sched_preempt_pri) ? TRUE : FALSE;
}

#<span class="enscript-reference">endif</span> <span class="enscript-comment">/* CONFIG_SCHED_TIMESHARE_CORE */</span>

<span class="enscript-comment">/*
 *	processor_setrun:
 *
 *	Dispatch a thread for execution on a
 *	processor.
 *
 *	Thread must be locked.  Associated pset must
 *	be locked, and is returned unlocked.
 */</span>
<span class="enscript-type">static</span> <span class="enscript-type">void</span>
<span class="enscript-function-name">processor_setrun</span>(
	processor_t			processor,
	thread_t			thread,
	integer_t			options)
{
	processor_set_t		pset = processor-&gt;processor_set;
	ast_t				preempt;
	<span class="enscript-type">enum</span> { eExitIdle, eInterruptRunning, eDoNothing } ipi_action = eDoNothing;
	<span class="enscript-type">enum</span> { eNoSignal, eDoSignal, eDoDeferredSignal } do_signal_idle = eNoSignal;

	boolean_t do_cause_ast = FALSE;

	thread-&gt;chosen_processor = processor;

	<span class="enscript-comment">/*
	 *	Dispatch directly onto idle processor.
	 */</span>
	<span class="enscript-keyword">if</span> ( (SCHED(direct_dispatch_to_idle_processors) ||
		  thread-&gt;bound_processor == processor)
		&amp;&amp; processor-&gt;state == PROCESSOR_IDLE) {
		remqueue((queue_entry_t)processor);
		enqueue_tail(&amp;pset-&gt;active_queue, (queue_entry_t)processor);

		processor-&gt;next_thread = thread;
		processor-&gt;current_pri = thread-&gt;sched_pri;
		processor-&gt;current_thmode = thread-&gt;sched_mode;
		processor-&gt;current_sfi_class = thread-&gt;sfi_class;
		processor-&gt;deadline = UINT64_MAX;
		processor-&gt;state = PROCESSOR_DISPATCHING;

		<span class="enscript-keyword">if</span> (!(pset-&gt;pending_AST_cpu_mask &amp; (1ULL &lt;&lt; processor-&gt;cpu_id))) {
			<span class="enscript-comment">/* cleared on exit from main processor_idle() loop */</span>
			pset-&gt;pending_AST_cpu_mask |= (1ULL &lt;&lt; processor-&gt;cpu_id);
			do_signal_idle = eDoSignal;
		}

		pset_unlock(pset);

		<span class="enscript-keyword">if</span> (do_signal_idle == eDoSignal) {
			machine_signal_idle(processor);
		}

		<span class="enscript-keyword">return</span>;
	}

	<span class="enscript-comment">/*
	 *	Set preemption mode.
	 */</span>
#<span class="enscript-reference">if</span> <span class="enscript-reference">defined</span>(<span class="enscript-variable-name">CONFIG_SCHED_DEFERRED_AST</span>)
	<span class="enscript-comment">/* TODO: Do we need to care about urgency (see rdar://problem/20136239)? */</span>
#<span class="enscript-reference">endif</span>
	<span class="enscript-keyword">if</span> (SCHED(priority_is_urgent)(thread-&gt;sched_pri) &amp;&amp; thread-&gt;sched_pri &gt; processor-&gt;current_pri)
		preempt = (AST_PREEMPT | AST_URGENT);
	<span class="enscript-keyword">else</span> <span class="enscript-keyword">if</span>(processor-&gt;active_thread &amp;&amp; thread_eager_preemption(processor-&gt;active_thread))
		preempt = (AST_PREEMPT | AST_URGENT);
	<span class="enscript-keyword">else</span> <span class="enscript-keyword">if</span> ((thread-&gt;sched_mode == TH_MODE_TIMESHARE) &amp;&amp; (thread-&gt;sched_pri &lt; thread-&gt;base_pri)) {
		<span class="enscript-keyword">if</span>(SCHED(priority_is_urgent)(thread-&gt;base_pri) &amp;&amp; thread-&gt;sched_pri &gt; processor-&gt;current_pri) {
			preempt = (options &amp; SCHED_PREEMPT)? AST_PREEMPT: AST_NONE;
		} <span class="enscript-keyword">else</span> {
			preempt = AST_NONE;
		}
	} <span class="enscript-keyword">else</span>
		preempt = (options &amp; SCHED_PREEMPT)? AST_PREEMPT: AST_NONE;

	SCHED(processor_enqueue)(processor, thread, options);

	<span class="enscript-keyword">if</span> (preempt != AST_NONE) {
		<span class="enscript-keyword">if</span> (processor-&gt;state == PROCESSOR_IDLE) {
			remqueue((queue_entry_t)processor);
			enqueue_tail(&amp;pset-&gt;active_queue, (queue_entry_t)processor);
			processor-&gt;next_thread = THREAD_NULL;
			processor-&gt;current_pri = thread-&gt;sched_pri;
			processor-&gt;current_thmode = thread-&gt;sched_mode;
			processor-&gt;current_sfi_class = thread-&gt;sfi_class;
			processor-&gt;deadline = UINT64_MAX;
			processor-&gt;state = PROCESSOR_DISPATCHING;

			ipi_action = eExitIdle;
		} <span class="enscript-keyword">else</span> <span class="enscript-keyword">if</span> ( processor-&gt;state == PROCESSOR_DISPATCHING) {
			<span class="enscript-keyword">if</span> ((processor-&gt;next_thread == THREAD_NULL) &amp;&amp; (processor-&gt;current_pri &lt; thread-&gt;sched_pri)) {
				processor-&gt;current_pri = thread-&gt;sched_pri;
				processor-&gt;current_thmode = thread-&gt;sched_mode;
				processor-&gt;current_sfi_class = thread-&gt;sfi_class;
				processor-&gt;deadline = UINT64_MAX;
			}
		} <span class="enscript-keyword">else</span> <span class="enscript-keyword">if</span> (	(processor-&gt;state == PROCESSOR_RUNNING		||
				 processor-&gt;state == PROCESSOR_SHUTDOWN)		&amp;&amp;
				(thread-&gt;sched_pri &gt;= processor-&gt;current_pri)) {
			ipi_action = eInterruptRunning;
		}
	} <span class="enscript-keyword">else</span> {
		<span class="enscript-comment">/*
		 * New thread is not important enough to preempt what is running, but
		 * special processor states may need special handling
		 */</span>
		<span class="enscript-keyword">if</span> (processor-&gt;state == PROCESSOR_SHUTDOWN		&amp;&amp;
			thread-&gt;sched_pri &gt;= processor-&gt;current_pri	) {
			ipi_action = eInterruptRunning;
		} <span class="enscript-keyword">else</span> <span class="enscript-keyword">if</span> (	processor-&gt;state == PROCESSOR_IDLE	&amp;&amp;
					processor != current_processor()	) {
			remqueue((queue_entry_t)processor);
			enqueue_tail(&amp;pset-&gt;active_queue, (queue_entry_t)processor);
			processor-&gt;next_thread = THREAD_NULL;
			processor-&gt;current_pri = thread-&gt;sched_pri;
			processor-&gt;current_thmode = thread-&gt;sched_mode;
			processor-&gt;current_sfi_class = thread-&gt;sfi_class;
			processor-&gt;deadline = UINT64_MAX;
			processor-&gt;state = PROCESSOR_DISPATCHING;

			ipi_action = eExitIdle;
		}
	}

	<span class="enscript-keyword">switch</span> (ipi_action) {
		<span class="enscript-keyword">case</span> <span class="enscript-reference">eDoNothing</span>:
			<span class="enscript-keyword">break</span>;
		<span class="enscript-keyword">case</span> <span class="enscript-reference">eExitIdle</span>:
			<span class="enscript-keyword">if</span> (processor == current_processor()) {
				<span class="enscript-keyword">if</span> (csw_check_locked(processor, pset, AST_NONE) != AST_NONE)
					ast_on(preempt);
			} <span class="enscript-keyword">else</span> {
#<span class="enscript-reference">if</span> <span class="enscript-reference">defined</span>(<span class="enscript-variable-name">CONFIG_SCHED_DEFERRED_AST</span>)
				<span class="enscript-keyword">if</span> (!(pset-&gt;pending_deferred_AST_cpu_mask &amp; (1ULL &lt;&lt; processor-&gt;cpu_id)) &amp;&amp;
				    !(pset-&gt;pending_AST_cpu_mask &amp; (1ULL &lt;&lt; processor-&gt;cpu_id))) {
					<span class="enscript-comment">/* cleared on exit from main processor_idle() loop */</span>
					pset-&gt;pending_deferred_AST_cpu_mask |= (1ULL &lt;&lt; processor-&gt;cpu_id);
					do_signal_idle = eDoDeferredSignal;
				}
#<span class="enscript-reference">else</span>
				<span class="enscript-keyword">if</span> (!(pset-&gt;pending_AST_cpu_mask &amp; (1ULL &lt;&lt; processor-&gt;cpu_id))) {
					<span class="enscript-comment">/* cleared on exit from main processor_idle() loop */</span>
					pset-&gt;pending_AST_cpu_mask |= (1ULL &lt;&lt; processor-&gt;cpu_id);
					do_signal_idle = eDoSignal;
				}
#<span class="enscript-reference">endif</span>
			}
			<span class="enscript-keyword">break</span>;
		<span class="enscript-keyword">case</span> <span class="enscript-reference">eInterruptRunning</span>:
			<span class="enscript-keyword">if</span> (processor == current_processor()) {
				<span class="enscript-keyword">if</span> (csw_check_locked(processor, pset, AST_NONE) != AST_NONE)
					ast_on(preempt);
			} <span class="enscript-keyword">else</span> {
				<span class="enscript-keyword">if</span> (!(pset-&gt;pending_AST_cpu_mask &amp; (1ULL &lt;&lt; processor-&gt;cpu_id))) {
					<span class="enscript-comment">/* cleared after IPI causes csw_check() to be called */</span>
					pset-&gt;pending_AST_cpu_mask |= (1ULL &lt;&lt; processor-&gt;cpu_id);
					do_cause_ast = TRUE;
				}
			}
			<span class="enscript-keyword">break</span>;
	}

	pset_unlock(pset);

	<span class="enscript-keyword">if</span> (do_signal_idle == eDoSignal) {
		machine_signal_idle(processor);
	}
#<span class="enscript-reference">if</span> <span class="enscript-reference">defined</span>(<span class="enscript-variable-name">CONFIG_SCHED_DEFERRED_AST</span>)
	<span class="enscript-keyword">else</span> <span class="enscript-keyword">if</span> (do_signal_idle == eDoDeferredSignal) {
		<span class="enscript-comment">/*
		 * TODO: The ability to cancel this signal could make
		 * sending it outside of the pset lock an issue.  Do
		 * we need to address this?  Or would the only fallout
		 * be that the core takes a signal?  As long as we do
		 * not run the risk of having a core marked as signal
		 * outstanding, with no real signal outstanding, the
		 * only result should be that we fail to cancel some
		 * signals.
		 */</span>
		machine_signal_idle_deferred(processor);
	}
#<span class="enscript-reference">endif</span>
	<span class="enscript-keyword">else</span> <span class="enscript-keyword">if</span> (do_cause_ast) {
		cause_ast_check(processor);
	}
}

<span class="enscript-comment">/*
 *	choose_next_pset:
 *
 *	Return the next sibling pset containing
 *	available processors.
 *
 *	Returns the original pset if none other is
 *	suitable.
 */</span>
<span class="enscript-type">static</span> processor_set_t
<span class="enscript-function-name">choose_next_pset</span>(
	processor_set_t		pset)
{
	processor_set_t		nset = pset;

	<span class="enscript-keyword">do</span> {
		nset = next_pset(nset);
	} <span class="enscript-keyword">while</span> (nset-&gt;online_processor_count &lt; 1 &amp;&amp; nset != pset);

	<span class="enscript-keyword">return</span> (nset);
}

<span class="enscript-comment">/*
 *	choose_processor:
 *
 *	Choose a processor for the thread, beginning at
 *	the pset.  Accepts an optional processor hint in
 *	the pset.
 *
 *	Returns a processor, possibly from a different pset.
 *
 *	The thread must be locked.  The pset must be locked,
 *	and the resulting pset is locked on return.
 */</span>
processor_t
<span class="enscript-function-name">choose_processor</span>(
	processor_set_t		pset,
	processor_t			processor,
	thread_t			thread)
{
	processor_set_t		nset, cset = pset;
	
	<span class="enscript-comment">/*
	 * Prefer the hinted processor, when appropriate.
	 */</span>

	<span class="enscript-comment">/* Fold last processor hint from secondary processor to its primary */</span>
	<span class="enscript-keyword">if</span> (processor != PROCESSOR_NULL) {
		processor = processor-&gt;processor_primary;
	}

	<span class="enscript-comment">/*
	 * Only consult platform layer if pset is active, which
	 * it may not be in some cases when a multi-set system
	 * is going to sleep.
	 */</span>
	<span class="enscript-keyword">if</span> (pset-&gt;online_processor_count) {
		<span class="enscript-keyword">if</span> ((processor == PROCESSOR_NULL) || (processor-&gt;processor_set == pset &amp;&amp; processor-&gt;state == PROCESSOR_IDLE)) {
			processor_t mc_processor = machine_choose_processor(pset, processor);
			<span class="enscript-keyword">if</span> (mc_processor != PROCESSOR_NULL)
				processor = mc_processor-&gt;processor_primary;
		}
	}

	<span class="enscript-comment">/*
	 * At this point, we may have a processor hint, and we may have
	 * an initial starting pset. If the hint is not in the pset, or
	 * if the hint is for a processor in an invalid state, discard
	 * the hint.
	 */</span>
	<span class="enscript-keyword">if</span> (processor != PROCESSOR_NULL) {
		<span class="enscript-keyword">if</span> (processor-&gt;processor_set != pset) {
			processor = PROCESSOR_NULL;
		} <span class="enscript-keyword">else</span> <span class="enscript-keyword">if</span> (!processor-&gt;is_recommended) {
			processor = PROCESSOR_NULL;
		} <span class="enscript-keyword">else</span> {
			<span class="enscript-keyword">switch</span> (processor-&gt;state) {
				<span class="enscript-keyword">case</span> <span class="enscript-reference">PROCESSOR_START</span>:
				<span class="enscript-keyword">case</span> <span class="enscript-reference">PROCESSOR_SHUTDOWN</span>:
				<span class="enscript-keyword">case</span> <span class="enscript-reference">PROCESSOR_OFF_LINE</span>:
					<span class="enscript-comment">/*
					 * Hint is for a processor that cannot support running new threads.
					 */</span>
					processor = PROCESSOR_NULL;
					<span class="enscript-keyword">break</span>;
				<span class="enscript-keyword">case</span> <span class="enscript-reference">PROCESSOR_IDLE</span>:
					<span class="enscript-comment">/*
					 * Hint is for an idle processor. Assume it is no worse than any other
					 * idle processor. The platform layer had an opportunity to provide
					 * the &quot;least cost idle&quot; processor above.
					 */</span>
					<span class="enscript-keyword">return</span> (processor);
					<span class="enscript-keyword">break</span>;
				<span class="enscript-keyword">case</span> <span class="enscript-reference">PROCESSOR_RUNNING</span>:
				<span class="enscript-keyword">case</span> <span class="enscript-reference">PROCESSOR_DISPATCHING</span>:
					<span class="enscript-comment">/*
					 * Hint is for an active CPU. This fast-path allows
					 * realtime threads to preempt non-realtime threads
					 * to regain their previous executing processor.
					 */</span>
					<span class="enscript-keyword">if</span> ((thread-&gt;sched_pri &gt;= BASEPRI_RTQUEUES) &amp;&amp;
						(processor-&gt;current_pri &lt; BASEPRI_RTQUEUES))
						<span class="enscript-keyword">return</span> (processor);

					<span class="enscript-comment">/* Otherwise, use hint as part of search below */</span>
					<span class="enscript-keyword">break</span>;
				<span class="enscript-reference">default</span>:
					processor = PROCESSOR_NULL;
					<span class="enscript-keyword">break</span>;
			}
		}
	}

	<span class="enscript-comment">/*
	 * Iterate through the processor sets to locate
	 * an appropriate processor. Seed results with
	 * a last-processor hint, if available, so that
	 * a search must find something strictly better
	 * to replace it.
	 *
	 * A primary/secondary pair of SMT processors are
	 * &quot;unpaired&quot; if the primary is busy but its
	 * corresponding secondary is idle (so the physical
	 * core has full use of its resources).
	 */</span>

	integer_t lowest_priority = MAXPRI + 1;
	integer_t lowest_unpaired_primary_priority = MAXPRI + 1;
	integer_t lowest_count = INT_MAX;
	uint64_t  furthest_deadline = 1;
	processor_t lp_processor = PROCESSOR_NULL;
	processor_t lp_unpaired_primary_processor = PROCESSOR_NULL;
	processor_t lp_unpaired_secondary_processor = PROCESSOR_NULL;
	processor_t lc_processor = PROCESSOR_NULL;
	processor_t fd_processor = PROCESSOR_NULL;

	<span class="enscript-keyword">if</span> (processor != PROCESSOR_NULL) {
		<span class="enscript-comment">/* All other states should be enumerated above. */</span>
		assert(processor-&gt;state == PROCESSOR_RUNNING || processor-&gt;state == PROCESSOR_DISPATCHING);

		lowest_priority = processor-&gt;current_pri;
		lp_processor = processor;

		<span class="enscript-keyword">if</span> (processor-&gt;current_pri &gt;= BASEPRI_RTQUEUES) {
			furthest_deadline = processor-&gt;deadline;
			fd_processor = processor;
		}

		lowest_count = SCHED(processor_runq_count)(processor);
		lc_processor = processor;
	}

	<span class="enscript-keyword">do</span> {

		<span class="enscript-comment">/*
		 * Choose an idle processor, in pset traversal order
		 */</span>
		qe_foreach_element(processor, &amp;cset-&gt;idle_queue, processor_queue) {
			<span class="enscript-keyword">if</span> (processor-&gt;is_recommended)
				<span class="enscript-keyword">return</span> processor;
		}

		<span class="enscript-comment">/*
		 * Otherwise, enumerate active and idle processors to find candidates
		 * with lower priority/etc.
		 */</span>

		qe_foreach_element(processor, &amp;cset-&gt;active_queue, processor_queue) {

			<span class="enscript-keyword">if</span> (!processor-&gt;is_recommended) {
				<span class="enscript-keyword">continue</span>;
			}

			integer_t cpri = processor-&gt;current_pri;
			<span class="enscript-keyword">if</span> (cpri &lt; lowest_priority) {
				lowest_priority = cpri;
				lp_processor = processor;
			}

			<span class="enscript-keyword">if</span> ((cpri &gt;= BASEPRI_RTQUEUES) &amp;&amp; (processor-&gt;deadline &gt; furthest_deadline)) {
				furthest_deadline = processor-&gt;deadline;
				fd_processor = processor;
			}

			integer_t ccount = SCHED(processor_runq_count)(processor);
			<span class="enscript-keyword">if</span> (ccount &lt; lowest_count) {
				lowest_count = ccount;
				lc_processor = processor;
			}
		}

		<span class="enscript-comment">/*
		 * For SMT configs, these idle secondary processors must have active primary. Otherwise
		 * the idle primary would have short-circuited the loop above
		 */</span>
		qe_foreach_element(processor, &amp;cset-&gt;idle_secondary_queue, processor_queue) {

			<span class="enscript-keyword">if</span> (!processor-&gt;is_recommended) {
				<span class="enscript-keyword">continue</span>;
			}

			processor_t cprimary = processor-&gt;processor_primary;

			<span class="enscript-comment">/* If the primary processor is offline or starting up, it's not a candidate for this path */</span>
			<span class="enscript-keyword">if</span> (cprimary-&gt;state == PROCESSOR_RUNNING || cprimary-&gt;state == PROCESSOR_DISPATCHING) {
				integer_t primary_pri = cprimary-&gt;current_pri;

				<span class="enscript-keyword">if</span> (primary_pri &lt; lowest_unpaired_primary_priority) {
					lowest_unpaired_primary_priority = primary_pri;
					lp_unpaired_primary_processor = cprimary;
					lp_unpaired_secondary_processor = processor;
				}
			}
		}


		<span class="enscript-keyword">if</span> (thread-&gt;sched_pri &gt;= BASEPRI_RTQUEUES) {

			<span class="enscript-comment">/*
			 * For realtime threads, the most important aspect is
			 * scheduling latency, so we attempt to assign threads
			 * to good preemption candidates (assuming an idle primary
			 * processor was not available above).
			 */</span>

			<span class="enscript-keyword">if</span> (thread-&gt;sched_pri &gt; lowest_unpaired_primary_priority) {
				<span class="enscript-comment">/* Move to end of active queue so that the next thread doesn't also pick it */</span>
				re_queue_tail(&amp;cset-&gt;active_queue, (queue_entry_t)lp_unpaired_primary_processor);
				<span class="enscript-keyword">return</span> lp_unpaired_primary_processor;
			}
			<span class="enscript-keyword">if</span> (thread-&gt;sched_pri &gt; lowest_priority) {
				<span class="enscript-comment">/* Move to end of active queue so that the next thread doesn't also pick it */</span>
				re_queue_tail(&amp;cset-&gt;active_queue, (queue_entry_t)lp_processor);
				<span class="enscript-keyword">return</span> lp_processor;
			}
			<span class="enscript-keyword">if</span> (thread-&gt;realtime.deadline &lt; furthest_deadline)
				<span class="enscript-keyword">return</span> fd_processor;

			<span class="enscript-comment">/*
			 * If all primary and secondary CPUs are busy with realtime
			 * threads with deadlines earlier than us, move on to next
			 * pset.
			 */</span>
		}
		<span class="enscript-keyword">else</span> {

			<span class="enscript-keyword">if</span> (thread-&gt;sched_pri &gt; lowest_unpaired_primary_priority) {
				<span class="enscript-comment">/* Move to end of active queue so that the next thread doesn't also pick it */</span>
				re_queue_tail(&amp;cset-&gt;active_queue, (queue_entry_t)lp_unpaired_primary_processor);
				<span class="enscript-keyword">return</span> lp_unpaired_primary_processor;
			}
			<span class="enscript-keyword">if</span> (thread-&gt;sched_pri &gt; lowest_priority) {
				<span class="enscript-comment">/* Move to end of active queue so that the next thread doesn't also pick it */</span>
				re_queue_tail(&amp;cset-&gt;active_queue, (queue_entry_t)lp_processor);
				<span class="enscript-keyword">return</span> lp_processor;
			}

			<span class="enscript-comment">/*
			 * If all primary processor in this pset are running a higher
			 * priority thread, move on to next pset. Only when we have
			 * exhausted this search do we fall back to other heuristics.
			 */</span>
		}

		<span class="enscript-comment">/*
		 * Move onto the next processor set.
		 */</span>
		nset = next_pset(cset);

		<span class="enscript-keyword">if</span> (nset != pset) {
			pset_unlock(cset);

			cset = nset;
			pset_lock(cset);
		}
	} <span class="enscript-keyword">while</span> (nset != pset);

	<span class="enscript-comment">/*
	 * Make sure that we pick a running processor,
	 * and that the correct processor set is locked.
	 * Since we may have unlock the candidate processor's
	 * pset, it may have changed state.
	 *
	 * All primary processors are running a higher priority
	 * thread, so the only options left are enqueuing on
	 * the secondary processor that would perturb the least priority
	 * primary, or the least busy primary.
	 */</span>
	<span class="enscript-keyword">do</span> {

		<span class="enscript-comment">/* lowest_priority is evaluated in the main loops above */</span>
		<span class="enscript-keyword">if</span> (lp_unpaired_secondary_processor != PROCESSOR_NULL) {
			processor = lp_unpaired_secondary_processor;
			lp_unpaired_secondary_processor = PROCESSOR_NULL;
		} <span class="enscript-keyword">else</span> <span class="enscript-keyword">if</span> (lc_processor != PROCESSOR_NULL) {
			processor = lc_processor;
			lc_processor = PROCESSOR_NULL;
		} <span class="enscript-keyword">else</span> {
			<span class="enscript-comment">/*
			 * All processors are executing higher
			 * priority threads, and the lowest_count
			 * candidate was not usable
			 */</span>
			processor = master_processor;
		}

		<span class="enscript-comment">/*
		 * Check that the correct processor set is
		 * returned locked.
		 */</span>
		<span class="enscript-keyword">if</span> (cset != processor-&gt;processor_set) {
			pset_unlock(cset);
			cset = processor-&gt;processor_set;
			pset_lock(cset);
		}

		<span class="enscript-comment">/*
		 * We must verify that the chosen processor is still available.
		 * master_processor is an exception, since we may need to preempt
		 * a running thread on it during processor shutdown (for sleep),
		 * and that thread needs to be enqueued on its runqueue to run
		 * when the processor is restarted.
		 */</span>
		<span class="enscript-keyword">if</span> (processor != master_processor &amp;&amp; (processor-&gt;state == PROCESSOR_SHUTDOWN || processor-&gt;state == PROCESSOR_OFF_LINE))
			processor = PROCESSOR_NULL;

	} <span class="enscript-keyword">while</span> (processor == PROCESSOR_NULL);

	<span class="enscript-keyword">return</span> (processor);
}

<span class="enscript-comment">/*
 *	thread_setrun:
 *
 *	Dispatch thread for execution, onto an idle
 *	processor or run queue, and signal a preemption
 *	as appropriate.
 *
 *	Thread must be locked.
 */</span>
<span class="enscript-type">void</span>
<span class="enscript-function-name">thread_setrun</span>(
	thread_t			thread,
	integer_t			options)
{
	processor_t			processor;
	processor_set_t		pset;

	assert((thread-&gt;state &amp; (TH_RUN|TH_WAIT|TH_UNINT|TH_TERMINATE|TH_TERMINATE2)) == TH_RUN);
	assert(thread-&gt;runq == PROCESSOR_NULL);

	<span class="enscript-comment">/*
	 *	Update priority if needed.
	 */</span>
	<span class="enscript-keyword">if</span> (SCHED(can_update_priority)(thread))
		SCHED(update_priority)(thread);

	thread-&gt;sfi_class = sfi_thread_classify(thread);

	assert(thread-&gt;runq == PROCESSOR_NULL);

#<span class="enscript-reference">if</span> <span class="enscript-variable-name">__SMP__</span>
	<span class="enscript-keyword">if</span> (thread-&gt;bound_processor == PROCESSOR_NULL) {
		<span class="enscript-comment">/*
		 *	Unbound case.
		 */</span>
		<span class="enscript-keyword">if</span> (thread-&gt;affinity_set != AFFINITY_SET_NULL) {
			<span class="enscript-comment">/*
			 * Use affinity set policy hint.
			 */</span>
			pset = thread-&gt;affinity_set-&gt;aset_pset;
			pset_lock(pset);

			processor = SCHED(choose_processor)(pset, PROCESSOR_NULL, thread);

			SCHED_DEBUG_CHOOSE_PROCESSOR_KERNEL_DEBUG_CONSTANT(MACHDBG_CODE(DBG_MACH_SCHED, MACH_SCHED_CHOOSE_PROCESSOR)|DBG_FUNC_NONE,
									  (uintptr_t)thread_tid(thread), (uintptr_t)-1, processor-&gt;cpu_id, processor-&gt;state, 0);
		} <span class="enscript-keyword">else</span> <span class="enscript-keyword">if</span> (thread-&gt;last_processor != PROCESSOR_NULL) {
			<span class="enscript-comment">/*
			 *	Simple (last processor) affinity case.
			 */</span>
			processor = thread-&gt;last_processor;
			pset = processor-&gt;processor_set;
			pset_lock(pset);
			processor = SCHED(choose_processor)(pset, processor, thread);

			SCHED_DEBUG_CHOOSE_PROCESSOR_KERNEL_DEBUG_CONSTANT(MACHDBG_CODE(DBG_MACH_SCHED, MACH_SCHED_CHOOSE_PROCESSOR)|DBG_FUNC_NONE,
								  (uintptr_t)thread_tid(thread), thread-&gt;last_processor-&gt;cpu_id, processor-&gt;cpu_id, processor-&gt;state, 0);
		} <span class="enscript-keyword">else</span> {
			<span class="enscript-comment">/*
			 *	No Affinity case:
			 *
			 *	Utilitize a per task hint to spread threads
			 *	among the available processor sets.
			 */</span>
			task_t		task = thread-&gt;task;

			pset = task-&gt;pset_hint;
			<span class="enscript-keyword">if</span> (pset == PROCESSOR_SET_NULL)
				pset = current_processor()-&gt;processor_set;

			pset = choose_next_pset(pset);
			pset_lock(pset);

			processor = SCHED(choose_processor)(pset, PROCESSOR_NULL, thread);
			task-&gt;pset_hint = processor-&gt;processor_set;

			SCHED_DEBUG_CHOOSE_PROCESSOR_KERNEL_DEBUG_CONSTANT(MACHDBG_CODE(DBG_MACH_SCHED, MACH_SCHED_CHOOSE_PROCESSOR)|DBG_FUNC_NONE,
									  (uintptr_t)thread_tid(thread), (uintptr_t)-1, processor-&gt;cpu_id, processor-&gt;state, 0);
		}
	} <span class="enscript-keyword">else</span> {
		<span class="enscript-comment">/*
		 *	Bound case:
		 *
		 *	Unconditionally dispatch on the processor.
		 */</span>
		processor = thread-&gt;bound_processor;
		pset = processor-&gt;processor_set;
		pset_lock(pset);

		SCHED_DEBUG_CHOOSE_PROCESSOR_KERNEL_DEBUG_CONSTANT(MACHDBG_CODE(DBG_MACH_SCHED, MACH_SCHED_CHOOSE_PROCESSOR)|DBG_FUNC_NONE,
							  (uintptr_t)thread_tid(thread), (uintptr_t)-2, processor-&gt;cpu_id, processor-&gt;state, 0);
	}
#<span class="enscript-reference">else</span> <span class="enscript-comment">/* !__SMP__ */</span>
	<span class="enscript-comment">/* Only one processor to choose */</span>
	assert(thread-&gt;bound_processor == PROCESSOR_NULL || thread-&gt;bound_processor == master_processor);
	processor = master_processor;
	pset = processor-&gt;processor_set;
	pset_lock(pset);
#<span class="enscript-reference">endif</span> <span class="enscript-comment">/* !__SMP__ */</span>

	<span class="enscript-comment">/*
	 *	Dispatch the thread on the chosen processor.
	 *	TODO: This should be based on sched_mode, not sched_pri
	 */</span>
	<span class="enscript-keyword">if</span> (thread-&gt;sched_pri &gt;= BASEPRI_RTQUEUES)
		realtime_setrun(processor, thread);
	<span class="enscript-keyword">else</span>
		processor_setrun(processor, thread, options);
}

processor_set_t
<span class="enscript-function-name">task_choose_pset</span>(
	task_t		task)
{
	processor_set_t		pset = task-&gt;pset_hint;

	<span class="enscript-keyword">if</span> (pset != PROCESSOR_SET_NULL)
		pset = choose_next_pset(pset);

	<span class="enscript-keyword">return</span> (pset);
}

<span class="enscript-comment">/*
 *	Check for a preemption point in
 *	the current context.
 *
 *	Called at splsched with thread locked.
 */</span>
ast_t
<span class="enscript-function-name">csw_check</span>(
	processor_t		processor,
	ast_t			check_reason)
{
	processor_set_t	pset = processor-&gt;processor_set;
	ast_t			result;

	pset_lock(pset);

	<span class="enscript-comment">/* If we were sent a remote AST and interrupted a running processor, acknowledge it here with pset lock held */</span>
	pset-&gt;pending_AST_cpu_mask &amp;= ~(1ULL &lt;&lt; processor-&gt;cpu_id);

	result = csw_check_locked(processor, pset, check_reason);

	pset_unlock(pset);

	<span class="enscript-keyword">return</span> result;
}

<span class="enscript-comment">/*
 * Check for preemption at splsched with
 * pset and thread locked
 */</span>
ast_t
<span class="enscript-function-name">csw_check_locked</span>(
	processor_t		processor,
	processor_set_t	pset __unused,
	ast_t			check_reason)
{
	ast_t			result;
	thread_t		thread = processor-&gt;active_thread;

	<span class="enscript-keyword">if</span> (processor-&gt;first_timeslice) {
		<span class="enscript-keyword">if</span> (rt_runq.count &gt; 0)
			<span class="enscript-keyword">return</span> (check_reason | AST_PREEMPT | AST_URGENT);
	}
	<span class="enscript-keyword">else</span> {
		<span class="enscript-keyword">if</span> (rt_runq.count &gt; 0) {
			<span class="enscript-keyword">if</span> (BASEPRI_RTQUEUES &gt; processor-&gt;current_pri)
				<span class="enscript-keyword">return</span> (check_reason | AST_PREEMPT | AST_URGENT);
			<span class="enscript-keyword">else</span>
				<span class="enscript-keyword">return</span> (check_reason | AST_PREEMPT);
		}
	}

	result = SCHED(processor_csw_check)(processor);
	<span class="enscript-keyword">if</span> (result != AST_NONE)
		<span class="enscript-keyword">return</span> (check_reason | result | (thread_eager_preemption(thread) ? AST_URGENT : AST_NONE));

#<span class="enscript-reference">if</span> <span class="enscript-variable-name">__SMP__</span>

	<span class="enscript-comment">/*
	 * If the current thread is running on a processor that is no longer recommended, gently
	 * (non-urgently) get to a point and then block, and which point thread_select() should
	 * try to idle the processor and re-dispatch the thread to a recommended processor.
	 */</span>
	<span class="enscript-keyword">if</span> (!processor-&gt;is_recommended)
		<span class="enscript-keyword">return</span> (check_reason | AST_PREEMPT);

	<span class="enscript-comment">/*
	 * Even though we could continue executing on this processor, a
	 * secondary SMT core should try to shed load to another primary core.
	 *
	 * TODO: Should this do the same check that thread_select does? i.e.
	 * if no bound threads target this processor, and idle primaries exist, preempt
	 * The case of RT threads existing is already taken care of above
	 * Consider Capri in this scenario.
	 *
	 * if (!SCHED(processor_bound_count)(processor) &amp;&amp; !queue_empty(&amp;pset-&gt;idle_queue))
	 *
	 * TODO: Alternatively - check if only primary is idle, or check if primary's pri is lower than mine.
	 */</span>

	<span class="enscript-keyword">if</span> (processor-&gt;current_pri &lt; BASEPRI_RTQUEUES &amp;&amp;
	    processor-&gt;processor_primary != processor)
		<span class="enscript-keyword">return</span> (check_reason | AST_PREEMPT);
#<span class="enscript-reference">endif</span>

	<span class="enscript-keyword">if</span> (thread-&gt;state &amp; TH_SUSP)
		<span class="enscript-keyword">return</span> (check_reason | AST_PREEMPT);

#<span class="enscript-reference">if</span> <span class="enscript-variable-name">CONFIG_SCHED_SFI</span>
	<span class="enscript-comment">/*
	 * Current thread may not need to be preempted, but maybe needs
	 * an SFI wait?
	 */</span>
	result = sfi_thread_needs_ast(thread, NULL);
	<span class="enscript-keyword">if</span> (result != AST_NONE)
		<span class="enscript-keyword">return</span> (check_reason | result);
#<span class="enscript-reference">endif</span>

	<span class="enscript-keyword">return</span> (AST_NONE);
}

<span class="enscript-comment">/*
 *	set_sched_pri:
 *
 *	Set the scheduled priority of the specified thread.
 *
 *	This may cause the thread to change queues.
 *
 *	Thread must be locked.
 */</span>
<span class="enscript-type">void</span>
<span class="enscript-function-name">set_sched_pri</span>(
              thread_t        thread,
              <span class="enscript-type">int</span>             priority)
{
	thread_t cthread = current_thread();
	boolean_t is_current_thread = (thread == cthread) ? TRUE : FALSE;
	<span class="enscript-type">int</span> curgency, nurgency;
	uint64_t urgency_param1, urgency_param2;
	boolean_t removed_from_runq = FALSE;

	<span class="enscript-comment">/* If we're already at this priority, no need to mess with the runqueue */</span>
	<span class="enscript-keyword">if</span> (priority == thread-&gt;sched_pri)
		<span class="enscript-keyword">return</span>;

	<span class="enscript-keyword">if</span> (is_current_thread) {
		assert(thread-&gt;runq == PROCESSOR_NULL);
		curgency = thread_get_urgency(thread, &amp;urgency_param1, &amp;urgency_param2);
	} <span class="enscript-keyword">else</span> {
		removed_from_runq = thread_run_queue_remove(thread);
	}

	KERNEL_DEBUG_CONSTANT(MACHDBG_CODE(DBG_MACH_SCHED, MACH_SCHED_CHANGE_PRIORITY),
	                      (uintptr_t)thread_tid(thread),
	                      thread-&gt;base_pri,
	                      thread-&gt;sched_pri,
	                      0, <span class="enscript-comment">/* eventually, 'reason' */</span>
	                      0);

	thread-&gt;sched_pri = priority;

	<span class="enscript-keyword">if</span> (is_current_thread) {
		nurgency = thread_get_urgency(thread, &amp;urgency_param1, &amp;urgency_param2);
		<span class="enscript-comment">/*
		 * set_sched_pri doesn't alter RT params. We expect direct base priority/QoS
		 * class alterations from user space to occur relatively infrequently, hence
		 * those are lazily handled. QoS classes have distinct priority bands, and QoS
		 * inheritance is expected to involve priority changes.
		 */</span>
		<span class="enscript-keyword">if</span> (nurgency != curgency) {
			thread_tell_urgency(nurgency, urgency_param1, urgency_param2, 0, thread);
			machine_thread_going_on_core(thread, nurgency, 0);
		}
	}

	<span class="enscript-comment">/* TODO: Should this be TAILQ if it went down, HEADQ if it went up? */</span>
	<span class="enscript-keyword">if</span> (removed_from_runq)
		thread_run_queue_reinsert(thread, SCHED_PREEMPT | SCHED_TAILQ);
	<span class="enscript-keyword">else</span> <span class="enscript-keyword">if</span> (thread-&gt;state &amp; TH_RUN) {
		processor_t processor = thread-&gt;last_processor;

		<span class="enscript-keyword">if</span> (is_current_thread) {
			ast_t preempt;

			processor-&gt;current_pri = priority;
			processor-&gt;current_thmode = thread-&gt;sched_mode;
			processor-&gt;current_sfi_class = thread-&gt;sfi_class = sfi_thread_classify(thread);
			<span class="enscript-keyword">if</span> ((preempt = csw_check(processor, AST_NONE)) != AST_NONE)
				ast_on(preempt);
		} <span class="enscript-keyword">else</span> <span class="enscript-keyword">if</span> (processor != PROCESSOR_NULL &amp;&amp; processor-&gt;active_thread == thread)
			cause_ast_check(processor);
	}
}

<span class="enscript-comment">/*
 * thread_run_queue_remove_for_handoff
 *
 * Pull a thread or its (recursive) push target out of the runqueue
 * so that it is ready for thread_run()
 *
 * Called at splsched
 *
 * Returns the thread that was pulled or THREAD_NULL if no thread could be pulled.
 * This may be different than the thread that was passed in.
 */</span>
thread_t
<span class="enscript-function-name">thread_run_queue_remove_for_handoff</span>(thread_t thread) {

	thread_t pulled_thread = THREAD_NULL;

	thread_lock(thread);

	<span class="enscript-comment">/*
	 * Check that the thread is not bound
	 * to a different processor, and that realtime
	 * is not involved.
	 *
	 * Next, pull it off its run queue.  If it
	 * doesn't come, it's not eligible.
	 */</span>

	processor_t processor = current_processor();
	<span class="enscript-keyword">if</span> (processor-&gt;current_pri &lt; BASEPRI_RTQUEUES &amp;&amp; thread-&gt;sched_pri &lt; BASEPRI_RTQUEUES &amp;&amp;
	    (thread-&gt;bound_processor == PROCESSOR_NULL || thread-&gt;bound_processor == processor)) {

			<span class="enscript-keyword">if</span> (thread_run_queue_remove(thread))
				pulled_thread = thread;
	}

	thread_unlock(thread);

	<span class="enscript-keyword">return</span> pulled_thread;
}

<span class="enscript-comment">/*
 *	thread_run_queue_remove:
 *
 *	Remove a thread from its current run queue and
 *	return TRUE if successful.
 *
 *	Thread must be locked.
 *
 *	If thread-&gt;runq is PROCESSOR_NULL, the thread will not re-enter the
 *	run queues because the caller locked the thread.  Otherwise
 *	the thread is on a run queue, but could be chosen for dispatch
 *	and removed by another processor under a different lock, which
 *	will set thread-&gt;runq to PROCESSOR_NULL.
 *
 *	Hence the thread select path must not rely on anything that could
 *	be changed under the thread lock after calling this function,
 *	most importantly thread-&gt;sched_pri.
 */</span>
boolean_t
<span class="enscript-function-name">thread_run_queue_remove</span>(
                        thread_t        thread)
{
	boolean_t removed = FALSE;
	processor_t processor = thread-&gt;runq;

	<span class="enscript-keyword">if</span> ((thread-&gt;state &amp; (TH_RUN|TH_WAIT)) == TH_WAIT) {
		<span class="enscript-comment">/* Thread isn't runnable */</span>
		assert(thread-&gt;runq == PROCESSOR_NULL);
		<span class="enscript-keyword">return</span> FALSE;
	}

	<span class="enscript-keyword">if</span> (processor == PROCESSOR_NULL) {
		<span class="enscript-comment">/*
		 * The thread is either not on the runq,
		 * or is in the midst of being removed from the runq.
		 *
		 * runq is set to NULL under the pset lock, not the thread
		 * lock, so the thread may still be in the process of being dequeued
		 * from the runq. It will wait in invoke for the thread lock to be
		 * dropped.
		 */</span>

		<span class="enscript-keyword">return</span> FALSE;
	}

	<span class="enscript-keyword">if</span> (thread-&gt;sched_pri &lt; BASEPRI_RTQUEUES) {
		<span class="enscript-keyword">return</span> SCHED(processor_queue_remove)(processor, thread);
	}

	rt_lock_lock();

	<span class="enscript-keyword">if</span> (thread-&gt;runq != PROCESSOR_NULL) {
		<span class="enscript-comment">/*
		 *	Thread is on the RT run queue and we have a lock on
		 *	that run queue.
		 */</span>

		assert(thread-&gt;runq == THREAD_ON_RT_RUNQ);

		remqueue((queue_entry_t)thread);
		SCHED_STATS_RUNQ_CHANGE(&amp;rt_runq.runq_stats, rt_runq.count);
		rt_runq.count--;

		thread-&gt;runq = PROCESSOR_NULL;

		removed = TRUE;
	}

	rt_lock_unlock();

	<span class="enscript-keyword">return</span> (removed);
}

<span class="enscript-comment">/*
 * Put the thread back where it goes after a thread_run_queue_remove
 *
 * Thread must have been removed under the same thread lock hold
 *
 * thread locked, at splsched
 */</span>
<span class="enscript-type">void</span>
<span class="enscript-function-name">thread_run_queue_reinsert</span>(thread_t thread, integer_t options)
{
	assert(thread-&gt;runq == PROCESSOR_NULL);

		assert(thread-&gt;state &amp; (TH_RUN));
		thread_setrun(thread, options);

}

<span class="enscript-type">void</span>
<span class="enscript-function-name">sys_override_cpu_throttle</span>(<span class="enscript-type">int</span> flag)
{
	<span class="enscript-keyword">if</span> (flag == CPU_THROTTLE_ENABLE)
		cpu_throttle_enabled = 1;
	<span class="enscript-keyword">if</span> (flag == CPU_THROTTLE_DISABLE)
		cpu_throttle_enabled = 0;
}

<span class="enscript-type">int</span>
<span class="enscript-function-name">thread_get_urgency</span>(thread_t thread, uint64_t *arg1, uint64_t *arg2)
{
	<span class="enscript-keyword">if</span> (thread == NULL || (thread-&gt;state &amp; TH_IDLE)) {
		*arg1 = 0;
		*arg2 = 0;

		<span class="enscript-keyword">return</span> (THREAD_URGENCY_NONE);
	} <span class="enscript-keyword">else</span> <span class="enscript-keyword">if</span> (thread-&gt;sched_mode == TH_MODE_REALTIME) {
		*arg1 = thread-&gt;realtime.period;
		*arg2 = thread-&gt;realtime.deadline;

		<span class="enscript-keyword">return</span> (THREAD_URGENCY_REAL_TIME);
	} <span class="enscript-keyword">else</span> <span class="enscript-keyword">if</span> (cpu_throttle_enabled &amp;&amp;
		   ((thread-&gt;sched_pri &lt;= MAXPRI_THROTTLE) &amp;&amp; (thread-&gt;base_pri &lt;= MAXPRI_THROTTLE)))  {
		<span class="enscript-comment">/*
		 * Background urgency applied when thread priority is MAXPRI_THROTTLE or lower and thread is not promoted
		 * TODO: Use TH_SFLAG_THROTTLED instead?
		 */</span>
		*arg1 = thread-&gt;sched_pri;
		*arg2 = thread-&gt;base_pri;

		<span class="enscript-keyword">return</span> (THREAD_URGENCY_BACKGROUND);
	} <span class="enscript-keyword">else</span> {
		<span class="enscript-comment">/* For otherwise unclassified threads, report throughput QoS
		 * parameters
		 */</span>
		*arg1 = thread-&gt;effective_policy.t_through_qos;
		*arg2 = thread-&gt;task-&gt;effective_policy.t_through_qos;
		
		<span class="enscript-keyword">return</span> (THREAD_URGENCY_NORMAL);
	}
}


<span class="enscript-comment">/*
 *	This is the processor idle loop, which just looks for other threads
 *	to execute.  Processor idle threads invoke this without supplying a
 *	current thread to idle without an asserted wait state.
 *
 *	Returns a the next thread to execute if dispatched directly.
 */</span>

#<span class="enscript-reference">if</span> 0
#<span class="enscript-reference">define</span> <span class="enscript-function-name">IDLE_KERNEL_DEBUG_CONSTANT</span>(...) KERNEL_DEBUG_CONSTANT(__VA_ARGS__)
#<span class="enscript-reference">else</span>
#<span class="enscript-reference">define</span> <span class="enscript-function-name">IDLE_KERNEL_DEBUG_CONSTANT</span>(...) do { } while(0)
#<span class="enscript-reference">endif</span>

thread_t
<span class="enscript-function-name">processor_idle</span>(
	thread_t			thread,
	processor_t			processor)
{
	processor_set_t		pset = processor-&gt;processor_set;
	thread_t			new_thread;
	<span class="enscript-type">int</span>					state;
	(<span class="enscript-type">void</span>)splsched();

	KERNEL_DEBUG_CONSTANT_IST(KDEBUG_TRACE,
		MACHDBG_CODE(DBG_MACH_SCHED,MACH_IDLE) | DBG_FUNC_START, 
		(uintptr_t)thread_tid(thread), 0, 0, 0, 0);

	SCHED_STATS_CPU_IDLE_START(processor);

	timer_switch(&amp;PROCESSOR_DATA(processor, system_state),
									mach_absolute_time(), &amp;PROCESSOR_DATA(processor, idle_state));
	PROCESSOR_DATA(processor, current_state) = &amp;PROCESSOR_DATA(processor, idle_state);

	<span class="enscript-keyword">while</span> (1) {
		<span class="enscript-keyword">if</span> (processor-&gt;state != PROCESSOR_IDLE) <span class="enscript-comment">/* unsafe, but worst case we loop around once */</span>
			<span class="enscript-keyword">break</span>;
		<span class="enscript-keyword">if</span> (pset-&gt;pending_AST_cpu_mask &amp; (1ULL &lt;&lt; processor-&gt;cpu_id))
			<span class="enscript-keyword">break</span>;
		<span class="enscript-keyword">if</span> (processor-&gt;is_recommended) {
			<span class="enscript-keyword">if</span> (rt_runq.count)
				<span class="enscript-keyword">break</span>;
		} <span class="enscript-keyword">else</span> {
			<span class="enscript-keyword">if</span> (SCHED(processor_bound_count)(processor))
				<span class="enscript-keyword">break</span>;
		}

#<span class="enscript-reference">if</span> <span class="enscript-variable-name">CONFIG_SCHED_IDLE_IN_PLACE</span>
		<span class="enscript-keyword">if</span> (thread != THREAD_NULL) {
			<span class="enscript-comment">/* Did idle-in-place thread wake up */</span>
			<span class="enscript-keyword">if</span> ((thread-&gt;state &amp; (TH_WAIT|TH_SUSP)) != TH_WAIT || thread-&gt;wake_active)
				<span class="enscript-keyword">break</span>;
		}
#<span class="enscript-reference">endif</span>

		IDLE_KERNEL_DEBUG_CONSTANT(
			MACHDBG_CODE(DBG_MACH_SCHED,MACH_IDLE) | DBG_FUNC_NONE, (uintptr_t)thread_tid(thread), rt_runq.count, SCHED(processor_runq_count)(processor), -1, 0);

		machine_track_platform_idle(TRUE);

		machine_idle();

		machine_track_platform_idle(FALSE);

		(<span class="enscript-type">void</span>)splsched();

		IDLE_KERNEL_DEBUG_CONSTANT(
			MACHDBG_CODE(DBG_MACH_SCHED,MACH_IDLE) | DBG_FUNC_NONE, (uintptr_t)thread_tid(thread), rt_runq.count, SCHED(processor_runq_count)(processor), -2, 0);

		<span class="enscript-keyword">if</span> (!SCHED(processor_queue_empty)(processor)) {
			<span class="enscript-comment">/* Secondary SMT processors respond to directed wakeups
			 * exclusively. Some platforms induce 'spurious' SMT wakeups.
			 */</span>
			<span class="enscript-keyword">if</span> (processor-&gt;processor_primary == processor)
					<span class="enscript-keyword">break</span>;
		}
	}

	timer_switch(&amp;PROCESSOR_DATA(processor, idle_state),
									mach_absolute_time(), &amp;PROCESSOR_DATA(processor, system_state));
	PROCESSOR_DATA(processor, current_state) = &amp;PROCESSOR_DATA(processor, system_state);

	pset_lock(pset);

	<span class="enscript-comment">/* If we were sent a remote AST and came out of idle, acknowledge it here with pset lock held */</span>
	pset-&gt;pending_AST_cpu_mask &amp;= ~(1ULL &lt;&lt; processor-&gt;cpu_id);
#<span class="enscript-reference">if</span> <span class="enscript-reference">defined</span>(<span class="enscript-variable-name">CONFIG_SCHED_DEFERRED_AST</span>)
	pset-&gt;pending_deferred_AST_cpu_mask &amp;= ~(1ULL &lt;&lt; processor-&gt;cpu_id);
#<span class="enscript-reference">endif</span>

	state = processor-&gt;state;
	<span class="enscript-keyword">if</span> (state == PROCESSOR_DISPATCHING) {
		<span class="enscript-comment">/*
		 *	Commmon case -- cpu dispatched.
		 */</span>
		new_thread = processor-&gt;next_thread;
		processor-&gt;next_thread = THREAD_NULL;
		processor-&gt;state = PROCESSOR_RUNNING;

		<span class="enscript-keyword">if</span> ((new_thread != THREAD_NULL) &amp;&amp; (SCHED(processor_queue_has_priority)(processor, new_thread-&gt;sched_pri, FALSE)					||
											(rt_runq.count &gt; 0))	) {
   			<span class="enscript-comment">/* Something higher priority has popped up on the runqueue - redispatch this thread elsewhere */</span>
			processor-&gt;current_pri = IDLEPRI;
			processor-&gt;current_thmode = TH_MODE_FIXED;
			processor-&gt;current_sfi_class = SFI_CLASS_KERNEL;
			processor-&gt;deadline = UINT64_MAX;

			pset_unlock(pset);

			thread_lock(new_thread);
			KERNEL_DEBUG_CONSTANT(MACHDBG_CODE(DBG_MACH_SCHED, MACH_REDISPATCH), (uintptr_t)thread_tid(new_thread), new_thread-&gt;sched_pri, rt_runq.count, 0, 0);
			thread_setrun(new_thread, SCHED_HEADQ);
			thread_unlock(new_thread);

			KERNEL_DEBUG_CONSTANT_IST(KDEBUG_TRACE,
				MACHDBG_CODE(DBG_MACH_SCHED,MACH_IDLE) | DBG_FUNC_END, 
				(uintptr_t)thread_tid(thread), state, 0, 0, 0);

			<span class="enscript-keyword">return</span> (THREAD_NULL);
		}

		pset_unlock(pset);

		KERNEL_DEBUG_CONSTANT_IST(KDEBUG_TRACE,
			MACHDBG_CODE(DBG_MACH_SCHED,MACH_IDLE) | DBG_FUNC_END, 
			(uintptr_t)thread_tid(thread), state, (uintptr_t)thread_tid(new_thread), 0, 0);
			
		<span class="enscript-keyword">return</span> (new_thread);
	}
	<span class="enscript-keyword">else</span>
	<span class="enscript-keyword">if</span> (state == PROCESSOR_IDLE) {
		remqueue((queue_entry_t)processor);

		processor-&gt;state = PROCESSOR_RUNNING;
		processor-&gt;current_pri = IDLEPRI;
		processor-&gt;current_thmode = TH_MODE_FIXED;
		processor-&gt;current_sfi_class = SFI_CLASS_KERNEL;
		processor-&gt;deadline = UINT64_MAX;
		enqueue_tail(&amp;pset-&gt;active_queue, (queue_entry_t)processor);
	}
	<span class="enscript-keyword">else</span>
	<span class="enscript-keyword">if</span> (state == PROCESSOR_SHUTDOWN) {
		<span class="enscript-comment">/*
		 *	Going off-line.  Force a
		 *	reschedule.
		 */</span>
		<span class="enscript-keyword">if</span> ((new_thread = processor-&gt;next_thread) != THREAD_NULL) {
			processor-&gt;next_thread = THREAD_NULL;
			processor-&gt;current_pri = IDLEPRI;
			processor-&gt;current_thmode = TH_MODE_FIXED;
			processor-&gt;current_sfi_class = SFI_CLASS_KERNEL;
			processor-&gt;deadline = UINT64_MAX;

			pset_unlock(pset);

			thread_lock(new_thread);
			thread_setrun(new_thread, SCHED_HEADQ);
			thread_unlock(new_thread);

			KERNEL_DEBUG_CONSTANT_IST(KDEBUG_TRACE,
				MACHDBG_CODE(DBG_MACH_SCHED,MACH_IDLE) | DBG_FUNC_END, 
				(uintptr_t)thread_tid(thread), state, 0, 0, 0);
		
			<span class="enscript-keyword">return</span> (THREAD_NULL);
		}
	}

	pset_unlock(pset);

	KERNEL_DEBUG_CONSTANT_IST(KDEBUG_TRACE,
		MACHDBG_CODE(DBG_MACH_SCHED,MACH_IDLE) | DBG_FUNC_END, 
		(uintptr_t)thread_tid(thread), state, 0, 0, 0);
		
	<span class="enscript-keyword">return</span> (THREAD_NULL);
}

<span class="enscript-comment">/*
 *	Each processor has a dedicated thread which
 *	executes the idle loop when there is no suitable
 *	previous context.
 */</span>
<span class="enscript-type">void</span>
<span class="enscript-function-name">idle_thread</span>(<span class="enscript-type">void</span>)
{
	processor_t		processor = current_processor();
	thread_t		new_thread;

	new_thread = processor_idle(THREAD_NULL, processor);
	<span class="enscript-keyword">if</span> (new_thread != THREAD_NULL) {
		thread_run(processor-&gt;idle_thread, (thread_continue_t)idle_thread, NULL, new_thread);
		<span class="enscript-comment">/*NOTREACHED*/</span>
	}

	thread_block((thread_continue_t)idle_thread);
	<span class="enscript-comment">/*NOTREACHED*/</span>
}

kern_return_t
<span class="enscript-function-name">idle_thread_create</span>(
	processor_t		processor)
{
	kern_return_t	result;
	thread_t		thread;
	spl_t			s;

	result = kernel_thread_create((thread_continue_t)idle_thread, NULL, MAXPRI_KERNEL, &amp;thread);
	<span class="enscript-keyword">if</span> (result != KERN_SUCCESS)
		<span class="enscript-keyword">return</span> (result);

	s = splsched();
	thread_lock(thread);
	thread-&gt;bound_processor = processor;
	processor-&gt;idle_thread = thread;
	thread-&gt;sched_pri = thread-&gt;base_pri = IDLEPRI;
	thread-&gt;state = (TH_RUN | TH_IDLE);
	thread-&gt;options |= TH_OPT_IDLE_THREAD;
	thread_unlock(thread);
	splx(s);

	thread_deallocate(thread);

	<span class="enscript-keyword">return</span> (KERN_SUCCESS);
}

<span class="enscript-comment">/*
 * sched_startup:
 *
 * Kicks off scheduler services.
 *
 * Called at splsched.
 */</span>
<span class="enscript-type">void</span>
<span class="enscript-function-name">sched_startup</span>(<span class="enscript-type">void</span>)
{
	kern_return_t	result;
	thread_t		thread;

	simple_lock_init(&amp;sched_vm_group_list_lock, 0);

	result = kernel_thread_start_priority((thread_continue_t)sched_init_thread,
	    (<span class="enscript-type">void</span> *)SCHED(maintenance_continuation), MAXPRI_KERNEL, &amp;thread);
	<span class="enscript-keyword">if</span> (result != KERN_SUCCESS)
		panic(<span class="enscript-string">&quot;sched_startup&quot;</span>);

	thread_deallocate(thread);

	<span class="enscript-comment">/*
	 * Yield to the sched_init_thread once, to
	 * initialize our own thread after being switched
	 * back to.
	 *
	 * The current thread is the only other thread
	 * active at this point.
	 */</span>
	thread_block(THREAD_CONTINUE_NULL);
}

#<span class="enscript-reference">if</span> <span class="enscript-reference">defined</span>(<span class="enscript-variable-name">CONFIG_SCHED_TIMESHARE_CORE</span>)

<span class="enscript-type">static</span> <span class="enscript-type">volatile</span> uint64_t 		sched_maintenance_deadline;
#<span class="enscript-reference">if</span> <span class="enscript-reference">defined</span>(<span class="enscript-variable-name">CONFIG_TELEMETRY</span>)
<span class="enscript-type">static</span> <span class="enscript-type">volatile</span> uint64_t		sched_telemetry_deadline = 0;
#<span class="enscript-reference">endif</span>
<span class="enscript-type">static</span> uint64_t				sched_tick_last_abstime;
<span class="enscript-type">static</span> uint64_t				sched_tick_delta;
uint64_t				sched_tick_max_delta;
<span class="enscript-comment">/*
 *	sched_init_thread:
 *
 *	Perform periodic bookkeeping functions about ten
 *	times per second.
 */</span>
<span class="enscript-type">void</span>
<span class="enscript-function-name">sched_timeshare_maintenance_continue</span>(<span class="enscript-type">void</span>)
{
	uint64_t	sched_tick_ctime, late_time;

	<span class="enscript-type">struct</span> sched_update_scan_context scan_context = {
		.earliest_bg_make_runnable_time = UINT64_MAX,
		.earliest_normal_make_runnable_time = UINT64_MAX,
		.earliest_rt_make_runnable_time = UINT64_MAX
	};

	sched_tick_ctime = mach_absolute_time();	

	<span class="enscript-keyword">if</span> (__improbable(sched_tick_last_abstime == 0)) {
		sched_tick_last_abstime = sched_tick_ctime;
		late_time = 0;
		sched_tick_delta = 1;
	} <span class="enscript-keyword">else</span> {
		late_time = sched_tick_ctime - sched_tick_last_abstime;
		sched_tick_delta = late_time / sched_tick_interval;
		<span class="enscript-comment">/* Ensure a delta of 1, since the interval could be slightly
		 * smaller than the sched_tick_interval due to dispatch
		 * latencies.
		 */</span>
		sched_tick_delta = MAX(sched_tick_delta, 1);

		<span class="enscript-comment">/* In the event interrupt latencies or platform
		 * idle events that advanced the timebase resulted
		 * in periods where no threads were dispatched,
		 * cap the maximum &quot;tick delta&quot; at SCHED_TICK_MAX_DELTA
		 * iterations.
		 */</span>
		sched_tick_delta = MIN(sched_tick_delta, SCHED_TICK_MAX_DELTA);

		sched_tick_last_abstime = sched_tick_ctime;
		sched_tick_max_delta = MAX(sched_tick_delta, sched_tick_max_delta);
	}

	KERNEL_DEBUG_CONSTANT(MACHDBG_CODE(DBG_MACH_SCHED, MACH_SCHED_MAINTENANCE)|DBG_FUNC_START,
						  sched_tick_delta,
						  late_time,
						  0,
						  0,
						  0);

	<span class="enscript-comment">/* Add a number of pseudo-ticks corresponding to the elapsed interval
	 * This could be greater than 1 if substantial intervals where
	 * all processors are idle occur, which rarely occurs in practice.
	 */</span>
	
	sched_tick += sched_tick_delta;

	<span class="enscript-comment">/*
	 *  Compute various averages.
	 */</span>
	compute_averages(sched_tick_delta);

	<span class="enscript-comment">/*
	 *  Scan the run queues for threads which
	 *  may need to be updated.
	 */</span>
	SCHED(thread_update_scan)(&amp;scan_context);

	rt_runq_scan(&amp;scan_context);

	uint64_t ctime = mach_absolute_time();

	machine_max_runnable_latency(ctime &gt; scan_context.earliest_bg_make_runnable_time ? ctime - scan_context.earliest_bg_make_runnable_time : 0,
								 ctime &gt; scan_context.earliest_normal_make_runnable_time ? ctime - scan_context.earliest_normal_make_runnable_time : 0,
								 ctime &gt; scan_context.earliest_rt_make_runnable_time ? ctime - scan_context.earliest_rt_make_runnable_time : 0);

	<span class="enscript-comment">/*
	 * Check to see if the special sched VM group needs attention.
	 */</span>
	sched_vm_group_maintenance();

	KERNEL_DEBUG_CONSTANT(MACHDBG_CODE(DBG_MACH_SCHED, MACH_SCHED_MAINTENANCE)|DBG_FUNC_END,
						  sched_pri_shift,
						  sched_background_pri_shift,
						  0,
						  0,
						  0);

	assert_wait((event_t)sched_timeshare_maintenance_continue, THREAD_UNINT);
	thread_block((thread_continue_t)sched_timeshare_maintenance_continue);
	<span class="enscript-comment">/*NOTREACHED*/</span>
}

<span class="enscript-type">static</span> uint64_t sched_maintenance_wakeups;

<span class="enscript-comment">/*
 * Determine if the set of routines formerly driven by a maintenance timer
 * must be invoked, based on a deadline comparison. Signals the scheduler
 * maintenance thread on deadline expiration. Must be invoked at an interval
 * lower than the &quot;sched_tick_interval&quot;, currently accomplished by
 * invocation via the quantum expiration timer and at context switch time.
 * Performance matters: this routine reuses a timestamp approximating the
 * current absolute time received from the caller, and should perform
 * no more than a comparison against the deadline in the common case.
 */</span>
<span class="enscript-type">void</span>
<span class="enscript-function-name">sched_timeshare_consider_maintenance</span>(uint64_t ctime) {
	uint64_t ndeadline, deadline = sched_maintenance_deadline;

	<span class="enscript-keyword">if</span> (__improbable(ctime &gt;= deadline)) {
		<span class="enscript-keyword">if</span> (__improbable(current_thread() == sched_maintenance_thread))
			<span class="enscript-keyword">return</span>;
		OSMemoryBarrier();

		ndeadline = ctime + sched_tick_interval;

		<span class="enscript-keyword">if</span> (__probable(__sync_bool_compare_and_swap(&amp;sched_maintenance_deadline, deadline, ndeadline))) {
			thread_wakeup((event_t)sched_timeshare_maintenance_continue);
			sched_maintenance_wakeups++;
		}
	}

#<span class="enscript-reference">if</span> <span class="enscript-reference">defined</span>(<span class="enscript-variable-name">CONFIG_TELEMETRY</span>)
	<span class="enscript-comment">/*
	 * Windowed telemetry is driven by the scheduler.  It should be safe
	 * to call compute_telemetry_windowed() even when windowed telemetry
	 * is disabled, but we should try to avoid doing extra work for no
	 * reason.
	 */</span>
	<span class="enscript-keyword">if</span> (telemetry_window_enabled) {
		deadline = sched_telemetry_deadline;

		<span class="enscript-keyword">if</span> (__improbable(ctime &gt;= deadline)) {
			ndeadline = ctime + sched_telemetry_interval;

			<span class="enscript-keyword">if</span> (__probable(__sync_bool_compare_and_swap(&amp;sched_telemetry_deadline, deadline, ndeadline))) {
				compute_telemetry_windowed();
			}
		}
	}
#<span class="enscript-reference">endif</span> <span class="enscript-comment">/* CONFIG_TELEMETRY */</span>
}

#<span class="enscript-reference">endif</span> <span class="enscript-comment">/* CONFIG_SCHED_TIMESHARE_CORE */</span>

<span class="enscript-type">void</span>
<span class="enscript-function-name">sched_init_thread</span>(<span class="enscript-type">void</span> (*continuation)(<span class="enscript-type">void</span>))
{
	thread_block(THREAD_CONTINUE_NULL);

	sched_maintenance_thread = current_thread();
	continuation();

	<span class="enscript-comment">/*NOTREACHED*/</span>
}

#<span class="enscript-reference">if</span> <span class="enscript-reference">defined</span>(<span class="enscript-variable-name">CONFIG_SCHED_TIMESHARE_CORE</span>)

<span class="enscript-comment">/*
 *	thread_update_scan / runq_scan:
 *
 *	Scan the run queues to account for timesharing threads 
 *	which need to be updated.
 *
 *	Scanner runs in two passes.  Pass one squirrels likely
 *	threads away in an array, pass two does the update.
 *
 *	This is necessary because the run queue is locked for
 *	the candidate scan, but	the thread is locked for the update.
 *
 *	Array should be sized to make forward progress, without
 *	disabling preemption for long periods.
 */</span>

#<span class="enscript-reference">define</span>	<span class="enscript-variable-name">THREAD_UPDATE_SIZE</span>		128

<span class="enscript-type">static</span> thread_t		thread_update_array[THREAD_UPDATE_SIZE];
<span class="enscript-type">static</span> <span class="enscript-type">int</span>			thread_update_count = 0;

<span class="enscript-comment">/* Returns TRUE if thread was added, FALSE if thread_update_array is full */</span>
boolean_t
<span class="enscript-function-name">thread_update_add_thread</span>(thread_t thread)
{
	<span class="enscript-keyword">if</span> (thread_update_count == THREAD_UPDATE_SIZE)
		<span class="enscript-keyword">return</span> (FALSE);

	thread_update_array[thread_update_count++] = thread;
	thread_reference_internal(thread);
	<span class="enscript-keyword">return</span> (TRUE);
}

<span class="enscript-type">void</span>
<span class="enscript-function-name">thread_update_process_threads</span>(<span class="enscript-type">void</span>)
{
	<span class="enscript-keyword">while</span> (thread_update_count &gt; 0) {
		spl_t   s;
		thread_t thread = thread_update_array[--thread_update_count];
		thread_update_array[thread_update_count] = THREAD_NULL;

		s = splsched();
		thread_lock(thread);
		<span class="enscript-keyword">if</span> (!(thread-&gt;state &amp; (TH_WAIT)) &amp;&amp; (SCHED(can_update_priority)(thread))) {
			SCHED(update_priority)(thread);
		}
		thread_unlock(thread);
		splx(s);

		thread_deallocate(thread);
	}
}

<span class="enscript-comment">/*
 *	Scan a runq for candidate threads.
 *
 *	Returns TRUE if retry is needed.
 */</span>
boolean_t
<span class="enscript-function-name">runq_scan</span>(
	run_queue_t				runq,
	sched_update_scan_context_t	scan_context)
{
	<span class="enscript-type">register</span> <span class="enscript-type">int</span>			count;
	<span class="enscript-type">register</span> queue_t		q;
	<span class="enscript-type">register</span> thread_t		thread;

	<span class="enscript-keyword">if</span> ((count = runq-&gt;count) &gt; 0) {
	    q = runq-&gt;queues + runq-&gt;highq;
		<span class="enscript-keyword">while</span> (count &gt; 0) {
			queue_iterate(q, thread, thread_t, links) {
				<span class="enscript-keyword">if</span> (		thread-&gt;sched_stamp != sched_tick		&amp;&amp;
						(thread-&gt;sched_mode == TH_MODE_TIMESHARE)	) {
					<span class="enscript-keyword">if</span> (thread_update_add_thread(thread) == FALSE)
						<span class="enscript-keyword">return</span> (TRUE);
				}

				<span class="enscript-keyword">if</span> (cpu_throttle_enabled &amp;&amp; ((thread-&gt;sched_pri &lt;= MAXPRI_THROTTLE) &amp;&amp; (thread-&gt;base_pri &lt;= MAXPRI_THROTTLE))) {
					<span class="enscript-keyword">if</span> (thread-&gt;last_made_runnable_time &lt; scan_context-&gt;earliest_bg_make_runnable_time) {
						scan_context-&gt;earliest_bg_make_runnable_time = thread-&gt;last_made_runnable_time;
					}
				} <span class="enscript-keyword">else</span> {
					<span class="enscript-keyword">if</span> (thread-&gt;last_made_runnable_time &lt; scan_context-&gt;earliest_normal_make_runnable_time) {
						scan_context-&gt;earliest_normal_make_runnable_time = thread-&gt;last_made_runnable_time;
					}
				}

				count--;
			}

			q--;
		}
	}

	<span class="enscript-keyword">return</span> (FALSE);
}

#<span class="enscript-reference">endif</span> <span class="enscript-comment">/* CONFIG_SCHED_TIMESHARE_CORE */</span>

boolean_t
<span class="enscript-function-name">thread_eager_preemption</span>(thread_t thread) 
{
	<span class="enscript-keyword">return</span> ((thread-&gt;sched_flags &amp; TH_SFLAG_EAGERPREEMPT) != 0);
}

<span class="enscript-type">void</span>
<span class="enscript-function-name">thread_set_eager_preempt</span>(thread_t thread) 
{
	spl_t x;
	processor_t p;
	ast_t ast = AST_NONE;

	x = splsched();
	p = current_processor();

	thread_lock(thread);
	thread-&gt;sched_flags |= TH_SFLAG_EAGERPREEMPT;

	<span class="enscript-keyword">if</span> (thread == current_thread()) {

		ast = csw_check(p, AST_NONE);
		thread_unlock(thread);
		<span class="enscript-keyword">if</span> (ast != AST_NONE) {
			(<span class="enscript-type">void</span>) thread_block_reason(THREAD_CONTINUE_NULL, NULL, ast);
		}
	} <span class="enscript-keyword">else</span> {
		p = thread-&gt;last_processor;

		<span class="enscript-keyword">if</span> (p != PROCESSOR_NULL	&amp;&amp; p-&gt;state == PROCESSOR_RUNNING &amp;&amp;
			p-&gt;active_thread == thread) {
			cause_ast_check(p);
		}
		
		thread_unlock(thread);
	}

	splx(x);
}

<span class="enscript-type">void</span>
<span class="enscript-function-name">thread_clear_eager_preempt</span>(thread_t thread) 
{
	spl_t x;

	x = splsched();
	thread_lock(thread);

	thread-&gt;sched_flags &amp;= ~TH_SFLAG_EAGERPREEMPT;
	
	thread_unlock(thread);
	splx(x);
}

<span class="enscript-comment">/*
 * Scheduling statistics
 */</span>
<span class="enscript-type">void</span>
<span class="enscript-function-name">sched_stats_handle_csw</span>(processor_t processor, <span class="enscript-type">int</span> reasons, <span class="enscript-type">int</span> selfpri, <span class="enscript-type">int</span> otherpri)
{
	<span class="enscript-type">struct</span> processor_sched_statistics *stats;
	boolean_t to_realtime = FALSE;
	
	stats = &amp;processor-&gt;processor_data.sched_stats;
	stats-&gt;csw_count++;

	<span class="enscript-keyword">if</span> (otherpri &gt;= BASEPRI_REALTIME) {
		stats-&gt;rt_sched_count++;
		to_realtime = TRUE;
	}

	<span class="enscript-keyword">if</span> ((reasons &amp; AST_PREEMPT) != 0) {
		stats-&gt;preempt_count++;

		<span class="enscript-keyword">if</span> (selfpri &gt;= BASEPRI_REALTIME) {
			stats-&gt;preempted_rt_count++;
		} 

		<span class="enscript-keyword">if</span> (to_realtime) {
			stats-&gt;preempted_by_rt_count++;
		}

	}
}

<span class="enscript-type">void</span>
<span class="enscript-function-name">sched_stats_handle_runq_change</span>(<span class="enscript-type">struct</span> runq_stats *stats, <span class="enscript-type">int</span> old_count) 
{
	uint64_t timestamp = mach_absolute_time();

	stats-&gt;count_sum += (timestamp - stats-&gt;last_change_timestamp) * old_count;
	stats-&gt;last_change_timestamp = timestamp;
}

<span class="enscript-comment">/*
 *     For calls from assembly code
 */</span>
#<span class="enscript-reference">undef</span> <span class="enscript-variable-name">thread_wakeup</span>
<span class="enscript-type">void</span>
<span class="enscript-function-name">thread_wakeup</span>(
       event_t         x);

<span class="enscript-type">void</span>
<span class="enscript-function-name">thread_wakeup</span>(
       event_t         x)
{
       thread_wakeup_with_result(x, THREAD_AWAKENED);
}

boolean_t
<span class="enscript-function-name">preemption_enabled</span>(<span class="enscript-type">void</span>)
{
	<span class="enscript-keyword">return</span> (get_preemption_level() == 0 &amp;&amp; ml_get_interrupts_enabled());
}

<span class="enscript-type">static</span> <span class="enscript-type">void</span>
<span class="enscript-function-name">sched_timer_deadline_tracking_init</span>(<span class="enscript-type">void</span>) {
	nanoseconds_to_absolutetime(TIMER_DEADLINE_TRACKING_BIN_1_DEFAULT, &amp;timer_deadline_tracking_bin_1);
	nanoseconds_to_absolutetime(TIMER_DEADLINE_TRACKING_BIN_2_DEFAULT, &amp;timer_deadline_tracking_bin_2);
}


kern_return_t
<span class="enscript-function-name">sched_work_interval_notify</span>(thread_t thread, uint64_t work_interval_id, uint64_t start, uint64_t finish, uint64_t deadline, uint64_t next_start, uint32_t flags)
{
	<span class="enscript-type">int</span> urgency;
	uint64_t urgency_param1, urgency_param2;
	spl_t s;

	<span class="enscript-keyword">if</span> (work_interval_id == 0) {
		<span class="enscript-keyword">return</span> (KERN_INVALID_ARGUMENT);
	}

	assert(thread == current_thread());

	thread_mtx_lock(thread);
	<span class="enscript-keyword">if</span> (thread-&gt;work_interval_id != work_interval_id) {
		thread_mtx_unlock(thread);
		<span class="enscript-keyword">return</span> (KERN_INVALID_ARGUMENT);
	}
	thread_mtx_unlock(thread);

	s = splsched();
	thread_lock(thread);
	urgency = thread_get_urgency(thread, &amp;urgency_param1, &amp;urgency_param2);
	thread_unlock(thread);
	splx(s);

	machine_work_interval_notify(thread, work_interval_id, start, finish, deadline, next_start, urgency, flags);
	<span class="enscript-keyword">return</span> (KERN_SUCCESS);
}

<span class="enscript-type">void</span> <span class="enscript-function-name">thread_set_options</span>(uint32_t thopt) {
 	spl_t x;
 	thread_t t = current_thread();
 
 	x = splsched();
 	thread_lock(t);
 
 	t-&gt;options |= thopt;
 
 	thread_unlock(t);
 	splx(x);
}
</pre>
<hr />
</body></html>