<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
    "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
<title>pmap.c</title>
<style type="text/css">
.enscript-comment { font-style: italic; color: rgb(178,34,34); }
.enscript-function-name { font-weight: bold; color: rgb(0,0,255); }
.enscript-variable-name { font-weight: bold; color: rgb(184,134,11); }
.enscript-keyword { font-weight: bold; color: rgb(160,32,240); }
.enscript-reference { font-weight: bold; color: rgb(95,158,160); }
.enscript-string { font-weight: bold; color: rgb(188,143,143); }
.enscript-builtin { font-weight: bold; color: rgb(218,112,214); }
.enscript-type { font-weight: bold; color: rgb(34,139,34); }
.enscript-highlight { text-decoration: underline; color: 0; }
</style>
</head>
<body id="top">
<h1 style="margin:8px;" id="f1">pmap.c&nbsp;&nbsp;&nbsp;<span style="font-weight: normal; font-size: 0.5em;">[<a href="?txt">plain text</a>]</span></h1>
<hr/>
<div></div>
<pre>
<span class="enscript-comment">/*
 * Copyright (c) 2000-2010 Apple Inc. All rights reserved.
 *
 * @APPLE_OSREFERENCE_LICENSE_HEADER_START@
 * 
 * This file contains Original Code and/or Modifications of Original Code
 * as defined in and that are subject to the Apple Public Source License
 * Version 2.0 (the 'License'). You may not use this file except in
 * compliance with the License. The rights granted to you under the License
 * may not be used to create, or enable the creation or redistribution of,
 * unlawful or unlicensed copies of an Apple operating system, or to
 * circumvent, violate, or enable the circumvention or violation of, any
 * terms of an Apple operating system software license agreement.
 * 
 * Please obtain a copy of the License at
 * <a href="http://www.opensource.apple.com/apsl/">http://www.opensource.apple.com/apsl/</a> and read it before using this file.
 * 
 * The Original Code and all software distributed under the License are
 * distributed on an 'AS IS' basis, WITHOUT WARRANTY OF ANY KIND, EITHER
 * EXPRESS OR IMPLIED, AND APPLE HEREBY DISCLAIMS ALL SUCH WARRANTIES,
 * INCLUDING WITHOUT LIMITATION, ANY WARRANTIES OF MERCHANTABILITY,
 * FITNESS FOR A PARTICULAR PURPOSE, QUIET ENJOYMENT OR NON-INFRINGEMENT.
 * Please see the License for the specific language governing rights and
 * limitations under the License.
 * 
 * @APPLE_OSREFERENCE_LICENSE_HEADER_END@
 */</span>
<span class="enscript-comment">/*
 * @OSF_COPYRIGHT@
 */</span>
<span class="enscript-comment">/*
 * Mach Operating System
 * Copyright (c) 1991,1990,1989,1988 Carnegie Mellon University
 * All Rights Reserved.
 * 
 * Permission to use, copy, modify and distribute this software and its
 * documentation is hereby granted, provided that both the copyright
 * notice and this permission notice appear in all copies of the
 * software, derivative works or modified versions, and any portions
 * thereof, and that both notices appear in supporting documentation.
 * 
 * CARNEGIE MELLON ALLOWS FREE USE OF THIS SOFTWARE IN ITS &quot;AS IS&quot;
 * CONDITION.  CARNEGIE MELLON DISCLAIMS ANY LIABILITY OF ANY KIND FOR
 * ANY DAMAGES WHATSOEVER RESULTING FROM THE USE OF THIS SOFTWARE.
 * 
 * Carnegie Mellon requests users of this software to return to
 * 
 *  Software Distribution Coordinator  or  <a href="mailto:Software.Distribution@CS.CMU.EDU">Software.Distribution@CS.CMU.EDU</a>
 *  School of Computer Science
 *  Carnegie Mellon University
 *  Pittsburgh PA 15213-3890
 * 
 * any improvements or extensions that they make and grant Carnegie Mellon
 * the rights to redistribute these changes.
 */</span>
<span class="enscript-comment">/*
 */</span>

<span class="enscript-comment">/*
 *	File:	pmap.c
 *	Author:	Avadis Tevanian, Jr., Michael Wayne Young
 *	(These guys wrote the Vax version)
 *
 *	Physical Map management code for Intel i386, i486, and i860.
 *
 *	Manages physical address maps.
 *
 *	In addition to hardware address maps, this
 *	module is called upon to provide software-use-only
 *	maps which may or may not be stored in the same
 *	form as hardware maps.  These pseudo-maps are
 *	used to store intermediate results from copy
 *	operations to and from address spaces.
 *
 *	Since the information managed by this module is
 *	also stored by the logical address mapping module,
 *	this module may throw away valid virtual-to-physical
 *	mappings at almost any time.  However, invalidations
 *	of virtual-to-physical mappings must be done as
 *	requested.
 *
 *	In order to cope with hardware architectures which
 *	make virtual-to-physical map invalidates expensive,
 *	this module may delay invalidate or reduced protection
 *	operations until such time as they are actually
 *	necessary.  This module is given full information as
 *	to which processors are currently using which maps,
 *	and to when physical maps must be made correct.
 */</span>

#<span class="enscript-reference">include</span> <span class="enscript-string">&lt;string.h&gt;</span>
#<span class="enscript-reference">include</span> <span class="enscript-string">&lt;mach_ldebug.h&gt;</span>

#<span class="enscript-reference">include</span> <span class="enscript-string">&lt;libkern/OSAtomic.h&gt;</span>

#<span class="enscript-reference">include</span> <span class="enscript-string">&lt;mach/machine/vm_types.h&gt;</span>

#<span class="enscript-reference">include</span> <span class="enscript-string">&lt;mach/boolean.h&gt;</span>
#<span class="enscript-reference">include</span> <span class="enscript-string">&lt;kern/thread.h&gt;</span>
#<span class="enscript-reference">include</span> <span class="enscript-string">&lt;kern/zalloc.h&gt;</span>
#<span class="enscript-reference">include</span> <span class="enscript-string">&lt;kern/queue.h&gt;</span>
#<span class="enscript-reference">include</span> <span class="enscript-string">&lt;kern/ledger.h&gt;</span>
#<span class="enscript-reference">include</span> <span class="enscript-string">&lt;kern/mach_param.h&gt;</span>

#<span class="enscript-reference">include</span> <span class="enscript-string">&lt;kern/kalloc.h&gt;</span>
#<span class="enscript-reference">include</span> <span class="enscript-string">&lt;kern/spl.h&gt;</span>

#<span class="enscript-reference">include</span> <span class="enscript-string">&lt;vm/pmap.h&gt;</span>
#<span class="enscript-reference">include</span> <span class="enscript-string">&lt;vm/vm_map.h&gt;</span>
#<span class="enscript-reference">include</span> <span class="enscript-string">&lt;vm/vm_kern.h&gt;</span>
#<span class="enscript-reference">include</span> <span class="enscript-string">&lt;mach/vm_param.h&gt;</span>
#<span class="enscript-reference">include</span> <span class="enscript-string">&lt;mach/vm_prot.h&gt;</span>
#<span class="enscript-reference">include</span> <span class="enscript-string">&lt;vm/vm_object.h&gt;</span>
#<span class="enscript-reference">include</span> <span class="enscript-string">&lt;vm/vm_page.h&gt;</span>

#<span class="enscript-reference">include</span> <span class="enscript-string">&lt;mach/machine/vm_param.h&gt;</span>
#<span class="enscript-reference">include</span> <span class="enscript-string">&lt;machine/thread.h&gt;</span>

#<span class="enscript-reference">include</span> <span class="enscript-string">&lt;kern/misc_protos.h&gt;</span>			<span class="enscript-comment">/* prototyping */</span>
#<span class="enscript-reference">include</span> <span class="enscript-string">&lt;i386/misc_protos.h&gt;</span>
#<span class="enscript-reference">include</span> <span class="enscript-string">&lt;i386/i386_lowmem.h&gt;</span>
#<span class="enscript-reference">include</span> <span class="enscript-string">&lt;x86_64/lowglobals.h&gt;</span>

#<span class="enscript-reference">include</span> <span class="enscript-string">&lt;i386/cpuid.h&gt;</span>
#<span class="enscript-reference">include</span> <span class="enscript-string">&lt;i386/cpu_data.h&gt;</span>
#<span class="enscript-reference">include</span> <span class="enscript-string">&lt;i386/cpu_number.h&gt;</span>
#<span class="enscript-reference">include</span> <span class="enscript-string">&lt;i386/machine_cpu.h&gt;</span>
#<span class="enscript-reference">include</span> <span class="enscript-string">&lt;i386/seg.h&gt;</span>
#<span class="enscript-reference">include</span> <span class="enscript-string">&lt;i386/serial_io.h&gt;</span>
#<span class="enscript-reference">include</span> <span class="enscript-string">&lt;i386/cpu_capabilities.h&gt;</span>
#<span class="enscript-reference">include</span> <span class="enscript-string">&lt;i386/machine_routines.h&gt;</span>
#<span class="enscript-reference">include</span> <span class="enscript-string">&lt;i386/proc_reg.h&gt;</span>
#<span class="enscript-reference">include</span> <span class="enscript-string">&lt;i386/tsc.h&gt;</span>
#<span class="enscript-reference">include</span> <span class="enscript-string">&lt;i386/pmap_internal.h&gt;</span>
#<span class="enscript-reference">include</span> <span class="enscript-string">&lt;i386/pmap_pcid.h&gt;</span>
#<span class="enscript-reference">if</span> <span class="enscript-variable-name">CONFIG_VMX</span>
#<span class="enscript-reference">include</span> <span class="enscript-string">&lt;i386/vmx/vmx_cpu.h&gt;</span>
#<span class="enscript-reference">endif</span>

#<span class="enscript-reference">include</span> <span class="enscript-string">&lt;vm/vm_protos.h&gt;</span>

#<span class="enscript-reference">include</span> <span class="enscript-string">&lt;i386/mp.h&gt;</span>
#<span class="enscript-reference">include</span> <span class="enscript-string">&lt;i386/mp_desc.h&gt;</span>
#<span class="enscript-reference">include</span> <span class="enscript-string">&lt;libkern/kernel_mach_header.h&gt;</span>

#<span class="enscript-reference">include</span> <span class="enscript-string">&lt;pexpert/i386/efi.h&gt;</span>


#<span class="enscript-reference">ifdef</span> <span class="enscript-variable-name">IWANTTODEBUG</span>
#<span class="enscript-reference">undef</span>	<span class="enscript-variable-name">DEBUG</span>
#<span class="enscript-reference">define</span> <span class="enscript-variable-name">DEBUG</span> 1
#<span class="enscript-reference">define</span> <span class="enscript-variable-name">POSTCODE_DELAY</span> 1
#<span class="enscript-reference">include</span> <span class="enscript-string">&lt;i386/postcode.h&gt;</span>
#<span class="enscript-reference">endif</span> <span class="enscript-comment">/* IWANTTODEBUG */</span>

#<span class="enscript-reference">ifdef</span>	<span class="enscript-variable-name">PMAP_DEBUG</span>
#<span class="enscript-reference">define</span> <span class="enscript-function-name">DBG</span>(x...)	kprintf(<span class="enscript-string">&quot;DBG: &quot;</span> x)
#<span class="enscript-reference">else</span>
#<span class="enscript-reference">define</span> <span class="enscript-function-name">DBG</span>(x...)
#<span class="enscript-reference">endif</span>
<span class="enscript-comment">/* Compile time assert to ensure adjacency/alignment of per-CPU data fields used
 * in the trampolines for kernel/user boundary TLB coherency.
 */</span>
<span class="enscript-type">char</span> pmap_cpu_data_assert[(((offsetof(cpu_data_t, cpu_tlb_invalid) - offsetof(cpu_data_t, cpu_active_cr3)) == 8) &amp;&amp; (offsetof(cpu_data_t, cpu_active_cr3) % 64 == 0)) ? 1 : -1];
boolean_t pmap_trace = FALSE;

boolean_t	no_shared_cr3 = DEBUG;		<span class="enscript-comment">/* TRUE for DEBUG by default */</span>

<span class="enscript-type">int</span> nx_enabled = 1;			<span class="enscript-comment">/* enable no-execute protection */</span>
<span class="enscript-type">int</span> allow_data_exec  = VM_ABI_32;	<span class="enscript-comment">/* 32-bit apps may execute data by default, 64-bit apps may not */</span>
<span class="enscript-type">int</span> allow_stack_exec = 0;		<span class="enscript-comment">/* No apps may execute from the stack by default */</span>

<span class="enscript-type">const</span> boolean_t cpu_64bit  = TRUE; <span class="enscript-comment">/* Mais oui! */</span>

uint64_t max_preemption_latency_tsc = 0;

pv_hashed_entry_t     *pv_hash_table;  <span class="enscript-comment">/* hash lists */</span>

uint32_t npvhashmask = 0, npvhashbuckets = 0;

pv_hashed_entry_t	pv_hashed_free_list = PV_HASHED_ENTRY_NULL;
pv_hashed_entry_t	pv_hashed_kern_free_list = PV_HASHED_ENTRY_NULL;
<span class="enscript-function-name">decl_simple_lock_data</span>(,pv_hashed_free_list_lock)
<span class="enscript-function-name">decl_simple_lock_data</span>(,pv_hashed_kern_free_list_lock)
<span class="enscript-function-name">decl_simple_lock_data</span>(,pv_hash_table_lock)

<span class="enscript-function-name">decl_simple_lock_data</span>(,phys_backup_lock)

zone_t		pv_hashed_list_zone;	<span class="enscript-comment">/* zone of pv_hashed_entry structures */</span>

<span class="enscript-comment">/*
 *	First and last physical addresses that we maintain any information
 *	for.  Initialized to zero so that pmap operations done before
 *	pmap_init won't touch any non-existent structures.
 */</span>
boolean_t	pmap_initialized = FALSE;<span class="enscript-comment">/* Has pmap_init completed? */</span>

<span class="enscript-type">static</span> <span class="enscript-type">struct</span> vm_object kptobj_object_store;
<span class="enscript-type">static</span> <span class="enscript-type">struct</span> vm_object kpml4obj_object_store;
<span class="enscript-type">static</span> <span class="enscript-type">struct</span> vm_object kpdptobj_object_store;

<span class="enscript-comment">/*
 *	Array of physical page attribites for managed pages.
 *	One byte per physical page.
 */</span>
<span class="enscript-type">char</span>		*pmap_phys_attributes;
ppnum_t		last_managed_page = 0;

<span class="enscript-comment">/*
 *	Amount of virtual memory mapped by one
 *	page-directory entry.
 */</span>

uint64_t pde_mapped_size = PDE_MAPPED_SIZE;

<span class="enscript-type">unsigned</span> pmap_memory_region_count;
<span class="enscript-type">unsigned</span> pmap_memory_region_current;

pmap_memory_region_t pmap_memory_regions[PMAP_MEMORY_REGIONS_SIZE];

<span class="enscript-comment">/*
 *	Other useful macros.
 */</span>
#<span class="enscript-reference">define</span> <span class="enscript-function-name">current_pmap</span>()		(vm_map_pmap(current_thread()-&gt;map))

<span class="enscript-type">struct</span> pmap	kernel_pmap_store;
pmap_t		kernel_pmap;

<span class="enscript-type">struct</span> zone	*pmap_zone;		<span class="enscript-comment">/* zone of pmap structures */</span>

<span class="enscript-type">struct</span> zone	*pmap_anchor_zone;
<span class="enscript-type">int</span>		pmap_debug = 0;		<span class="enscript-comment">/* flag for debugging prints */</span>

<span class="enscript-type">unsigned</span> <span class="enscript-type">int</span>	inuse_ptepages_count = 0;
<span class="enscript-type">long</span> <span class="enscript-type">long</span>	alloc_ptepages_count __attribute__((aligned(8))) = 0; <span class="enscript-comment">/* aligned for atomic access */</span>
<span class="enscript-type">unsigned</span> <span class="enscript-type">int</span>	bootstrap_wired_pages = 0;
<span class="enscript-type">int</span>		pt_fake_zone_index = -1;

<span class="enscript-type">extern</span> 	<span class="enscript-type">long</span>	NMIPI_acks;

boolean_t	kernel_text_ps_4K = TRUE;
boolean_t	wpkernel = TRUE;

<span class="enscript-type">extern</span> <span class="enscript-type">char</span>	end;

<span class="enscript-type">static</span> <span class="enscript-type">int</span>	nkpt;

pt_entry_t     *DMAP1, *DMAP2;
caddr_t         DADDR1;
caddr_t         DADDR2;

boolean_t	pmap_disable_kheap_nx = FALSE;
boolean_t	pmap_disable_kstack_nx = FALSE;
<span class="enscript-type">extern</span> boolean_t doconstro_override;

<span class="enscript-type">extern</span> <span class="enscript-type">long</span> __stack_chk_guard[];

boolean_t pmap_ept_support_ad = FALSE;


<span class="enscript-comment">/*
 *	Map memory at initialization.  The physical addresses being
 *	mapped are not managed and are never unmapped.
 *
 *	For now, VM is already on, we only need to map the
 *	specified memory.
 */</span>
vm_offset_t
<span class="enscript-function-name">pmap_map</span>(
	vm_offset_t	virt,
	vm_map_offset_t	start_addr,
	vm_map_offset_t	end_addr,
	vm_prot_t	prot,
	<span class="enscript-type">unsigned</span> <span class="enscript-type">int</span>	flags)
{
	<span class="enscript-type">int</span>		ps;

	ps = PAGE_SIZE;
	<span class="enscript-keyword">while</span> (start_addr &lt; end_addr) {
		pmap_enter(kernel_pmap, (vm_map_offset_t)virt,
			   (ppnum_t) i386_btop(start_addr), prot, VM_PROT_NONE, flags, TRUE);
		virt += ps;
		start_addr += ps;
	}
	<span class="enscript-keyword">return</span>(virt);
}

<span class="enscript-type">extern</span>	<span class="enscript-type">char</span>			*first_avail;
<span class="enscript-type">extern</span>	vm_offset_t		virtual_avail, virtual_end;
<span class="enscript-type">extern</span>	pmap_paddr_t		avail_start, avail_end;
<span class="enscript-type">extern</span>  vm_offset_t		sHIB;
<span class="enscript-type">extern</span>  vm_offset_t		eHIB;
<span class="enscript-type">extern</span>  vm_offset_t		stext;
<span class="enscript-type">extern</span>  vm_offset_t		etext;
<span class="enscript-type">extern</span>  vm_offset_t		sdata, edata;
<span class="enscript-type">extern</span>  vm_offset_t		sconstdata, econstdata;

<span class="enscript-type">extern</span> <span class="enscript-type">void</span>			*KPTphys;

boolean_t pmap_smep_enabled = FALSE;
boolean_t pmap_smap_enabled = FALSE;

<span class="enscript-type">void</span>
<span class="enscript-function-name">pmap_cpu_init</span>(<span class="enscript-type">void</span>)
{
	cpu_data_t	*cdp = current_cpu_datap();
	<span class="enscript-comment">/*
	 * Here early in the life of a processor (from cpu_mode_init()).
	 * Ensure global page feature is disabled at this point.
	 */</span>

	set_cr4(get_cr4() &amp;~ CR4_PGE);

	<span class="enscript-comment">/*
	 * Initialize the per-cpu, TLB-related fields.
	 */</span>
	cdp-&gt;cpu_kernel_cr3 = kernel_pmap-&gt;pm_cr3;
	cdp-&gt;cpu_active_cr3 = kernel_pmap-&gt;pm_cr3;
	cdp-&gt;cpu_tlb_invalid = FALSE;
	cdp-&gt;cpu_task_map = TASK_MAP_64BIT;
	pmap_pcid_configure();
	<span class="enscript-keyword">if</span> (cpuid_leaf7_features() &amp; CPUID_LEAF7_FEATURE_SMEP) {
		boolean_t nsmep;
		<span class="enscript-keyword">if</span> (!PE_parse_boot_argn(<span class="enscript-string">&quot;-pmap_smep_disable&quot;</span>, &amp;nsmep, <span class="enscript-keyword">sizeof</span>(nsmep))) {
			set_cr4(get_cr4() | CR4_SMEP);
			pmap_smep_enabled = TRUE;
		}
	}
	<span class="enscript-keyword">if</span> (cpuid_leaf7_features() &amp; CPUID_LEAF7_FEATURE_SMAP) {
		boolean_t nsmap;
		<span class="enscript-keyword">if</span> (!PE_parse_boot_argn(<span class="enscript-string">&quot;-pmap_smap_disable&quot;</span>, &amp;nsmap, <span class="enscript-keyword">sizeof</span>(nsmap))) {
			set_cr4(get_cr4() | CR4_SMAP);
			pmap_smap_enabled = TRUE;
		}
	}

	<span class="enscript-keyword">if</span> (cdp-&gt;cpu_fixed_pmcs_enabled) {
		boolean_t enable = TRUE;
		cpu_pmc_control(&amp;enable);
	}
}

<span class="enscript-type">static</span> uint32_t <span class="enscript-function-name">pmap_scale_shift</span>(<span class="enscript-type">void</span>) {
	uint32_t scale = 0;

	<span class="enscript-keyword">if</span> (sane_size &lt;= 8*GB) {
		scale = (uint32_t)(sane_size / (2 * GB));
	} <span class="enscript-keyword">else</span> <span class="enscript-keyword">if</span> (sane_size &lt;= 32*GB) {
		scale = 4 + (uint32_t)((sane_size - (8 * GB))/ (4 * GB)); 
	} <span class="enscript-keyword">else</span> {
		scale = 10 + (uint32_t)MIN(4, ((sane_size - (32 * GB))/ (8 * GB))); 
	}
	<span class="enscript-keyword">return</span> scale;
}

<span class="enscript-comment">/*
 *	Bootstrap the system enough to run with virtual memory.
 *	Map the kernel's code and data, and allocate the system page table.
 *	Called with mapping OFF.  Page_size must already be set.
 */</span>

<span class="enscript-type">void</span>
<span class="enscript-function-name">pmap_bootstrap</span>(
	__unused vm_offset_t	load_start,
	__unused boolean_t	IA32e)
{
#<span class="enscript-reference">if</span> <span class="enscript-variable-name">NCOPY_WINDOWS</span> &gt; 0
	vm_offset_t	va;
	<span class="enscript-type">int</span> i;
#<span class="enscript-reference">endif</span>
	assert(IA32e);

	vm_last_addr = VM_MAX_KERNEL_ADDRESS;	<span class="enscript-comment">/* Set the highest address
						 * known to VM */</span>
	<span class="enscript-comment">/*
	 *	The kernel's pmap is statically allocated so we don't
	 *	have to use pmap_create, which is unlikely to work
	 *	correctly at this part of the boot sequence.
	 */</span>

	kernel_pmap = &amp;kernel_pmap_store;
	kernel_pmap-&gt;ref_count = 1;
	kernel_pmap-&gt;nx_enabled = TRUE;
	kernel_pmap-&gt;pm_task_map = TASK_MAP_64BIT;
	kernel_pmap-&gt;pm_obj = (vm_object_t) NULL;
	kernel_pmap-&gt;dirbase = (pd_entry_t *)((uintptr_t)IdlePTD);
	kernel_pmap-&gt;pm_pdpt = (pd_entry_t *) ((uintptr_t)IdlePDPT);
	kernel_pmap-&gt;pm_pml4 = IdlePML4;
	kernel_pmap-&gt;pm_cr3 = (uintptr_t)ID_MAP_VTOP(IdlePML4);
	kernel_pmap-&gt;pm_eptp = 0;
	pmap_pcid_initialize_kernel(kernel_pmap);

	

	current_cpu_datap()-&gt;cpu_kernel_cr3 = (addr64_t) kernel_pmap-&gt;pm_cr3;

	nkpt = NKPT;
	OSAddAtomic(NKPT,  &amp;inuse_ptepages_count);
	OSAddAtomic64(NKPT,  &amp;alloc_ptepages_count);
	bootstrap_wired_pages = NKPT;

	virtual_avail = (vm_offset_t)(VM_MIN_KERNEL_ADDRESS) + (vm_offset_t)first_avail;
	virtual_end = (vm_offset_t)(VM_MAX_KERNEL_ADDRESS);

#<span class="enscript-reference">if</span> <span class="enscript-variable-name">NCOPY_WINDOWS</span> &gt; 0
	<span class="enscript-comment">/*
	 * Reserve some special page table entries/VA space for temporary
	 * mapping of pages.
	 */</span>
#<span class="enscript-reference">define</span>	<span class="enscript-function-name">SYSMAP</span>(c, p, v, n)	\
	v = (c)va; va += ((n)*INTEL_PGBYTES);

	va = virtual_avail;

        <span class="enscript-keyword">for</span> (i=0; i&lt;PMAP_NWINDOWS; i++) {
#<span class="enscript-reference">if</span> 1
	    kprintf(<span class="enscript-string">&quot;trying to do SYSMAP idx %d %p\n&quot;</span>, i,
	 	current_cpu_datap());
	    kprintf(<span class="enscript-string">&quot;cpu_pmap %p\n&quot;</span>, current_cpu_datap()-&gt;cpu_pmap);
	    kprintf(<span class="enscript-string">&quot;mapwindow %p\n&quot;</span>, current_cpu_datap()-&gt;cpu_pmap-&gt;mapwindow);
	    kprintf(<span class="enscript-string">&quot;two stuff %p %p\n&quot;</span>,
		   (<span class="enscript-type">void</span> *)(current_cpu_datap()-&gt;cpu_pmap-&gt;mapwindow[i].prv_CMAP),
                   (<span class="enscript-type">void</span> *)(current_cpu_datap()-&gt;cpu_pmap-&gt;mapwindow[i].prv_CADDR));
#<span class="enscript-reference">endif</span>
            SYSMAP(caddr_t,
		   (current_cpu_datap()-&gt;cpu_pmap-&gt;mapwindow[i].prv_CMAP),
                   (current_cpu_datap()-&gt;cpu_pmap-&gt;mapwindow[i].prv_CADDR),
		   1);
	    current_cpu_datap()-&gt;cpu_pmap-&gt;mapwindow[i].prv_CMAP =
	        &amp;(current_cpu_datap()-&gt;cpu_pmap-&gt;mapwindow[i].prv_CMAP_store);
            *current_cpu_datap()-&gt;cpu_pmap-&gt;mapwindow[i].prv_CMAP = 0;
        }

	<span class="enscript-comment">/* DMAP user for debugger */</span>
	SYSMAP(caddr_t, DMAP1, DADDR1, 1);
	SYSMAP(caddr_t, DMAP2, DADDR2, 1);  <span class="enscript-comment">/* XXX temporary - can remove */</span>

	virtual_avail = va;
#<span class="enscript-reference">endif</span>
	<span class="enscript-keyword">if</span> (!PE_parse_boot_argn(<span class="enscript-string">&quot;npvhash&quot;</span>, &amp;npvhashmask, <span class="enscript-keyword">sizeof</span> (npvhashmask))) {
		npvhashmask = ((NPVHASHBUCKETS) &lt;&lt; pmap_scale_shift()) - 1;

	}

	npvhashbuckets = npvhashmask + 1;

	<span class="enscript-keyword">if</span> (0 != ((npvhashbuckets) &amp; npvhashmask)) {
		panic(<span class="enscript-string">&quot;invalid hash %d, must be ((2^N)-1), &quot;</span>
		    <span class="enscript-string">&quot;using default %d\n&quot;</span>, npvhashmask, NPVHASHMASK);
	}

	simple_lock_init(&amp;kernel_pmap-&gt;lock, 0);
	simple_lock_init(&amp;pv_hashed_free_list_lock, 0);
	simple_lock_init(&amp;pv_hashed_kern_free_list_lock, 0);
	simple_lock_init(&amp;pv_hash_table_lock,0);
	simple_lock_init(&amp;phys_backup_lock, 0);

	pmap_cpu_init();

	<span class="enscript-keyword">if</span> (pmap_pcid_ncpus)
		printf(<span class="enscript-string">&quot;PMAP: PCID enabled\n&quot;</span>);

	<span class="enscript-keyword">if</span> (pmap_smep_enabled)
		printf(<span class="enscript-string">&quot;PMAP: Supervisor Mode Execute Protection enabled\n&quot;</span>);
	<span class="enscript-keyword">if</span> (pmap_smap_enabled)
		printf(<span class="enscript-string">&quot;PMAP: Supervisor Mode Access Protection enabled\n&quot;</span>);

#<span class="enscript-reference">if</span>	<span class="enscript-variable-name">DEBUG</span>
	printf(<span class="enscript-string">&quot;Stack canary: 0x%lx\n&quot;</span>, __stack_chk_guard[0]);
	printf(<span class="enscript-string">&quot;early_random(): 0x%qx\n&quot;</span>, early_random());
#<span class="enscript-reference">endif</span>
	boolean_t ptmp;
	<span class="enscript-comment">/* Check if the user has requested disabling stack or heap no-execute
	 * enforcement. These are &quot;const&quot; variables; that qualifier is cast away
	 * when altering them. The TEXT/DATA const sections are marked
	 * write protected later in the kernel startup sequence, so altering
	 * them is possible at this point, in pmap_bootstrap().
	 */</span>
	<span class="enscript-keyword">if</span> (PE_parse_boot_argn(<span class="enscript-string">&quot;-pmap_disable_kheap_nx&quot;</span>, &amp;ptmp, <span class="enscript-keyword">sizeof</span>(ptmp))) {
		boolean_t *pdknxp = (boolean_t *) &amp;pmap_disable_kheap_nx;
		*pdknxp = TRUE;
	}

	<span class="enscript-keyword">if</span> (PE_parse_boot_argn(<span class="enscript-string">&quot;-pmap_disable_kstack_nx&quot;</span>, &amp;ptmp, <span class="enscript-keyword">sizeof</span>(ptmp))) {
		boolean_t *pdknhp = (boolean_t *) &amp;pmap_disable_kstack_nx;
		*pdknhp = TRUE;
	}

	boot_args *args = (boot_args *)PE_state.bootArgs;
	<span class="enscript-keyword">if</span> (args-&gt;efiMode == kBootArgsEfiMode32) {
		printf(<span class="enscript-string">&quot;EFI32: kernel virtual space limited to 4GB\n&quot;</span>);
		virtual_end = VM_MAX_KERNEL_ADDRESS_EFI32;
	}
	kprintf(<span class="enscript-string">&quot;Kernel virtual space from 0x%lx to 0x%lx.\n&quot;</span>,
			(<span class="enscript-type">long</span>)KERNEL_BASE, (<span class="enscript-type">long</span>)virtual_end);
	kprintf(<span class="enscript-string">&quot;Available physical space from 0x%llx to 0x%llx\n&quot;</span>,
			avail_start, avail_end);

	<span class="enscript-comment">/*
	 * The -no_shared_cr3 boot-arg is a debugging feature (set by default
	 * in the DEBUG kernel) to force the kernel to switch to its own map
	 * (and cr3) when control is in kernelspace. The kernel's map does not
	 * include (i.e. share) userspace so wild references will cause
	 * a panic. Only copyin and copyout are exempt from this. 
	 */</span>
	(<span class="enscript-type">void</span>) PE_parse_boot_argn(<span class="enscript-string">&quot;-no_shared_cr3&quot;</span>,
				  &amp;no_shared_cr3, <span class="enscript-keyword">sizeof</span> (no_shared_cr3));
	<span class="enscript-keyword">if</span> (no_shared_cr3)
		kprintf(<span class="enscript-string">&quot;Kernel not sharing user map\n&quot;</span>);
		
#<span class="enscript-reference">ifdef</span>	<span class="enscript-variable-name">PMAP_TRACES</span>
	<span class="enscript-keyword">if</span> (PE_parse_boot_argn(<span class="enscript-string">&quot;-pmap_trace&quot;</span>, &amp;pmap_trace, <span class="enscript-keyword">sizeof</span> (pmap_trace))) {
		kprintf(<span class="enscript-string">&quot;Kernel traces for pmap operations enabled\n&quot;</span>);
	}	
#<span class="enscript-reference">endif</span>	<span class="enscript-comment">/* PMAP_TRACES */</span>
}

<span class="enscript-type">void</span>
<span class="enscript-function-name">pmap_virtual_space</span>(
	vm_offset_t *startp,
	vm_offset_t *endp)
{
	*startp = virtual_avail;
	*endp = virtual_end;
}




#<span class="enscript-reference">if</span> <span class="enscript-variable-name">HIBERNATION</span>

#<span class="enscript-reference">include</span> <span class="enscript-string">&lt;IOKit/IOHibernatePrivate.h&gt;</span>

int32_t		pmap_npages;
int32_t		pmap_teardown_last_valid_compact_indx = -1;


<span class="enscript-type">void</span>	hibernate_rebuild_pmap_structs(<span class="enscript-type">void</span>);
<span class="enscript-type">void</span>	hibernate_teardown_pmap_structs(addr64_t *, addr64_t *);
<span class="enscript-type">void</span>	pmap_pack_index(uint32_t);
int32_t	pmap_unpack_index(pv_rooted_entry_t);


int32_t
<span class="enscript-function-name">pmap_unpack_index</span>(pv_rooted_entry_t pv_h)
{
	int32_t	indx = 0;

	indx = (int32_t)(*((uint64_t *)(&amp;pv_h-&gt;qlink.next)) &gt;&gt; 48);
	indx = indx &lt;&lt; 16;
	indx |= (int32_t)(*((uint64_t *)(&amp;pv_h-&gt;qlink.prev)) &gt;&gt; 48);
	
	*((uint64_t *)(&amp;pv_h-&gt;qlink.next)) |= ((uint64_t)0xffff &lt;&lt; 48);
	*((uint64_t *)(&amp;pv_h-&gt;qlink.prev)) |= ((uint64_t)0xffff &lt;&lt; 48);

	<span class="enscript-keyword">return</span> (indx);
}


<span class="enscript-type">void</span>
<span class="enscript-function-name">pmap_pack_index</span>(uint32_t indx)
{
	pv_rooted_entry_t	pv_h;

	pv_h = &amp;pv_head_table[indx];

	*((uint64_t *)(&amp;pv_h-&gt;qlink.next)) &amp;= ~((uint64_t)0xffff &lt;&lt; 48);
	*((uint64_t *)(&amp;pv_h-&gt;qlink.prev)) &amp;= ~((uint64_t)0xffff &lt;&lt; 48);

	*((uint64_t *)(&amp;pv_h-&gt;qlink.next)) |= ((uint64_t)(indx &gt;&gt; 16)) &lt;&lt; 48;
	*((uint64_t *)(&amp;pv_h-&gt;qlink.prev)) |= ((uint64_t)(indx &amp; 0xffff)) &lt;&lt; 48;
}


<span class="enscript-type">void</span>
<span class="enscript-function-name">hibernate_teardown_pmap_structs</span>(addr64_t *unneeded_start, addr64_t *unneeded_end)
{
	int32_t		i;
	int32_t		compact_target_indx;

	compact_target_indx = 0;

	<span class="enscript-keyword">for</span> (i = 0; i &lt; pmap_npages; i++) {
		<span class="enscript-keyword">if</span> (pv_head_table[i].pmap == PMAP_NULL) {

			<span class="enscript-keyword">if</span> (pv_head_table[compact_target_indx].pmap != PMAP_NULL)
				compact_target_indx = i;
		} <span class="enscript-keyword">else</span> {
			pmap_pack_index((uint32_t)i);

			<span class="enscript-keyword">if</span> (pv_head_table[compact_target_indx].pmap == PMAP_NULL) {
				<span class="enscript-comment">/*
                                 * we've got a hole to fill, so
                                 * move this pv_rooted_entry_t to it's new home
                                 */</span>
				pv_head_table[compact_target_indx] = pv_head_table[i];
				pv_head_table[i].pmap = PMAP_NULL;
				
				pmap_teardown_last_valid_compact_indx = compact_target_indx;
				compact_target_indx++;
			} <span class="enscript-keyword">else</span>
				pmap_teardown_last_valid_compact_indx = i;
		}
	}
	*unneeded_start = (addr64_t)&amp;pv_head_table[pmap_teardown_last_valid_compact_indx+1];
	*unneeded_end = (addr64_t)&amp;pv_head_table[pmap_npages-1];
	
	HIBLOG(<span class="enscript-string">&quot;hibernate_teardown_pmap_structs done: last_valid_compact_indx %d\n&quot;</span>, pmap_teardown_last_valid_compact_indx);
}


<span class="enscript-type">void</span>
<span class="enscript-function-name">hibernate_rebuild_pmap_structs</span>(<span class="enscript-type">void</span>)
{
	int32_t			cindx, eindx, rindx;
	pv_rooted_entry_t	pv_h;

	eindx = (int32_t)pmap_npages;

	<span class="enscript-keyword">for</span> (cindx = pmap_teardown_last_valid_compact_indx; cindx &gt;= 0; cindx--) {

		pv_h = &amp;pv_head_table[cindx];

		rindx = pmap_unpack_index(pv_h);
		assert(rindx &lt; pmap_npages);

		<span class="enscript-keyword">if</span> (rindx != cindx) {
			<span class="enscript-comment">/*
			 * this pv_rooted_entry_t was moved by hibernate_teardown_pmap_structs,
			 * so move it back to its real location
			 */</span>
			pv_head_table[rindx] = pv_head_table[cindx];
		}
		<span class="enscript-keyword">if</span> (rindx+1 != eindx) {
			<span class="enscript-comment">/*
			 * the 'hole' between this vm_rooted_entry_t and the previous
			 * vm_rooted_entry_t we moved needs to be initialized as 
			 * a range of zero'd vm_rooted_entry_t's
			 */</span>
			bzero((<span class="enscript-type">char</span> *)&amp;pv_head_table[rindx+1], (eindx - rindx - 1) * <span class="enscript-keyword">sizeof</span> (<span class="enscript-type">struct</span> pv_rooted_entry));
		}
		eindx = rindx;
	}
	<span class="enscript-keyword">if</span> (rindx)
		bzero ((<span class="enscript-type">char</span> *)&amp;pv_head_table[0], rindx * <span class="enscript-keyword">sizeof</span> (<span class="enscript-type">struct</span> pv_rooted_entry));

	HIBLOG(<span class="enscript-string">&quot;hibernate_rebuild_pmap_structs done: last_valid_compact_indx %d\n&quot;</span>, pmap_teardown_last_valid_compact_indx);
}

#<span class="enscript-reference">endif</span>

<span class="enscript-comment">/*
 *	Initialize the pmap module.
 *	Called by vm_init, to initialize any structures that the pmap
 *	system needs to map virtual memory.
 */</span>
<span class="enscript-type">void</span>
<span class="enscript-function-name">pmap_init</span>(<span class="enscript-type">void</span>)
{
	<span class="enscript-type">long</span>			npages;
	vm_offset_t		addr;
	vm_size_t		s, vsize;
	vm_map_offset_t		vaddr;
	ppnum_t ppn;


	kernel_pmap-&gt;pm_obj_pml4 = &amp;kpml4obj_object_store;
	_vm_object_allocate((vm_object_size_t)NPML4PGS * PAGE_SIZE, &amp;kpml4obj_object_store);

	kernel_pmap-&gt;pm_obj_pdpt = &amp;kpdptobj_object_store;
	_vm_object_allocate((vm_object_size_t)NPDPTPGS * PAGE_SIZE, &amp;kpdptobj_object_store);

	kernel_pmap-&gt;pm_obj = &amp;kptobj_object_store;
	_vm_object_allocate((vm_object_size_t)NPDEPGS * PAGE_SIZE, &amp;kptobj_object_store);

	<span class="enscript-comment">/*
	 *	Allocate memory for the pv_head_table and its lock bits,
	 *	the modify bit array, and the pte_page table.
	 */</span>

	<span class="enscript-comment">/*
	 * zero bias all these arrays now instead of off avail_start
	 * so we cover all memory
	 */</span>

	npages = i386_btop(avail_end);
#<span class="enscript-reference">if</span> <span class="enscript-variable-name">HIBERNATION</span>
	pmap_npages = (uint32_t)npages;
#<span class="enscript-reference">endif</span>	
	s = (vm_size_t) (<span class="enscript-keyword">sizeof</span>(<span class="enscript-type">struct</span> pv_rooted_entry) * npages
			 + (<span class="enscript-keyword">sizeof</span> (<span class="enscript-type">struct</span> pv_hashed_entry_t *) * (npvhashbuckets))
			 + pv_lock_table_size(npages)
			 + pv_hash_lock_table_size((npvhashbuckets))
				+ npages);
	s = round_page(s);
	<span class="enscript-keyword">if</span> (kernel_memory_allocate(kernel_map, &amp;addr, s, 0,
				   KMA_KOBJECT | KMA_PERMANENT, VM_KERN_MEMORY_PMAP)
	    != KERN_SUCCESS)
		panic(<span class="enscript-string">&quot;pmap_init&quot;</span>);

	memset((<span class="enscript-type">char</span> *)addr, 0, s);

	vaddr = addr;
	vsize = s;

#<span class="enscript-reference">if</span> <span class="enscript-variable-name">PV_DEBUG</span>
	<span class="enscript-keyword">if</span> (0 == npvhashmask) panic(<span class="enscript-string">&quot;npvhashmask not initialized&quot;</span>);
#<span class="enscript-reference">endif</span>

	<span class="enscript-comment">/*
	 *	Allocate the structures first to preserve word-alignment.
	 */</span>
	pv_head_table = (pv_rooted_entry_t) addr;
	addr = (vm_offset_t) (pv_head_table + npages);

	pv_hash_table = (pv_hashed_entry_t *)addr;
	addr = (vm_offset_t) (pv_hash_table + (npvhashbuckets));

	pv_lock_table = (<span class="enscript-type">char</span> *) addr;
	addr = (vm_offset_t) (pv_lock_table + pv_lock_table_size(npages));

	pv_hash_lock_table = (<span class="enscript-type">char</span> *) addr;
	addr = (vm_offset_t) (pv_hash_lock_table + pv_hash_lock_table_size((npvhashbuckets)));

	pmap_phys_attributes = (<span class="enscript-type">char</span> *) addr;

	ppnum_t  last_pn = i386_btop(avail_end);
        <span class="enscript-type">unsigned</span> <span class="enscript-type">int</span> i;
	pmap_memory_region_t *pmptr = pmap_memory_regions;
	<span class="enscript-keyword">for</span> (i = 0; i &lt; pmap_memory_region_count; i++, pmptr++) {
		<span class="enscript-keyword">if</span> (pmptr-&gt;type != kEfiConventionalMemory)
			<span class="enscript-keyword">continue</span>;
		ppnum_t pn;
		<span class="enscript-keyword">for</span> (pn = pmptr-&gt;base; pn &lt;= pmptr-&gt;end; pn++) {
			<span class="enscript-keyword">if</span> (pn &lt; last_pn) {
				pmap_phys_attributes[pn] |= PHYS_MANAGED;

				<span class="enscript-keyword">if</span> (pn &gt; last_managed_page)
					last_managed_page = pn;

				<span class="enscript-keyword">if</span> (pn &gt;= lowest_hi &amp;&amp; pn &lt;= highest_hi)
					pmap_phys_attributes[pn] |= PHYS_NOENCRYPT;
			}
		}
	}
	<span class="enscript-keyword">while</span> (vsize) {
		ppn = pmap_find_phys(kernel_pmap, vaddr);

		pmap_phys_attributes[ppn] |= PHYS_NOENCRYPT;

		vaddr += PAGE_SIZE;
		vsize -= PAGE_SIZE;
	}
	<span class="enscript-comment">/*
	 *	Create the zone of physical maps,
	 *	and of the physical-to-virtual entries.
	 */</span>
	s = (vm_size_t) <span class="enscript-keyword">sizeof</span>(<span class="enscript-type">struct</span> pmap);
	pmap_zone = zinit(s, 400*s, 4096, <span class="enscript-string">&quot;pmap&quot;</span>); <span class="enscript-comment">/* XXX */</span>
        zone_change(pmap_zone, Z_NOENCRYPT, TRUE);

	pmap_anchor_zone = zinit(PAGE_SIZE, task_max, PAGE_SIZE, <span class="enscript-string">&quot;pagetable anchors&quot;</span>);
	zone_change(pmap_anchor_zone, Z_NOENCRYPT, TRUE);

	<span class="enscript-comment">/* The anchor is required to be page aligned. Zone debugging adds
	 * padding which may violate that requirement. Tell the zone
	 * subsystem that alignment is required.
	 */</span>

	zone_change(pmap_anchor_zone, Z_ALIGNMENT_REQUIRED, TRUE);

	s = (vm_size_t) <span class="enscript-keyword">sizeof</span>(<span class="enscript-type">struct</span> pv_hashed_entry);
	pv_hashed_list_zone = zinit(s, 10000*s <span class="enscript-comment">/* Expandable zone */</span>,
	    4096 * 3 <span class="enscript-comment">/* LCM x86_64*/</span>, <span class="enscript-string">&quot;pv_list&quot;</span>);
	zone_change(pv_hashed_list_zone, Z_NOENCRYPT, TRUE);

	<span class="enscript-comment">/* create pv entries for kernel pages mapped by low level
	   startup code.  these have to exist so we can pmap_remove()
	   e.g. kext pages from the middle of our addr space */</span>

	vaddr = (vm_map_offset_t) VM_MIN_KERNEL_ADDRESS;
	<span class="enscript-keyword">for</span> (ppn = VM_MIN_KERNEL_PAGE; ppn &lt; i386_btop(avail_start); ppn++) {
		pv_rooted_entry_t pv_e;

		pv_e = pai_to_pvh(ppn);
		pv_e-&gt;va = vaddr;
		vaddr += PAGE_SIZE;
		pv_e-&gt;pmap = kernel_pmap;
		queue_init(&amp;pv_e-&gt;qlink);
	}
	pmap_initialized = TRUE;

	max_preemption_latency_tsc = tmrCvt((uint64_t)MAX_PREEMPTION_LATENCY_NS, tscFCvtn2t);

	<span class="enscript-comment">/*
	 * Ensure the kernel's PML4 entry exists for the basement
	 * before this is shared with any user.
	 */</span>
	pmap_expand_pml4(kernel_pmap, KERNEL_BASEMENT, PMAP_EXPAND_OPTIONS_NONE);

#<span class="enscript-reference">if</span> <span class="enscript-variable-name">CONFIG_VMX</span>
	pmap_ept_support_ad = vmx_hv_support()  &amp;&amp; (VMX_CAP(MSR_IA32_VMX_EPT_VPID_CAP, MSR_IA32_VMX_EPT_VPID_CAP_AD_SHIFT, 1) ? TRUE : FALSE);
#<span class="enscript-reference">else</span>
	pmap_ept_support_ad = FALSE;
#<span class="enscript-reference">endif</span> <span class="enscript-comment">/* CONFIG_VMX */</span>
}

<span class="enscript-type">static</span>
<span class="enscript-type">void</span> <span class="enscript-function-name">pmap_mark_range</span>(pmap_t npmap, uint64_t sv, uint64_t nxrosz, boolean_t NX, boolean_t ro) {
	uint64_t ev = sv + nxrosz, cv = sv;
	pd_entry_t *pdep;
	pt_entry_t *ptep = NULL;

	assert(!is_ept_pmap(npmap));

	assert(((sv &amp; 0xFFFULL) | (nxrosz &amp; 0xFFFULL)) == 0);

	<span class="enscript-keyword">for</span> (pdep = pmap_pde(npmap, cv); pdep != NULL &amp;&amp; (cv &lt; ev);) {
		uint64_t pdev = (cv &amp; ~((uint64_t)PDEMASK));

		<span class="enscript-keyword">if</span> (*pdep &amp; INTEL_PTE_PS) {
			<span class="enscript-keyword">if</span> (NX)
				*pdep |= INTEL_PTE_NX;
			<span class="enscript-keyword">if</span> (ro)
				*pdep &amp;= ~INTEL_PTE_WRITE;
			cv += NBPD;
			cv &amp;= ~((uint64_t) PDEMASK);
			pdep = pmap_pde(npmap, cv);
			<span class="enscript-keyword">continue</span>;
		}

		<span class="enscript-keyword">for</span> (ptep = pmap_pte(npmap, cv); ptep != NULL &amp;&amp; (cv &lt; (pdev + NBPD)) &amp;&amp; (cv &lt; ev);) {
			<span class="enscript-keyword">if</span> (NX)
				*ptep |= INTEL_PTE_NX;
			<span class="enscript-keyword">if</span> (ro)
				*ptep &amp;= ~INTEL_PTE_WRITE;
			cv += NBPT;
			ptep = pmap_pte(npmap, cv);
		}
	}
	DPRINTF(<span class="enscript-string">&quot;%s(0x%llx, 0x%llx, %u, %u): 0x%llx, 0x%llx\n&quot;</span>, __FUNCTION__, sv, nxrosz, NX, ro, cv, ptep ? *ptep: 0);
}

<span class="enscript-comment">/*
 * Called once VM is fully initialized so that we can release unused
 * sections of low memory to the general pool.
 * Also complete the set-up of identity-mapped sections of the kernel:
 *  1) write-protect kernel text
 *  2) map kernel text using large pages if possible
 *  3) read and write-protect page zero (for K32)
 *  4) map the global page at the appropriate virtual address.
 *
 * Use of large pages
 * ------------------
 * To effectively map and write-protect all kernel text pages, the text
 * must be 2M-aligned at the base, and the data section above must also be
 * 2M-aligned. That is, there's padding below and above. This is achieved
 * through linker directives. Large pages are used only if this alignment
 * exists (and not overriden by the -kernel_text_page_4K boot-arg). The
 * memory layout is:
 * 
 *                       :                :
 *                       |     __DATA     |
 *               sdata:  ==================  2Meg
 *                       |                |
 *                       |  zero-padding  |
 *                       |                |
 *               etext:  ------------------ 
 *                       |                |
 *                       :                :
 *                       |                |
 *                       |     __TEXT     |
 *                       |                |
 *                       :                :
 *                       |                |
 *               stext:  ==================  2Meg
 *                       |                |
 *                       |  zero-padding  |
 *                       |                |
 *               eHIB:   ------------------ 
 *                       |     __HIB      |
 *                       :                :
 *
 * Prior to changing the mapping from 4K to 2M, the zero-padding pages
 * [eHIB,stext] and [etext,sdata] are ml_static_mfree()'d. Then all the
 * 4K pages covering [stext,etext] are coalesced as 2M large pages.
 * The now unused level-1 PTE pages are also freed.
 */</span>
<span class="enscript-type">extern</span> ppnum_t	vm_kernel_base_page;
<span class="enscript-type">void</span>
<span class="enscript-function-name">pmap_lowmem_finalize</span>(<span class="enscript-type">void</span>)
{
	spl_t           spl;
	<span class="enscript-type">int</span>		i;

	<span class="enscript-comment">/*
	 * Update wired memory statistics for early boot pages
	 */</span>
	PMAP_ZINFO_PALLOC(kernel_pmap, bootstrap_wired_pages * PAGE_SIZE);

	<span class="enscript-comment">/*
	 * Free pages in pmap regions below the base:
	 * rdar://6332712
	 *	We can't free all the pages to VM that EFI reports available.
	 *	Pages in the range 0xc0000-0xff000 aren't safe over sleep/wake.
	 *	There's also a size miscalculation here: pend is one page less
	 *	than it should be but this is not fixed to be backwards
	 *	compatible.
	 * This is important for KASLR because up to 256*2MB = 512MB of space
	 * needs has to be released to VM.
	 */</span>
	<span class="enscript-keyword">for</span> (i = 0;
	     pmap_memory_regions[i].end &lt; vm_kernel_base_page;
	     i++) {
		vm_offset_t	pbase = i386_ptob(pmap_memory_regions[i].base);
		vm_offset_t	pend  = i386_ptob(pmap_memory_regions[i].end+1);

		DBG(<span class="enscript-string">&quot;pmap region %d [%p..[%p\n&quot;</span>,
		    i, (<span class="enscript-type">void</span> *) pbase, (<span class="enscript-type">void</span> *) pend);

		<span class="enscript-keyword">if</span> (pmap_memory_regions[i].attribute &amp; EFI_MEMORY_KERN_RESERVED)
			<span class="enscript-keyword">continue</span>;
		<span class="enscript-comment">/*
		 * rdar://6332712
		 * Adjust limits not to free pages in range 0xc0000-0xff000.
		 */</span>
		<span class="enscript-keyword">if</span> (pbase &gt;= 0xc0000 &amp;&amp; pend &lt;= 0x100000)
			<span class="enscript-keyword">continue</span>;
		<span class="enscript-keyword">if</span> (pbase &lt; 0xc0000 &amp;&amp; pend &gt; 0x100000) {
			<span class="enscript-comment">/* page range entirely within region, free lower part */</span>
			DBG(<span class="enscript-string">&quot;- ml_static_mfree(%p,%p)\n&quot;</span>,
			    (<span class="enscript-type">void</span> *) ml_static_ptovirt(pbase),
			    (<span class="enscript-type">void</span> *) (0xc0000-pbase));
			ml_static_mfree(ml_static_ptovirt(pbase),0xc0000-pbase);
			pbase = 0x100000;
		}
		<span class="enscript-keyword">if</span> (pbase &lt; 0xc0000)
			pend = MIN(pend, 0xc0000);
		<span class="enscript-keyword">if</span> (pend  &gt; 0x100000)
			pbase = MAX(pbase, 0x100000);
		DBG(<span class="enscript-string">&quot;- ml_static_mfree(%p,%p)\n&quot;</span>,
		    (<span class="enscript-type">void</span> *) ml_static_ptovirt(pbase),
		    (<span class="enscript-type">void</span> *) (pend - pbase));
		ml_static_mfree(ml_static_ptovirt(pbase), pend - pbase);
	}

	<span class="enscript-comment">/* A final pass to get rid of all initial identity mappings to
	 * low pages.
	 */</span>
	DPRINTF(<span class="enscript-string">&quot;%s: Removing mappings from 0-&gt;0x%lx\n&quot;</span>, __FUNCTION__, vm_kernel_base);

	<span class="enscript-comment">/*
	 * Remove all mappings past the boot-cpu descriptor aliases and low globals.
	 * Non-boot-cpu GDT aliases will be remapped later as needed. 
	 */</span>
	pmap_remove(kernel_pmap, LOWGLOBAL_ALIAS + PAGE_SIZE, vm_kernel_base);

	<span class="enscript-comment">/*
	 * If text and data are both 2MB-aligned,
	 * we can map text with large-pages,
	 * unless the -kernel_text_ps_4K boot-arg overrides.
	 */</span>
	<span class="enscript-keyword">if</span> ((stext &amp; I386_LPGMASK) == 0 &amp;&amp; (sdata &amp; I386_LPGMASK) == 0) {
		kprintf(<span class="enscript-string">&quot;Kernel text is 2MB aligned&quot;</span>);
		kernel_text_ps_4K = FALSE;
		<span class="enscript-keyword">if</span> (PE_parse_boot_argn(<span class="enscript-string">&quot;-kernel_text_ps_4K&quot;</span>,
				       &amp;kernel_text_ps_4K,
				       <span class="enscript-keyword">sizeof</span> (kernel_text_ps_4K)))
			kprintf(<span class="enscript-string">&quot; but will be mapped with 4K pages\n&quot;</span>);
		<span class="enscript-keyword">else</span>
			kprintf(<span class="enscript-string">&quot; and will be mapped with 2M pages\n&quot;</span>);
	}

	(<span class="enscript-type">void</span>) PE_parse_boot_argn(<span class="enscript-string">&quot;wpkernel&quot;</span>, &amp;wpkernel, <span class="enscript-keyword">sizeof</span> (wpkernel));
	<span class="enscript-keyword">if</span> (wpkernel)
		kprintf(<span class="enscript-string">&quot;Kernel text %p-%p to be write-protected\n&quot;</span>,
			(<span class="enscript-type">void</span> *) stext, (<span class="enscript-type">void</span> *) etext);

	spl = splhigh();

	<span class="enscript-comment">/*
	 * Scan over text if mappings are to be changed:
	 * - Remap kernel text readonly unless the &quot;wpkernel&quot; boot-arg is 0 
 	 * - Change to large-pages if possible and not overriden.
	 */</span>
	<span class="enscript-keyword">if</span> (kernel_text_ps_4K &amp;&amp; wpkernel) {
		vm_offset_t     myva;
		<span class="enscript-keyword">for</span> (myva = stext; myva &lt; etext; myva += PAGE_SIZE) {
			pt_entry_t     *ptep;

			ptep = pmap_pte(kernel_pmap, (vm_map_offset_t)myva);
			<span class="enscript-keyword">if</span> (ptep)
				pmap_store_pte(ptep, *ptep &amp; ~INTEL_PTE_WRITE);
		}
	}

	<span class="enscript-keyword">if</span> (!kernel_text_ps_4K) {
		vm_offset_t     myva;

		<span class="enscript-comment">/*
		 * Release zero-filled page padding used for 2M-alignment.
		 */</span>
		DBG(<span class="enscript-string">&quot;ml_static_mfree(%p,%p) for padding below text\n&quot;</span>,
			(<span class="enscript-type">void</span> *) eHIB, (<span class="enscript-type">void</span> *) (stext - eHIB));
		ml_static_mfree(eHIB, stext - eHIB);
		DBG(<span class="enscript-string">&quot;ml_static_mfree(%p,%p) for padding above text\n&quot;</span>,
			(<span class="enscript-type">void</span> *) etext, (<span class="enscript-type">void</span> *) (sdata - etext));
		ml_static_mfree(etext, sdata - etext);

		<span class="enscript-comment">/*
		 * Coalesce text pages into large pages.
		 */</span>
		<span class="enscript-keyword">for</span> (myva = stext; myva &lt; sdata; myva += I386_LPGBYTES) {
			pt_entry_t	*ptep;
			vm_offset_t	pte_phys;
			pt_entry_t	*pdep;
			pt_entry_t	pde;

			pdep = pmap_pde(kernel_pmap, (vm_map_offset_t)myva);
			ptep = pmap_pte(kernel_pmap, (vm_map_offset_t)myva);
			DBG(<span class="enscript-string">&quot;myva: %p pdep: %p ptep: %p\n&quot;</span>,
				(<span class="enscript-type">void</span> *) myva, (<span class="enscript-type">void</span> *) pdep, (<span class="enscript-type">void</span> *) ptep);
			<span class="enscript-keyword">if</span> ((*ptep &amp; INTEL_PTE_VALID) == 0)
				<span class="enscript-keyword">continue</span>;
			pte_phys = (vm_offset_t)(*ptep &amp; PG_FRAME);
			pde = *pdep &amp; PTMASK;	<span class="enscript-comment">/* page attributes from pde */</span>
			pde |= INTEL_PTE_PS;	<span class="enscript-comment">/* make it a 2M entry */</span>
			pde |= pte_phys;	<span class="enscript-comment">/* take page frame from pte */</span>

			<span class="enscript-keyword">if</span> (wpkernel)
				pde &amp;= ~INTEL_PTE_WRITE;
			DBG(<span class="enscript-string">&quot;pmap_store_pte(%p,0x%llx)\n&quot;</span>,
				(<span class="enscript-type">void</span> *)pdep, pde);
			pmap_store_pte(pdep, pde);

			<span class="enscript-comment">/*
			 * Free the now-unused level-1 pte.
			 * Note: ptep is a virtual address to the pte in the
			 *   recursive map. We can't use this address to free
			 *   the page. Instead we need to compute its address
			 *   in the Idle PTEs in &quot;low memory&quot;.
			 */</span>
			vm_offset_t vm_ptep = (vm_offset_t) KPTphys
						+ (pte_phys &gt;&gt; PTPGSHIFT);
			DBG(<span class="enscript-string">&quot;ml_static_mfree(%p,0x%x) for pte\n&quot;</span>,
				(<span class="enscript-type">void</span> *) vm_ptep, PAGE_SIZE);
			ml_static_mfree(vm_ptep, PAGE_SIZE);
		}

		<span class="enscript-comment">/* Change variable read by sysctl machdep.pmap */</span>
		pmap_kernel_text_ps = I386_LPGBYTES;
	}

	boolean_t doconstro = TRUE;

	(<span class="enscript-type">void</span>) PE_parse_boot_argn(<span class="enscript-string">&quot;dataconstro&quot;</span>, &amp;doconstro, <span class="enscript-keyword">sizeof</span>(doconstro));

	<span class="enscript-keyword">if</span> ((sconstdata | econstdata) &amp; PAGE_MASK) {
		kprintf(<span class="enscript-string">&quot;Const DATA misaligned 0x%lx 0x%lx\n&quot;</span>, sconstdata, econstdata);
		<span class="enscript-keyword">if</span> ((sconstdata &amp; PAGE_MASK) || (doconstro_override == FALSE))
			doconstro = FALSE;
	}

	<span class="enscript-keyword">if</span> ((sconstdata &gt; edata) || (sconstdata &lt; sdata) || ((econstdata - sconstdata) &gt;= (edata - sdata))) {
		kprintf(<span class="enscript-string">&quot;Const DATA incorrect size 0x%lx 0x%lx 0x%lx 0x%lx\n&quot;</span>, sconstdata, econstdata, sdata, edata);
		doconstro = FALSE;
	}

	<span class="enscript-keyword">if</span> (doconstro)
		kprintf(<span class="enscript-string">&quot;Marking const DATA read-only\n&quot;</span>);

	vm_offset_t dva;

	<span class="enscript-keyword">for</span> (dva = sdata; dva &lt; edata; dva += I386_PGBYTES) {
		assert(((sdata | edata) &amp; PAGE_MASK) == 0);
		<span class="enscript-keyword">if</span> ( (sdata | edata) &amp; PAGE_MASK) {
			kprintf(<span class="enscript-string">&quot;DATA misaligned, 0x%lx, 0x%lx\n&quot;</span>, sdata, edata);
			<span class="enscript-keyword">break</span>;
		}

		pt_entry_t dpte, *dptep = pmap_pte(kernel_pmap, dva);

		dpte = *dptep;

		assert((dpte &amp; INTEL_PTE_VALID));
		<span class="enscript-keyword">if</span> ((dpte &amp; INTEL_PTE_VALID) == 0) {
			kprintf(<span class="enscript-string">&quot;Missing data mapping 0x%lx 0x%lx 0x%lx\n&quot;</span>, dva, sdata, edata);
			<span class="enscript-keyword">continue</span>;
		}

		dpte |= INTEL_PTE_NX;
		<span class="enscript-keyword">if</span> (doconstro &amp;&amp; (dva &gt;= sconstdata) &amp;&amp; (dva &lt; econstdata)) {
			dpte &amp;= ~INTEL_PTE_WRITE;
		}
		pmap_store_pte(dptep, dpte);
	}
	kernel_segment_command_t * seg;
	kernel_section_t         * sec;

	<span class="enscript-keyword">for</span> (seg = firstseg(); seg != NULL; seg = nextsegfromheader(&amp;_mh_execute_header, seg)) {
		<span class="enscript-keyword">if</span> (!strcmp(seg-&gt;segname, <span class="enscript-string">&quot;__TEXT&quot;</span>) ||
		    !strcmp(seg-&gt;segname, <span class="enscript-string">&quot;__DATA&quot;</span>)) {
			<span class="enscript-keyword">continue</span>;
		}
		<span class="enscript-comment">//XXX
</span>		<span class="enscript-keyword">if</span> (!strcmp(seg-&gt;segname, <span class="enscript-string">&quot;__KLD&quot;</span>)) {
			<span class="enscript-keyword">continue</span>;
		}
		<span class="enscript-keyword">if</span> (!strcmp(seg-&gt;segname, <span class="enscript-string">&quot;__HIB&quot;</span>)) {
			<span class="enscript-keyword">for</span> (sec = firstsect(seg); sec != NULL; sec = nextsect(seg, sec)) {
				<span class="enscript-keyword">if</span> (sec-&gt;addr &amp; PAGE_MASK)
					panic(<span class="enscript-string">&quot;__HIB segment's sections misaligned&quot;</span>);
				<span class="enscript-keyword">if</span> (!strcmp(sec-&gt;sectname, <span class="enscript-string">&quot;__text&quot;</span>)) {
					pmap_mark_range(kernel_pmap, sec-&gt;addr, round_page(sec-&gt;size), FALSE, TRUE);
				} <span class="enscript-keyword">else</span> {
					pmap_mark_range(kernel_pmap, sec-&gt;addr, round_page(sec-&gt;size), TRUE, FALSE);
				}
			}
		} <span class="enscript-keyword">else</span> {
			pmap_mark_range(kernel_pmap, seg-&gt;vmaddr, round_page_64(seg-&gt;vmsize), TRUE, FALSE);
		}
	}

	<span class="enscript-comment">/*
	 * If we're debugging, map the low global vector page at the fixed
	 * virtual address.  Otherwise, remove the mapping for this.
	 */</span>
	<span class="enscript-keyword">if</span> (debug_boot_arg) {
		pt_entry_t *pte = NULL;
		<span class="enscript-keyword">if</span> (0 == (pte = pmap_pte(kernel_pmap, LOWGLOBAL_ALIAS)))
			panic(<span class="enscript-string">&quot;lowmem pte&quot;</span>);
		<span class="enscript-comment">/* make sure it is defined on page boundary */</span>
		assert(0 == ((vm_offset_t) &amp;lowGlo &amp; PAGE_MASK));
		pmap_store_pte(pte, kvtophys((vm_offset_t)&amp;lowGlo)
					| INTEL_PTE_REF
					| INTEL_PTE_MOD
					| INTEL_PTE_WIRED
					| INTEL_PTE_VALID
					| INTEL_PTE_WRITE
					| INTEL_PTE_NX);
	} <span class="enscript-keyword">else</span> {
		pmap_remove(kernel_pmap,
			    LOWGLOBAL_ALIAS, LOWGLOBAL_ALIAS + PAGE_SIZE);
	}
	
	splx(spl);
	<span class="enscript-keyword">if</span> (pmap_pcid_ncpus)
		tlb_flush_global();
	<span class="enscript-keyword">else</span>
		flush_tlb_raw();
}

<span class="enscript-comment">/*
 * this function is only used for debugging fron the vm layer
 */</span>
boolean_t
<span class="enscript-function-name">pmap_verify_free</span>(
		 ppnum_t pn)
{
	pv_rooted_entry_t	pv_h;
	<span class="enscript-type">int</span>		pai;
	boolean_t	result;

	assert(pn != vm_page_fictitious_addr);

	<span class="enscript-keyword">if</span> (!pmap_initialized)
		<span class="enscript-keyword">return</span>(TRUE);

	<span class="enscript-keyword">if</span> (pn == vm_page_guard_addr)
		<span class="enscript-keyword">return</span> TRUE;

	pai = ppn_to_pai(pn);
	<span class="enscript-keyword">if</span> (!IS_MANAGED_PAGE(pai))
		<span class="enscript-keyword">return</span>(FALSE);
	pv_h = pai_to_pvh(pn);
	result = (pv_h-&gt;pmap == PMAP_NULL);
	<span class="enscript-keyword">return</span>(result);
}

boolean_t
<span class="enscript-function-name">pmap_is_empty</span>(
       pmap_t          pmap,
       vm_map_offset_t va_start,
       vm_map_offset_t va_end)
{
	vm_map_offset_t offset;
	ppnum_t         phys_page;

	<span class="enscript-keyword">if</span> (pmap == PMAP_NULL) {
		<span class="enscript-keyword">return</span> TRUE;
	}

	<span class="enscript-comment">/*
	 * Check the resident page count
	 * - if it's zero, the pmap is completely empty.
	 * This short-circuit test prevents a virtual address scan which is
	 * painfully slow for 64-bit spaces.
	 * This assumes the count is correct
	 * .. the debug kernel ought to be checking perhaps by page table walk.
	 */</span>
	<span class="enscript-keyword">if</span> (pmap-&gt;stats.resident_count == 0)
		<span class="enscript-keyword">return</span> TRUE;

	<span class="enscript-keyword">for</span> (offset = va_start;
	     offset &lt; va_end;
	     offset += PAGE_SIZE_64) {
		phys_page = pmap_find_phys(pmap, offset);
		<span class="enscript-keyword">if</span> (phys_page) {
			kprintf(<span class="enscript-string">&quot;pmap_is_empty(%p,0x%llx,0x%llx): &quot;</span>
				<span class="enscript-string">&quot;page %d at 0x%llx\n&quot;</span>,
				pmap, va_start, va_end, phys_page, offset);
			<span class="enscript-keyword">return</span> FALSE;
		}
	}

	<span class="enscript-keyword">return</span> TRUE;
}

<span class="enscript-type">void</span>
<span class="enscript-function-name">hv_ept_pmap_create</span>(<span class="enscript-type">void</span> **ept_pmap, <span class="enscript-type">void</span> **eptp)
{
	pmap_t p;

	<span class="enscript-keyword">if</span> ((ept_pmap == NULL) || (eptp == NULL)) {
		<span class="enscript-keyword">return</span>;
	}

	p = pmap_create_options(get_task_ledger(current_task()), 0, (PMAP_CREATE_64BIT | PMAP_CREATE_EPT));
	<span class="enscript-keyword">if</span> (p == PMAP_NULL) {
		*ept_pmap = NULL;
		*eptp = NULL;
		<span class="enscript-keyword">return</span>;
	}

	assert(is_ept_pmap(p));

	*ept_pmap = (<span class="enscript-type">void</span>*)p;
	*eptp = (<span class="enscript-type">void</span>*)(p-&gt;pm_eptp);
	<span class="enscript-keyword">return</span>;
}

<span class="enscript-comment">/*
 *	Create and return a physical map.
 *
 *	If the size specified for the map
 *	is zero, the map is an actual physical
 *	map, and may be referenced by the
 *	hardware.
 *
 *	If the size specified is non-zero,
 *	the map will be used in software only, and
 *	is bounded by that size.
 */</span>
pmap_t
<span class="enscript-function-name">pmap_create_options</span>(
	ledger_t	ledger,
	vm_map_size_t	sz,
	<span class="enscript-type">int</span>		flags)
{
	pmap_t		p;
	vm_size_t	size;
	pml4_entry_t    *pml4;
	pml4_entry_t    *kpml4;

	PMAP_TRACE(PMAP_CODE(PMAP__CREATE) | DBG_FUNC_START,
		   (uint32_t) (sz&gt;&gt;32), (uint32_t) sz, flags, 0, 0);

	size = (vm_size_t) sz;

	<span class="enscript-comment">/*
	 *	A software use-only map doesn't even need a map.
	 */</span>

	<span class="enscript-keyword">if</span> (size != 0) {
		<span class="enscript-keyword">return</span>(PMAP_NULL);
	}

	<span class="enscript-comment">/*
	 *	Return error when unrecognized flags are passed.
	 */</span>
	<span class="enscript-keyword">if</span> ((flags &amp; ~(PMAP_CREATE_KNOWN_FLAGS)) != 0) {
		<span class="enscript-keyword">return</span>(PMAP_NULL);
	}

	p = (pmap_t) zalloc(pmap_zone);
	<span class="enscript-keyword">if</span> (PMAP_NULL == p)
		panic(<span class="enscript-string">&quot;pmap_create zalloc&quot;</span>);
	<span class="enscript-comment">/* Zero all fields */</span>
	bzero(p, <span class="enscript-keyword">sizeof</span>(*p));
	<span class="enscript-comment">/* init counts now since we'll be bumping some */</span>
	simple_lock_init(&amp;p-&gt;lock, 0);
#<span class="enscript-reference">if</span> 00
	p-&gt;stats.resident_count = 0;
	p-&gt;stats.resident_max = 0;
	p-&gt;stats.wired_count = 0;
#<span class="enscript-reference">else</span>
	bzero(&amp;p-&gt;stats, <span class="enscript-keyword">sizeof</span> (p-&gt;stats));
#<span class="enscript-reference">endif</span>
	p-&gt;ref_count = 1;
	p-&gt;nx_enabled = 1;
	p-&gt;pm_shared = FALSE;
	ledger_reference(ledger);
	p-&gt;ledger = ledger;

	p-&gt;pm_task_map = ((flags &amp; PMAP_CREATE_64BIT) ? TASK_MAP_64BIT : TASK_MAP_32BIT);
	<span class="enscript-keyword">if</span> (pmap_pcid_ncpus)
		pmap_pcid_initialize(p);

	p-&gt;pm_pml4 = zalloc(pmap_anchor_zone);

	pmap_assert((((uintptr_t)p-&gt;pm_pml4) &amp; PAGE_MASK) == 0);

	memset((<span class="enscript-type">char</span> *)p-&gt;pm_pml4, 0, PAGE_SIZE);

	<span class="enscript-keyword">if</span> (flags &amp; PMAP_CREATE_EPT) {
		p-&gt;pm_eptp = (pmap_paddr_t)kvtophys((vm_offset_t)p-&gt;pm_pml4);
		p-&gt;pm_cr3 = 0;
	} <span class="enscript-keyword">else</span> {
		p-&gt;pm_eptp = 0;
		p-&gt;pm_cr3 = (pmap_paddr_t)kvtophys((vm_offset_t)p-&gt;pm_pml4);
	}

	<span class="enscript-comment">/* allocate the vm_objs to hold the pdpt, pde and pte pages */</span>

	p-&gt;pm_obj_pml4 = vm_object_allocate((vm_object_size_t)(NPML4PGS) * PAGE_SIZE);
	<span class="enscript-keyword">if</span> (NULL == p-&gt;pm_obj_pml4)
		panic(<span class="enscript-string">&quot;pmap_create pdpt obj&quot;</span>);

	p-&gt;pm_obj_pdpt = vm_object_allocate((vm_object_size_t)(NPDPTPGS) * PAGE_SIZE);
	<span class="enscript-keyword">if</span> (NULL == p-&gt;pm_obj_pdpt)
		panic(<span class="enscript-string">&quot;pmap_create pdpt obj&quot;</span>);

	p-&gt;pm_obj = vm_object_allocate((vm_object_size_t)(NPDEPGS) * PAGE_SIZE);
	<span class="enscript-keyword">if</span> (NULL == p-&gt;pm_obj)
		panic(<span class="enscript-string">&quot;pmap_create pte obj&quot;</span>);

	<span class="enscript-comment">/* All pmaps share the kernel's pml4 */</span>
	pml4 = pmap64_pml4(p, 0ULL);
	kpml4 = kernel_pmap-&gt;pm_pml4;
	pml4[KERNEL_PML4_INDEX]    = kpml4[KERNEL_PML4_INDEX];
	pml4[KERNEL_KEXTS_INDEX]   = kpml4[KERNEL_KEXTS_INDEX];
	pml4[KERNEL_PHYSMAP_PML4_INDEX] = kpml4[KERNEL_PHYSMAP_PML4_INDEX];

	PMAP_TRACE(PMAP_CODE(PMAP__CREATE) | DBG_FUNC_START,
		   p, flags, 0, 0, 0);

	<span class="enscript-keyword">return</span>(p);
}

pmap_t
<span class="enscript-function-name">pmap_create</span>(
	ledger_t	ledger,
	vm_map_size_t	sz,
	boolean_t	is_64bit)
{
	<span class="enscript-keyword">return</span> pmap_create_options(ledger, sz, ((is_64bit) ? PMAP_CREATE_64BIT : 0));
}

<span class="enscript-comment">/*
 *	Retire the given physical map from service.
 *	Should only be called if the map contains
 *	no valid mappings.
 */</span>
<span class="enscript-type">extern</span> <span class="enscript-type">int</span> vm_wired_objects_page_count;

<span class="enscript-type">void</span>
<span class="enscript-function-name">pmap_destroy</span>(pmap_t	p)
{
	<span class="enscript-type">int</span>		c;

	<span class="enscript-keyword">if</span> (p == PMAP_NULL)
		<span class="enscript-keyword">return</span>;

	PMAP_TRACE(PMAP_CODE(PMAP__DESTROY) | DBG_FUNC_START,
		   p, 0, 0, 0, 0);

	PMAP_LOCK(p);

	c = --p-&gt;ref_count;

	pmap_assert((current_thread() &amp;&amp; (current_thread()-&gt;map)) ? (current_thread()-&gt;map-&gt;pmap != p) : TRUE);

	<span class="enscript-keyword">if</span> (c == 0) {
		<span class="enscript-comment">/* 
		 * If some cpu is not using the physical pmap pointer that it
		 * is supposed to be (see set_dirbase), we might be using the
		 * pmap that is being destroyed! Make sure we are
		 * physically on the right pmap:
		 */</span>
		PMAP_UPDATE_TLBS(p, 0x0ULL, 0xFFFFFFFFFFFFF000ULL);
		<span class="enscript-keyword">if</span> (pmap_pcid_ncpus)
			pmap_destroy_pcid_sync(p);
	}

	PMAP_UNLOCK(p);

	<span class="enscript-keyword">if</span> (c != 0) {
		PMAP_TRACE(PMAP_CODE(PMAP__DESTROY) | DBG_FUNC_END,
			   p, 1, 0, 0, 0);
		pmap_assert(p == kernel_pmap);
	        <span class="enscript-keyword">return</span>;	<span class="enscript-comment">/* still in use */</span>
	}

	<span class="enscript-comment">/*
	 *	Free the memory maps, then the
	 *	pmap structure.
	 */</span>
	<span class="enscript-type">int</span> inuse_ptepages = 0;

	zfree(pmap_anchor_zone, p-&gt;pm_pml4);

	inuse_ptepages += p-&gt;pm_obj_pml4-&gt;resident_page_count;
	vm_object_deallocate(p-&gt;pm_obj_pml4);

	inuse_ptepages += p-&gt;pm_obj_pdpt-&gt;resident_page_count;
	vm_object_deallocate(p-&gt;pm_obj_pdpt);

	inuse_ptepages += p-&gt;pm_obj-&gt;resident_page_count;
	vm_object_deallocate(p-&gt;pm_obj);

	OSAddAtomic(-inuse_ptepages,  &amp;inuse_ptepages_count);
	PMAP_ZINFO_PFREE(p, inuse_ptepages * PAGE_SIZE);
	ledger_dereference(p-&gt;ledger);
	zfree(pmap_zone, p);

	PMAP_TRACE(PMAP_CODE(PMAP__DESTROY) | DBG_FUNC_END,
		   0, 0, 0, 0, 0);
}

<span class="enscript-comment">/*
 *	Add a reference to the specified pmap.
 */</span>

<span class="enscript-type">void</span>
<span class="enscript-function-name">pmap_reference</span>(pmap_t	p)
{
	<span class="enscript-keyword">if</span> (p != PMAP_NULL) {
	        PMAP_LOCK(p);
		p-&gt;ref_count++;
		PMAP_UNLOCK(p);;
	}
}

<span class="enscript-comment">/*
 *	Remove phys addr if mapped in specified map
 *
 */</span>
<span class="enscript-type">void</span>
<span class="enscript-function-name">pmap_remove_some_phys</span>(
	__unused pmap_t		map,
	__unused ppnum_t         pn)
{

<span class="enscript-comment">/* Implement to support working set code */</span>

}


<span class="enscript-type">void</span>
<span class="enscript-function-name">pmap_protect</span>(
	pmap_t		map,
	vm_map_offset_t	sva,
	vm_map_offset_t	eva,
	vm_prot_t	prot)
{
	pmap_protect_options(map, sva, eva, prot, 0, NULL);
}


<span class="enscript-comment">/*
 *	Set the physical protection on the
 *	specified range of this map as requested.
 *	Will not increase permissions.
 */</span>
<span class="enscript-type">void</span>
<span class="enscript-function-name">pmap_protect_options</span>(
	pmap_t		map,
	vm_map_offset_t	sva,
	vm_map_offset_t	eva,
	vm_prot_t	prot,
	<span class="enscript-type">unsigned</span> <span class="enscript-type">int</span>	options,
	<span class="enscript-type">void</span>		*arg)
{
	pt_entry_t	*pde;
	pt_entry_t	*spte, *epte;
	vm_map_offset_t lva;
	vm_map_offset_t orig_sva;
	boolean_t       set_NX;
	<span class="enscript-type">int</span>             num_found = 0;
	boolean_t	is_ept;

	pmap_intr_assert();

	<span class="enscript-keyword">if</span> (map == PMAP_NULL)
		<span class="enscript-keyword">return</span>;

	<span class="enscript-keyword">if</span> (prot == VM_PROT_NONE) {
		pmap_remove_options(map, sva, eva, options);
		<span class="enscript-keyword">return</span>;
	}
	PMAP_TRACE(PMAP_CODE(PMAP__PROTECT) | DBG_FUNC_START,
		   map,
		   (uint32_t) (sva &gt;&gt; 32), (uint32_t) sva,
		   (uint32_t) (eva &gt;&gt; 32), (uint32_t) eva);

	<span class="enscript-keyword">if</span> ((prot &amp; VM_PROT_EXECUTE) || !nx_enabled || !map-&gt;nx_enabled)
		set_NX = FALSE;
	<span class="enscript-keyword">else</span>
		set_NX = TRUE;

	is_ept = is_ept_pmap(map);


	PMAP_LOCK(map);

	orig_sva = sva;
	<span class="enscript-keyword">while</span> (sva &lt; eva) {
		lva = (sva + pde_mapped_size) &amp; ~(pde_mapped_size - 1);
		<span class="enscript-keyword">if</span> (lva &gt; eva)
			lva = eva;
		pde = pmap_pde(map, sva);
		<span class="enscript-keyword">if</span> (pde &amp;&amp; (*pde &amp; PTE_VALID_MASK(is_ept))) {
			<span class="enscript-keyword">if</span> (*pde &amp; PTE_PS) {
				<span class="enscript-comment">/* superpage */</span>
				spte = pde;
				epte = spte+1; <span class="enscript-comment">/* excluded */</span>
			} <span class="enscript-keyword">else</span> {
				spte = pmap_pte(map, (sva &amp; ~(pde_mapped_size - 1)));
				spte = &amp;spte[ptenum(sva)];
				epte = &amp;spte[intel_btop(lva - sva)];
			}

			<span class="enscript-keyword">for</span> (; spte &lt; epte; spte++) {
				<span class="enscript-keyword">if</span> (!(*spte &amp; PTE_VALID_MASK(is_ept)))
					<span class="enscript-keyword">continue</span>;

				<span class="enscript-keyword">if</span> (is_ept) {
					<span class="enscript-keyword">if</span> (prot &amp; VM_PROT_READ)
						pmap_update_pte(spte, 0, PTE_READ(is_ept));
					<span class="enscript-keyword">else</span>
						pmap_update_pte(spte, PTE_READ(is_ept), 0);
				}
				<span class="enscript-keyword">if</span> (prot &amp; VM_PROT_WRITE)
					pmap_update_pte(spte, 0, PTE_WRITE(is_ept));
				<span class="enscript-keyword">else</span>
					pmap_update_pte(spte, PTE_WRITE(is_ept), 0);

				<span class="enscript-keyword">if</span> (set_NX) {
					<span class="enscript-keyword">if</span> (!is_ept)
						pmap_update_pte(spte, 0, INTEL_PTE_NX);
					<span class="enscript-keyword">else</span>
						pmap_update_pte(spte, INTEL_EPT_EX, 0);
				} <span class="enscript-keyword">else</span> {
					<span class="enscript-keyword">if</span> (!is_ept)
						pmap_update_pte(spte, INTEL_PTE_NX, 0);
					<span class="enscript-keyword">else</span>
						pmap_update_pte(spte, 0, INTEL_EPT_EX);
				}
				num_found++;
			}
		}
		sva = lva;
	}
	<span class="enscript-keyword">if</span> (num_found) {
		<span class="enscript-keyword">if</span> (options &amp; PMAP_OPTIONS_NOFLUSH)
			PMAP_UPDATE_TLBS_DELAYED(map, orig_sva, eva, (pmap_flush_context *)arg);
		<span class="enscript-keyword">else</span>
			PMAP_UPDATE_TLBS(map, orig_sva, eva);
	}
	PMAP_UNLOCK(map);

	PMAP_TRACE(PMAP_CODE(PMAP__PROTECT) | DBG_FUNC_END,
		   0, 0, 0, 0, 0);

}

<span class="enscript-comment">/* Map a (possibly) autogenned block */</span>
<span class="enscript-type">void</span>
<span class="enscript-function-name">pmap_map_block</span>(
	pmap_t		pmap, 
	addr64_t	va,
	ppnum_t 	pa,
	uint32_t	size,
	vm_prot_t	prot,
	<span class="enscript-type">int</span>		attr,
	__unused <span class="enscript-type">unsigned</span> <span class="enscript-type">int</span>	flags)
{
	uint32_t        page;
	<span class="enscript-type">int</span>		cur_page_size;

	<span class="enscript-keyword">if</span> (attr &amp; VM_MEM_SUPERPAGE)
		cur_page_size =  SUPERPAGE_SIZE;
	<span class="enscript-keyword">else</span> 
		cur_page_size =  PAGE_SIZE;

	<span class="enscript-keyword">for</span> (page = 0; page &lt; size; page+=cur_page_size/PAGE_SIZE) {
		pmap_enter(pmap, va, pa, prot, VM_PROT_NONE, attr, TRUE);
		va += cur_page_size;
		pa+=cur_page_size/PAGE_SIZE;
	}
}

kern_return_t
<span class="enscript-function-name">pmap_expand_pml4</span>(
	pmap_t		map,
	vm_map_offset_t	vaddr,
	<span class="enscript-type">unsigned</span> <span class="enscript-type">int</span> options)
{
	vm_page_t	m;
	pmap_paddr_t	pa;
	uint64_t	i;
	ppnum_t		pn;
	pml4_entry_t	*pml4p;
	boolean_t	is_ept = is_ept_pmap(map);

	DBG(<span class="enscript-string">&quot;pmap_expand_pml4(%p,%p)\n&quot;</span>, map, (<span class="enscript-type">void</span> *)vaddr);

	<span class="enscript-comment">/*
	 *	Allocate a VM page for the pml4 page
	 */</span>
	<span class="enscript-keyword">while</span> ((m = vm_page_grab()) == VM_PAGE_NULL) {
		<span class="enscript-keyword">if</span> (options &amp; PMAP_EXPAND_OPTIONS_NOWAIT)
			<span class="enscript-keyword">return</span> KERN_RESOURCE_SHORTAGE;
		VM_PAGE_WAIT();
	}
	<span class="enscript-comment">/*
	 *	put the page into the pmap's obj list so it
	 *	can be found later.
	 */</span>
	pn = m-&gt;phys_page;
	pa = i386_ptob(pn);
	i = pml4idx(map, vaddr);

	<span class="enscript-comment">/*
	 *	Zero the page.
	 */</span>
	pmap_zero_page(pn);

	vm_page_lockspin_queues();
	vm_page_wire(m, VM_KERN_MEMORY_PTE, TRUE);
	vm_page_unlock_queues();

	OSAddAtomic(1,  &amp;inuse_ptepages_count);
	OSAddAtomic64(1,  &amp;alloc_ptepages_count);
	PMAP_ZINFO_PALLOC(map, PAGE_SIZE);

	<span class="enscript-comment">/* Take the oject lock (mutex) before the PMAP_LOCK (spinlock) */</span>
	vm_object_lock(map-&gt;pm_obj_pml4);

	PMAP_LOCK(map);
	<span class="enscript-comment">/*
	 *	See if someone else expanded us first
	 */</span>
	<span class="enscript-keyword">if</span> (pmap64_pdpt(map, vaddr) != PDPT_ENTRY_NULL) {
	        PMAP_UNLOCK(map);
		vm_object_unlock(map-&gt;pm_obj_pml4);

		VM_PAGE_FREE(m);

		OSAddAtomic(-1,  &amp;inuse_ptepages_count);
		PMAP_ZINFO_PFREE(map, PAGE_SIZE);
		<span class="enscript-keyword">return</span> KERN_SUCCESS;
	}

#<span class="enscript-reference">if</span> 0 <span class="enscript-comment">/* DEBUG */</span>
       <span class="enscript-keyword">if</span> (0 != vm_page_lookup(map-&gt;pm_obj_pml4, (vm_object_offset_t)i * PAGE_SIZE)) {
	       panic(<span class="enscript-string">&quot;pmap_expand_pml4: obj not empty, pmap %p pm_obj %p vaddr 0x%llx i 0x%llx\n&quot;</span>,
		     map, map-&gt;pm_obj_pml4, vaddr, i);
       }
#<span class="enscript-reference">endif</span>
	vm_page_insert_wired(m, map-&gt;pm_obj_pml4, (vm_object_offset_t)i * PAGE_SIZE, VM_KERN_MEMORY_PTE);
	vm_object_unlock(map-&gt;pm_obj_pml4);

	<span class="enscript-comment">/*
	 *	Set the page directory entry for this page table.
	 */</span>
	pml4p = pmap64_pml4(map, vaddr); <span class="enscript-comment">/* refetch under lock */</span>

	pmap_store_pte(pml4p, pa_to_pte(pa)
				| PTE_READ(is_ept)
				| (is_ept ? INTEL_EPT_EX : INTEL_PTE_USER)
				| PTE_WRITE(is_ept));

	PMAP_UNLOCK(map);

	<span class="enscript-keyword">return</span> KERN_SUCCESS;
}

kern_return_t
<span class="enscript-function-name">pmap_expand_pdpt</span>(pmap_t map, vm_map_offset_t vaddr, <span class="enscript-type">unsigned</span> <span class="enscript-type">int</span> options)
{
	vm_page_t	m;
	pmap_paddr_t	pa;
	uint64_t	i;
	ppnum_t		pn;
	pdpt_entry_t	*pdptp;
	boolean_t	is_ept = is_ept_pmap(map);

	DBG(<span class="enscript-string">&quot;pmap_expand_pdpt(%p,%p)\n&quot;</span>, map, (<span class="enscript-type">void</span> *)vaddr);

	<span class="enscript-keyword">while</span> ((pdptp = pmap64_pdpt(map, vaddr)) == PDPT_ENTRY_NULL) {
		kern_return_t pep4kr = pmap_expand_pml4(map, vaddr, options);
		<span class="enscript-keyword">if</span> (pep4kr != KERN_SUCCESS)
			<span class="enscript-keyword">return</span> pep4kr;
	}

	<span class="enscript-comment">/*
	 *	Allocate a VM page for the pdpt page
	 */</span>
	<span class="enscript-keyword">while</span> ((m = vm_page_grab()) == VM_PAGE_NULL) {
		<span class="enscript-keyword">if</span> (options &amp; PMAP_EXPAND_OPTIONS_NOWAIT)
			<span class="enscript-keyword">return</span> KERN_RESOURCE_SHORTAGE;
		VM_PAGE_WAIT();
	}

	<span class="enscript-comment">/*
	 *	put the page into the pmap's obj list so it
	 *	can be found later.
	 */</span>
	pn = m-&gt;phys_page;
	pa = i386_ptob(pn);
	i = pdptidx(map, vaddr);

	<span class="enscript-comment">/*
	 *	Zero the page.
	 */</span>
	pmap_zero_page(pn);

	vm_page_lockspin_queues();
	vm_page_wire(m, VM_KERN_MEMORY_PTE, TRUE);
	vm_page_unlock_queues();

	OSAddAtomic(1,  &amp;inuse_ptepages_count);
	OSAddAtomic64(1,  &amp;alloc_ptepages_count);
	PMAP_ZINFO_PALLOC(map, PAGE_SIZE);

	<span class="enscript-comment">/* Take the oject lock (mutex) before the PMAP_LOCK (spinlock) */</span>
	vm_object_lock(map-&gt;pm_obj_pdpt);

	PMAP_LOCK(map);
	<span class="enscript-comment">/*
	 *	See if someone else expanded us first
	 */</span>
	<span class="enscript-keyword">if</span> (pmap64_pde(map, vaddr) != PD_ENTRY_NULL) {
		PMAP_UNLOCK(map);
		vm_object_unlock(map-&gt;pm_obj_pdpt);

		VM_PAGE_FREE(m);

		OSAddAtomic(-1,  &amp;inuse_ptepages_count);
		PMAP_ZINFO_PFREE(map, PAGE_SIZE);
		<span class="enscript-keyword">return</span> KERN_SUCCESS;
	}

#<span class="enscript-reference">if</span> 0 <span class="enscript-comment">/* DEBUG */</span>
       <span class="enscript-keyword">if</span> (0 != vm_page_lookup(map-&gt;pm_obj_pdpt, (vm_object_offset_t)i * PAGE_SIZE)) {
	       panic(<span class="enscript-string">&quot;pmap_expand_pdpt: obj not empty, pmap %p pm_obj %p vaddr 0x%llx i 0x%llx\n&quot;</span>,
		     map, map-&gt;pm_obj_pdpt, vaddr, i);
       }
#<span class="enscript-reference">endif</span>
	vm_page_insert_wired(m, map-&gt;pm_obj_pdpt, (vm_object_offset_t)i * PAGE_SIZE, VM_KERN_MEMORY_PTE);
	vm_object_unlock(map-&gt;pm_obj_pdpt);

	<span class="enscript-comment">/*
	 *	Set the page directory entry for this page table.
	 */</span>
	pdptp = pmap64_pdpt(map, vaddr); <span class="enscript-comment">/* refetch under lock */</span>

	pmap_store_pte(pdptp, pa_to_pte(pa)
				| PTE_READ(is_ept)
				| (is_ept ? INTEL_EPT_EX : INTEL_PTE_USER)
				| PTE_WRITE(is_ept));

	PMAP_UNLOCK(map);

	<span class="enscript-keyword">return</span> KERN_SUCCESS;

}



<span class="enscript-comment">/*
 *	Routine:	pmap_expand
 *
 *	Expands a pmap to be able to map the specified virtual address.
 *
 *	Allocates new virtual memory for the P0 or P1 portion of the
 *	pmap, then re-maps the physical pages that were in the old
 *	pmap to be in the new pmap.
 *
 *	Must be called with the pmap system and the pmap unlocked,
 *	since these must be unlocked to use vm_allocate or vm_deallocate.
 *	Thus it must be called in a loop that checks whether the map
 *	has been expanded enough.
 *	(We won't loop forever, since page tables aren't shrunk.)
 */</span>
kern_return_t
<span class="enscript-function-name">pmap_expand</span>(
	pmap_t		map,
	vm_map_offset_t	vaddr,
	<span class="enscript-type">unsigned</span> <span class="enscript-type">int</span> options)
{
	pt_entry_t		*pdp;
	<span class="enscript-type">register</span> vm_page_t	m;
	<span class="enscript-type">register</span> pmap_paddr_t	pa;
	uint64_t		i;
	ppnum_t                 pn;
	boolean_t		is_ept = is_ept_pmap(map);


	<span class="enscript-comment">/*
 	 * For the kernel, the virtual address must be in or above the basement
	 * which is for kexts and is in the 512GB immediately below the kernel..
	 * XXX - should use VM_MIN_KERNEL_AND_KEXT_ADDRESS not KERNEL_BASEMENT
	 */</span>
	<span class="enscript-keyword">if</span> (map == kernel_pmap &amp;&amp; 
	    !(vaddr &gt;= KERNEL_BASEMENT &amp;&amp; vaddr &lt;= VM_MAX_KERNEL_ADDRESS))
		panic(<span class="enscript-string">&quot;pmap_expand: bad vaddr 0x%llx for kernel pmap&quot;</span>, vaddr);


	<span class="enscript-keyword">while</span> ((pdp = pmap64_pde(map, vaddr)) == PD_ENTRY_NULL) {
		kern_return_t pepkr = pmap_expand_pdpt(map, vaddr, options);
		<span class="enscript-keyword">if</span> (pepkr != KERN_SUCCESS)
			<span class="enscript-keyword">return</span> pepkr;
	}

	<span class="enscript-comment">/*
	 *	Allocate a VM page for the pde entries.
	 */</span>
	<span class="enscript-keyword">while</span> ((m = vm_page_grab()) == VM_PAGE_NULL) {
		<span class="enscript-keyword">if</span> (options &amp; PMAP_EXPAND_OPTIONS_NOWAIT)
			<span class="enscript-keyword">return</span> KERN_RESOURCE_SHORTAGE;
		VM_PAGE_WAIT();
	}

	<span class="enscript-comment">/*
	 *	put the page into the pmap's obj list so it
	 *	can be found later.
	 */</span>
	pn = m-&gt;phys_page;
	pa = i386_ptob(pn);
	i = pdeidx(map, vaddr);

	<span class="enscript-comment">/*
	 *	Zero the page.
	 */</span>
	pmap_zero_page(pn);

	vm_page_lockspin_queues();
	vm_page_wire(m, VM_KERN_MEMORY_PTE, TRUE);
	vm_page_unlock_queues();

	OSAddAtomic(1,  &amp;inuse_ptepages_count);
	OSAddAtomic64(1,  &amp;alloc_ptepages_count);
	PMAP_ZINFO_PALLOC(map, PAGE_SIZE);

	<span class="enscript-comment">/* Take the oject lock (mutex) before the PMAP_LOCK (spinlock) */</span>
	vm_object_lock(map-&gt;pm_obj);

	PMAP_LOCK(map);

	<span class="enscript-comment">/*
	 *	See if someone else expanded us first
	 */</span>
	<span class="enscript-keyword">if</span> (pmap_pte(map, vaddr) != PT_ENTRY_NULL) {
		PMAP_UNLOCK(map);
		vm_object_unlock(map-&gt;pm_obj);

		VM_PAGE_FREE(m);

		OSAddAtomic(-1,  &amp;inuse_ptepages_count);
		PMAP_ZINFO_PFREE(map, PAGE_SIZE);
		<span class="enscript-keyword">return</span> KERN_SUCCESS;
	}

#<span class="enscript-reference">if</span> 0 <span class="enscript-comment">/* DEBUG */</span>
       <span class="enscript-keyword">if</span> (0 != vm_page_lookup(map-&gt;pm_obj, (vm_object_offset_t)i * PAGE_SIZE)) {
	       panic(<span class="enscript-string">&quot;pmap_expand: obj not empty, pmap 0x%x pm_obj 0x%x vaddr 0x%llx i 0x%llx\n&quot;</span>,
		     map, map-&gt;pm_obj, vaddr, i);
       }
#<span class="enscript-reference">endif</span>
	vm_page_insert_wired(m, map-&gt;pm_obj, (vm_object_offset_t)i * PAGE_SIZE, VM_KERN_MEMORY_PTE);
	vm_object_unlock(map-&gt;pm_obj);

	<span class="enscript-comment">/*
	 *	Set the page directory entry for this page table.
	 */</span>
	pdp = pmap_pde(map, vaddr);
	pmap_store_pte(pdp, pa_to_pte(pa)
				| PTE_READ(is_ept)
				| (is_ept ? INTEL_EPT_EX : INTEL_PTE_USER)
				| PTE_WRITE(is_ept));

	PMAP_UNLOCK(map);

	<span class="enscript-keyword">return</span> KERN_SUCCESS;
}

<span class="enscript-comment">/* On K64 machines with more than 32GB of memory, pmap_steal_memory
 * will allocate past the 1GB of pre-expanded virtual kernel area. This
 * function allocates all the page tables using memory from the same pool
 * that pmap_steal_memory uses, rather than calling vm_page_grab (which
 * isn't available yet). */</span>
<span class="enscript-type">void</span>
<span class="enscript-function-name">pmap_pre_expand</span>(pmap_t pmap, vm_map_offset_t vaddr)
{
	ppnum_t pn;
	pt_entry_t		*pte;
	boolean_t		is_ept = is_ept_pmap(pmap);

	PMAP_LOCK(pmap);

	<span class="enscript-keyword">if</span>(pmap64_pdpt(pmap, vaddr) == PDPT_ENTRY_NULL) {
		<span class="enscript-keyword">if</span> (!pmap_next_page_hi(&amp;pn))
			panic(<span class="enscript-string">&quot;pmap_pre_expand&quot;</span>);

		pmap_zero_page(pn);

		pte = pmap64_pml4(pmap, vaddr);

		pmap_store_pte(pte, pa_to_pte(i386_ptob(pn))
				| PTE_READ(is_ept)
				| (is_ept ? INTEL_EPT_EX : INTEL_PTE_USER)
				| PTE_WRITE(is_ept));
	}

	<span class="enscript-keyword">if</span>(pmap64_pde(pmap, vaddr) == PD_ENTRY_NULL) {
		<span class="enscript-keyword">if</span> (!pmap_next_page_hi(&amp;pn))
			panic(<span class="enscript-string">&quot;pmap_pre_expand&quot;</span>);

		pmap_zero_page(pn);

		pte = pmap64_pdpt(pmap, vaddr);

		pmap_store_pte(pte, pa_to_pte(i386_ptob(pn))
				| PTE_READ(is_ept)
				| (is_ept ? INTEL_EPT_EX : INTEL_PTE_USER)
				| PTE_WRITE(is_ept));
	}

	<span class="enscript-keyword">if</span>(pmap_pte(pmap, vaddr) == PT_ENTRY_NULL) {
		<span class="enscript-keyword">if</span> (!pmap_next_page_hi(&amp;pn))
			panic(<span class="enscript-string">&quot;pmap_pre_expand&quot;</span>);

		pmap_zero_page(pn);

		pte = pmap64_pde(pmap, vaddr);

		pmap_store_pte(pte, pa_to_pte(i386_ptob(pn))
				| PTE_READ(is_ept)
				| (is_ept ? INTEL_EPT_EX : INTEL_PTE_USER)
				| PTE_WRITE(is_ept));
	}

	PMAP_UNLOCK(pmap);
}

<span class="enscript-comment">/*
 * pmap_sync_page_data_phys(ppnum_t pa)
 * 
 * Invalidates all of the instruction cache on a physical page and
 * pushes any dirty data from the data cache for the same physical page
 * Not required in i386.
 */</span>
<span class="enscript-type">void</span>
<span class="enscript-function-name">pmap_sync_page_data_phys</span>(__unused ppnum_t pa)
{
	<span class="enscript-keyword">return</span>;
}

<span class="enscript-comment">/*
 * pmap_sync_page_attributes_phys(ppnum_t pa)
 * 
 * Write back and invalidate all cachelines on a physical page.
 */</span>
<span class="enscript-type">void</span>
<span class="enscript-function-name">pmap_sync_page_attributes_phys</span>(ppnum_t pa)
{
	cache_flush_page_phys(pa);
}



#<span class="enscript-reference">ifdef</span> <span class="enscript-variable-name">CURRENTLY_UNUSED_AND_UNTESTED</span>

<span class="enscript-type">int</span>	collect_ref;
<span class="enscript-type">int</span>	collect_unref;

<span class="enscript-comment">/*
 *	Routine:	pmap_collect
 *	Function:
 *		Garbage collects the physical map system for
 *		pages which are no longer used.
 *		Success need not be guaranteed -- that is, there
 *		may well be pages which are not referenced, but
 *		others may be collected.
 *	Usage:
 *		Called by the pageout daemon when pages are scarce.
 */</span>
<span class="enscript-type">void</span>
<span class="enscript-function-name">pmap_collect</span>(
	pmap_t 		p)
{
	<span class="enscript-type">register</span> pt_entry_t	*pdp, *ptp;
	pt_entry_t		*eptp;
	<span class="enscript-type">int</span>			wired;
	boolean_t		is_ept;

	<span class="enscript-keyword">if</span> (p == PMAP_NULL)
		<span class="enscript-keyword">return</span>;

	<span class="enscript-keyword">if</span> (p == kernel_pmap)
		<span class="enscript-keyword">return</span>;

	is_ept = is_ept_pmap(p);

	<span class="enscript-comment">/*
	 *	Garbage collect map.
	 */</span>
	PMAP_LOCK(p);

	<span class="enscript-keyword">for</span> (pdp = (pt_entry_t *)p-&gt;dirbase;
	     pdp &lt; (pt_entry_t *)&amp;p-&gt;dirbase[(UMAXPTDI+1)];
	     pdp++)
	{
		<span class="enscript-keyword">if</span> (*pdp &amp; PTE_VALID_MASK(is_ept)) {
			<span class="enscript-keyword">if</span> (*pdp &amp; PTE_REF(is_ept)) {
				pmap_store_pte(pdp, *pdp &amp; ~PTE_REF(is_ept));
				collect_ref++;
			} <span class="enscript-keyword">else</span> {
				collect_unref++;
				ptp = pmap_pte(p, pdetova(pdp - (pt_entry_t *)p-&gt;dirbase));
				eptp = ptp + NPTEPG;

				<span class="enscript-comment">/*
				 * If the pte page has any wired mappings, we cannot
				 * free it.
				 */</span>
				wired = 0;
				{
					<span class="enscript-type">register</span> pt_entry_t *ptep;
					<span class="enscript-keyword">for</span> (ptep = ptp; ptep &lt; eptp; ptep++) {
						<span class="enscript-keyword">if</span> (iswired(*ptep)) {
							wired = 1;
							<span class="enscript-keyword">break</span>;
						}
					}
				}
				<span class="enscript-keyword">if</span> (!wired) {
					<span class="enscript-comment">/*
					 * Remove the virtual addresses mapped by this pte page.
					 */</span>
						pmap_remove_range(p,
							pdetova(pdp - (pt_entry_t *)p-&gt;dirbase),
							ptp,
							eptp);

					<span class="enscript-comment">/*
					 * Invalidate the page directory pointer.
					 */</span>
					pmap_store_pte(pdp, 0x0);

					PMAP_UNLOCK(p);

					<span class="enscript-comment">/*
					 * And free the pte page itself.
					 */</span>
					{
						<span class="enscript-type">register</span> vm_page_t m;

						vm_object_lock(p-&gt;pm_obj);

						m = vm_page_lookup(p-&gt;pm_obj,(vm_object_offset_t)(pdp - (pt_entry_t *)&amp;p-&gt;dirbase[0]) * PAGE_SIZE);
						<span class="enscript-keyword">if</span> (m == VM_PAGE_NULL)
							panic(<span class="enscript-string">&quot;pmap_collect: pte page not in object&quot;</span>);

						vm_object_unlock(p-&gt;pm_obj);

						VM_PAGE_FREE(m);

						OSAddAtomic(-1,  &amp;inuse_ptepages_count);
						PMAP_ZINFO_PFREE(p, PAGE_SIZE);
					}

					PMAP_LOCK(p);
				}
			}
		}
	}

	PMAP_UPDATE_TLBS(p, 0x0, 0xFFFFFFFFFFFFF000ULL);
	PMAP_UNLOCK(p);
	<span class="enscript-keyword">return</span>;
}
#<span class="enscript-reference">endif</span>


<span class="enscript-type">void</span>
<span class="enscript-function-name">pmap_copy_page</span>(ppnum_t src, ppnum_t dst)
{
	bcopy_phys((addr64_t)i386_ptob(src),
		   (addr64_t)i386_ptob(dst),
		   PAGE_SIZE);
}


<span class="enscript-comment">/*
 *	Routine:	pmap_pageable
 *	Function:
 *		Make the specified pages (by pmap, offset)
 *		pageable (or not) as requested.
 *
 *		A page which is not pageable may not take
 *		a fault; therefore, its page table entry
 *		must remain valid for the duration.
 *
 *		This routine is merely advisory; pmap_enter
 *		will specify that these pages are to be wired
 *		down (or not) as appropriate.
 */</span>
<span class="enscript-type">void</span>
<span class="enscript-function-name">pmap_pageable</span>(
	__unused pmap_t			pmap,
	__unused vm_map_offset_t	start_addr,
	__unused vm_map_offset_t	end_addr,
	__unused boolean_t		pageable)
{
#<span class="enscript-reference">ifdef</span>	<span class="enscript-variable-name">lint</span>
	pmap++; start_addr++; end_addr++; pageable++;
#<span class="enscript-reference">endif</span>	<span class="enscript-comment">/* lint */</span>
}

<span class="enscript-type">void</span> 
<span class="enscript-function-name">invalidate_icache</span>(__unused vm_offset_t	addr,
		  __unused <span class="enscript-type">unsigned</span>	cnt,
		  __unused <span class="enscript-type">int</span>		phys)
{
	<span class="enscript-keyword">return</span>;
}

<span class="enscript-type">void</span> 
<span class="enscript-function-name">flush_dcache</span>(__unused vm_offset_t	addr,
	     __unused <span class="enscript-type">unsigned</span>		count,
	     __unused <span class="enscript-type">int</span>		phys)
{
	<span class="enscript-keyword">return</span>;
}

#<span class="enscript-reference">if</span> <span class="enscript-variable-name">CONFIG_DTRACE</span>
<span class="enscript-comment">/*
 * Constrain DTrace copyin/copyout actions
 */</span>
<span class="enscript-type">extern</span> kern_return_t <span class="enscript-function-name">dtrace_copyio_preflight</span>(addr64_t);
<span class="enscript-type">extern</span> kern_return_t <span class="enscript-function-name">dtrace_copyio_postflight</span>(addr64_t);

kern_return_t <span class="enscript-function-name">dtrace_copyio_preflight</span>(__unused addr64_t va)
{
	thread_t thread = current_thread();
	uint64_t ccr3;
	<span class="enscript-keyword">if</span> (current_map() == kernel_map)
		<span class="enscript-keyword">return</span> KERN_FAILURE;
	<span class="enscript-keyword">else</span> <span class="enscript-keyword">if</span> (((ccr3 = get_cr3_base()) != thread-&gt;map-&gt;pmap-&gt;pm_cr3) &amp;&amp; (no_shared_cr3 == FALSE))
		<span class="enscript-keyword">return</span> KERN_FAILURE;
	<span class="enscript-keyword">else</span> <span class="enscript-keyword">if</span> (no_shared_cr3 &amp;&amp; (ccr3 != kernel_pmap-&gt;pm_cr3))
		<span class="enscript-keyword">return</span> KERN_FAILURE;
	<span class="enscript-keyword">else</span>
		<span class="enscript-keyword">return</span> KERN_SUCCESS;
}
 
kern_return_t <span class="enscript-function-name">dtrace_copyio_postflight</span>(__unused addr64_t va)
{
	<span class="enscript-keyword">return</span> KERN_SUCCESS;
}
#<span class="enscript-reference">endif</span> <span class="enscript-comment">/* CONFIG_DTRACE */</span>

#<span class="enscript-reference">include</span> <span class="enscript-string">&lt;mach_vm_debug.h&gt;</span>
#<span class="enscript-reference">if</span>	<span class="enscript-variable-name">MACH_VM_DEBUG</span>
#<span class="enscript-reference">include</span> <span class="enscript-string">&lt;vm/vm_debug.h&gt;</span>

<span class="enscript-type">int</span>
<span class="enscript-function-name">pmap_list_resident_pages</span>(
	__unused pmap_t		pmap,
	__unused vm_offset_t	*listp,
	__unused <span class="enscript-type">int</span>		space)
{
	<span class="enscript-keyword">return</span> 0;
}
#<span class="enscript-reference">endif</span>	<span class="enscript-comment">/* MACH_VM_DEBUG */</span>



<span class="enscript-comment">/* temporary workaround */</span>
boolean_t
<span class="enscript-function-name">coredumpok</span>(__unused vm_map_t map, __unused vm_offset_t va)
{
#<span class="enscript-reference">if</span> 0
	pt_entry_t     *ptep;

	ptep = pmap_pte(map-&gt;pmap, va);
	<span class="enscript-keyword">if</span> (0 == ptep)
		<span class="enscript-keyword">return</span> FALSE;
	<span class="enscript-keyword">return</span> ((*ptep &amp; (INTEL_PTE_NCACHE | INTEL_PTE_WIRED)) != (INTEL_PTE_NCACHE | INTEL_PTE_WIRED));
#<span class="enscript-reference">else</span>
	<span class="enscript-keyword">return</span> TRUE;
#<span class="enscript-reference">endif</span>
}


boolean_t
<span class="enscript-function-name">phys_page_exists</span>(ppnum_t pn)
{
	assert(pn != vm_page_fictitious_addr);

	<span class="enscript-keyword">if</span> (!pmap_initialized)
		<span class="enscript-keyword">return</span> TRUE;

	<span class="enscript-keyword">if</span> (pn == vm_page_guard_addr)
		<span class="enscript-keyword">return</span> FALSE;

	<span class="enscript-keyword">if</span> (!IS_MANAGED_PAGE(ppn_to_pai(pn)))
		<span class="enscript-keyword">return</span> FALSE;

	<span class="enscript-keyword">return</span> TRUE;
}



<span class="enscript-type">void</span>
<span class="enscript-function-name">pmap_switch</span>(pmap_t tpmap)
{
        spl_t	s;

	s = splhigh();		<span class="enscript-comment">/* Make sure interruptions are disabled */</span>
	set_dirbase(tpmap, current_thread(), cpu_number());
	splx(s);
}


<span class="enscript-comment">/*
 * disable no-execute capability on
 * the specified pmap
 */</span>
<span class="enscript-type">void</span>
<span class="enscript-function-name">pmap_disable_NX</span>(pmap_t pmap)
{
        pmap-&gt;nx_enabled = 0;
}

<span class="enscript-type">void</span> 
<span class="enscript-function-name">pt_fake_zone_init</span>(<span class="enscript-type">int</span> zone_index)
{
	pt_fake_zone_index = zone_index;
}

<span class="enscript-type">void</span>
<span class="enscript-function-name">pt_fake_zone_info</span>(
	<span class="enscript-type">int</span>		*count,
	vm_size_t	*cur_size,
	vm_size_t	*max_size,
	vm_size_t	*elem_size,
	vm_size_t	*alloc_size,
	uint64_t	*sum_size,
	<span class="enscript-type">int</span>		*collectable,
	<span class="enscript-type">int</span>		*exhaustable,
	<span class="enscript-type">int</span>		*caller_acct)
{
        *count      = inuse_ptepages_count;
	*cur_size   = PAGE_SIZE * inuse_ptepages_count;
	*max_size   = PAGE_SIZE * (inuse_ptepages_count +
				   vm_page_inactive_count +
				   vm_page_active_count +
				   vm_page_free_count);
	*elem_size  = PAGE_SIZE;
	*alloc_size = PAGE_SIZE;
	*sum_size = alloc_ptepages_count * PAGE_SIZE;

	*collectable = 1;
	*exhaustable = 0;
	*caller_acct = 1;
}


<span class="enscript-type">void</span>
<span class="enscript-function-name">pmap_flush_context_init</span>(pmap_flush_context *pfc)
{
	pfc-&gt;pfc_cpus = 0;
	pfc-&gt;pfc_invalid_global = 0;
}

<span class="enscript-type">extern</span> <span class="enscript-type">unsigned</span> TLBTimeOut;
<span class="enscript-type">void</span>
<span class="enscript-function-name">pmap_flush</span>(
	pmap_flush_context *pfc)
{
	<span class="enscript-type">unsigned</span> <span class="enscript-type">int</span>	my_cpu;
	<span class="enscript-type">unsigned</span> <span class="enscript-type">int</span>	cpu;
	<span class="enscript-type">unsigned</span> <span class="enscript-type">int</span>	cpu_bit;
	cpumask_t	cpus_to_respond = 0;
	cpumask_t	cpus_to_signal = 0;
	cpumask_t	cpus_signaled = 0;
	boolean_t	flush_self = FALSE;
	uint64_t	deadline;

	mp_disable_preemption();

	my_cpu = cpu_number();
	cpus_to_signal = pfc-&gt;pfc_cpus;

	PMAP_TRACE_CONSTANT(PMAP_CODE(PMAP__FLUSH_DELAYED_TLBS) | DBG_FUNC_START,
			    NULL, cpus_to_signal, 0, 0, 0);

	<span class="enscript-keyword">for</span> (cpu = 0, cpu_bit = 1; cpu &lt; real_ncpus &amp;&amp; cpus_to_signal; cpu++, cpu_bit &lt;&lt;= 1) {

		<span class="enscript-keyword">if</span> (cpus_to_signal &amp; cpu_bit) {

			cpus_to_signal &amp;= ~cpu_bit;

			<span class="enscript-keyword">if</span> (!cpu_datap(cpu)-&gt;cpu_running)
				<span class="enscript-keyword">continue</span>;

			<span class="enscript-keyword">if</span> (pfc-&gt;pfc_invalid_global &amp; cpu_bit)
				cpu_datap(cpu)-&gt;cpu_tlb_invalid_global = TRUE;
			<span class="enscript-keyword">else</span>
				cpu_datap(cpu)-&gt;cpu_tlb_invalid_local = TRUE;
			mfence();

			<span class="enscript-keyword">if</span> (cpu == my_cpu) {
				flush_self = TRUE;
				<span class="enscript-keyword">continue</span>;
			}
			<span class="enscript-keyword">if</span> (CPU_CR3_IS_ACTIVE(cpu)) {
				cpus_to_respond |= cpu_bit;
				i386_signal_cpu(cpu, MP_TLB_FLUSH, ASYNC);
			}
		}
	}
	cpus_signaled = cpus_to_respond;

	<span class="enscript-comment">/*
	 * Flush local tlb if required.
	 * Do this now to overlap with other processors responding.
	 */</span>
	<span class="enscript-keyword">if</span> (flush_self &amp;&amp; cpu_datap(my_cpu)-&gt;cpu_tlb_invalid != FALSE)
		process_pmap_updates();

	<span class="enscript-keyword">if</span> (cpus_to_respond) {

		deadline = mach_absolute_time() +
				(TLBTimeOut ? TLBTimeOut : LockTimeOut);
		boolean_t is_timeout_traced = FALSE;
		
		<span class="enscript-comment">/*
		 * Wait for those other cpus to acknowledge
		 */</span>
		<span class="enscript-keyword">while</span> (cpus_to_respond != 0) {
			<span class="enscript-type">long</span> orig_acks = 0;

			<span class="enscript-keyword">for</span> (cpu = 0, cpu_bit = 1; cpu &lt; real_ncpus; cpu++, cpu_bit &lt;&lt;= 1) {
				<span class="enscript-comment">/* Consider checking local/global invalidity
				 * as appropriate in the PCID case.
				 */</span>
				<span class="enscript-keyword">if</span> ((cpus_to_respond &amp; cpu_bit) != 0) {
					<span class="enscript-keyword">if</span> (!cpu_datap(cpu)-&gt;cpu_running ||
					    cpu_datap(cpu)-&gt;cpu_tlb_invalid == FALSE ||
					    !CPU_CR3_IS_ACTIVE(cpu)) {
						cpus_to_respond &amp;= ~cpu_bit;
					}
					cpu_pause();
				}
				<span class="enscript-keyword">if</span> (cpus_to_respond == 0)
					<span class="enscript-keyword">break</span>;
			}
			<span class="enscript-keyword">if</span> (cpus_to_respond &amp;&amp; (mach_absolute_time() &gt; deadline)) {
				<span class="enscript-keyword">if</span> (machine_timeout_suspended())
					<span class="enscript-keyword">continue</span>;
				<span class="enscript-keyword">if</span> (TLBTimeOut == 0) {
					<span class="enscript-keyword">if</span> (is_timeout_traced)
						<span class="enscript-keyword">continue</span>;
					PMAP_TRACE_CONSTANT(PMAP_CODE(PMAP__FLUSH_TLBS_TO),
			    			NULL, cpus_to_signal, cpus_to_respond, 0, 0);
					is_timeout_traced = TRUE;
					<span class="enscript-keyword">continue</span>;
				}
				pmap_tlb_flush_timeout = TRUE;
				orig_acks = NMIPI_acks;
				mp_cpus_NMIPI(cpus_to_respond);

				panic(<span class="enscript-string">&quot;TLB invalidation IPI timeout: &quot;</span>
				    <span class="enscript-string">&quot;CPU(s) failed to respond to interrupts, unresponsive CPU bitmap: 0x%llx, NMIPI acks: orig: 0x%lx, now: 0x%lx&quot;</span>,
				    cpus_to_respond, orig_acks, NMIPI_acks);
			}
		}
	}
	PMAP_TRACE_CONSTANT(PMAP_CODE(PMAP__FLUSH_DELAYED_TLBS) | DBG_FUNC_END,
			    NULL, cpus_signaled, flush_self, 0, 0);

	mp_enable_preemption();
}


<span class="enscript-type">static</span> <span class="enscript-type">void</span>
<span class="enscript-function-name">invept</span>(<span class="enscript-type">void</span> *eptp)
{
	<span class="enscript-type">struct</span> {
		uint64_t eptp;
		uint64_t reserved;
	} __attribute__((aligned(16), packed)) invept_descriptor = {(uint64_t)eptp, 0};

	__asm__ <span class="enscript-type">volatile</span>(<span class="enscript-string">&quot;invept (%%rax), %%rcx&quot;</span>
		: : <span class="enscript-string">&quot;c&quot;</span> (PMAP_INVEPT_SINGLE_CONTEXT), <span class="enscript-string">&quot;a&quot;</span> (&amp;invept_descriptor)
		: <span class="enscript-string">&quot;cc&quot;</span>, <span class="enscript-string">&quot;memory&quot;</span>);
}

<span class="enscript-comment">/*
 * Called with pmap locked, we:
 *  - scan through per-cpu data to see which other cpus need to flush
 *  - send an IPI to each non-idle cpu to be flushed
 *  - wait for all to signal back that they are inactive or we see that
 *    they are at a safe point (idle).
 *  - flush the local tlb if active for this pmap
 *  - return ... the caller will unlock the pmap
 */</span>

<span class="enscript-type">void</span>
<span class="enscript-function-name">pmap_flush_tlbs</span>(pmap_t	pmap, vm_map_offset_t startv, vm_map_offset_t endv, <span class="enscript-type">int</span> options, pmap_flush_context *pfc)
{
	<span class="enscript-type">unsigned</span> <span class="enscript-type">int</span>	cpu;
	<span class="enscript-type">unsigned</span> <span class="enscript-type">int</span>	cpu_bit;
	cpumask_t	cpus_to_signal;
	<span class="enscript-type">unsigned</span> <span class="enscript-type">int</span>	my_cpu = cpu_number();
	pmap_paddr_t	pmap_cr3 = pmap-&gt;pm_cr3;
	boolean_t	flush_self = FALSE;
	uint64_t	deadline;
	boolean_t	pmap_is_shared = (pmap-&gt;pm_shared || (pmap == kernel_pmap));
	boolean_t	need_global_flush = FALSE;
	uint32_t	event_code;
	boolean_t	is_ept = is_ept_pmap(pmap);

	assert((processor_avail_count &lt; 2) ||
	       (ml_get_interrupts_enabled() &amp;&amp; get_preemption_level() != 0));

	<span class="enscript-keyword">if</span> (pmap == kernel_pmap) {
		event_code = PMAP_CODE(PMAP__FLUSH_KERN_TLBS);
	} <span class="enscript-keyword">else</span> <span class="enscript-keyword">if</span> (is_ept) {
		event_code = PMAP_CODE(PMAP__FLUSH_EPT);
	} <span class="enscript-keyword">else</span> {
		event_code = PMAP_CODE(PMAP__FLUSH_TLBS);
	}

	PMAP_TRACE_CONSTANT(event_code | DBG_FUNC_START,
			    pmap, options, startv, endv, 0);

	<span class="enscript-keyword">if</span> (is_ept) {
		mp_cpus_call(CPUMASK_ALL, ASYNC, invept, (<span class="enscript-type">void</span>*)pmap-&gt;pm_eptp);
		<span class="enscript-keyword">goto</span> <span class="enscript-reference">out</span>;
	}

	<span class="enscript-comment">/*
	 * Scan other cpus for matching active or task CR3.
	 * For idle cpus (with no active map) we mark them invalid but
	 * don't signal -- they'll check as they go busy.
	 */</span>
	cpus_to_signal = 0;

	<span class="enscript-keyword">if</span> (pmap_pcid_ncpus) {
		<span class="enscript-keyword">if</span> (pmap_is_shared)
			need_global_flush = TRUE;
		pmap_pcid_invalidate_all_cpus(pmap);
		mfence();
	}
	<span class="enscript-keyword">for</span> (cpu = 0, cpu_bit = 1; cpu &lt; real_ncpus; cpu++, cpu_bit &lt;&lt;= 1) {
		<span class="enscript-keyword">if</span> (!cpu_datap(cpu)-&gt;cpu_running)
			<span class="enscript-keyword">continue</span>;
		uint64_t	cpu_active_cr3 = CPU_GET_ACTIVE_CR3(cpu);
		uint64_t	cpu_task_cr3 = CPU_GET_TASK_CR3(cpu);

		<span class="enscript-keyword">if</span> ((pmap_cr3 == cpu_task_cr3) ||
		    (pmap_cr3 == cpu_active_cr3) ||
		    (pmap_is_shared)) {

			<span class="enscript-keyword">if</span> (options &amp; PMAP_DELAY_TLB_FLUSH) {
				<span class="enscript-keyword">if</span> (need_global_flush == TRUE)
					pfc-&gt;pfc_invalid_global |= cpu_bit;
				pfc-&gt;pfc_cpus |= cpu_bit;

				<span class="enscript-keyword">continue</span>;
			}
			<span class="enscript-keyword">if</span> (cpu == my_cpu) {
				flush_self = TRUE;
				<span class="enscript-keyword">continue</span>;
			}
			<span class="enscript-keyword">if</span> (need_global_flush == TRUE)
				cpu_datap(cpu)-&gt;cpu_tlb_invalid_global = TRUE;
			<span class="enscript-keyword">else</span>
				cpu_datap(cpu)-&gt;cpu_tlb_invalid_local = TRUE;
			mfence();

			<span class="enscript-comment">/*
			 * We don't need to signal processors which will flush
			 * lazily at the idle state or kernel boundary.
			 * For example, if we're invalidating the kernel pmap,
			 * processors currently in userspace don't need to flush
			 * their TLBs until the next time they enter the kernel.
			 * Alterations to the address space of a task active
			 * on a remote processor result in a signal, to
			 * account for copy operations. (There may be room
			 * for optimization in such cases).
			 * The order of the loads below with respect
			 * to the store to the &quot;cpu_tlb_invalid&quot; field above
			 * is important--hence the barrier.
			 */</span>
			<span class="enscript-keyword">if</span> (CPU_CR3_IS_ACTIVE(cpu) &amp;&amp;
			    (pmap_cr3 == CPU_GET_ACTIVE_CR3(cpu) ||
			     pmap-&gt;pm_shared ||
			     (pmap_cr3 == CPU_GET_TASK_CR3(cpu)))) {
				cpus_to_signal |= cpu_bit;
				i386_signal_cpu(cpu, MP_TLB_FLUSH, ASYNC);
			}
		}
	}
	<span class="enscript-keyword">if</span> ((options &amp; PMAP_DELAY_TLB_FLUSH))
		<span class="enscript-keyword">goto</span> <span class="enscript-reference">out</span>;

	<span class="enscript-comment">/*
	 * Flush local tlb if required.
	 * Do this now to overlap with other processors responding.
	 */</span>
	<span class="enscript-keyword">if</span> (flush_self) {
		<span class="enscript-keyword">if</span> (pmap_pcid_ncpus) {
			pmap_pcid_validate_cpu(pmap, my_cpu);
			<span class="enscript-keyword">if</span> (pmap_is_shared)
				tlb_flush_global();
			<span class="enscript-keyword">else</span>
				flush_tlb_raw();
		}
		<span class="enscript-keyword">else</span>
			flush_tlb_raw();
	}

	<span class="enscript-keyword">if</span> (cpus_to_signal) {
		cpumask_t	cpus_to_respond = cpus_to_signal;

		deadline = mach_absolute_time() +
				(TLBTimeOut ? TLBTimeOut : LockTimeOut);
		boolean_t is_timeout_traced = FALSE;

		<span class="enscript-comment">/*
		 * Wait for those other cpus to acknowledge
		 */</span>
		<span class="enscript-keyword">while</span> (cpus_to_respond != 0) {
			<span class="enscript-type">long</span> orig_acks = 0;

			<span class="enscript-keyword">for</span> (cpu = 0, cpu_bit = 1; cpu &lt; real_ncpus; cpu++, cpu_bit &lt;&lt;= 1) {
				<span class="enscript-comment">/* Consider checking local/global invalidity
				 * as appropriate in the PCID case.
				 */</span>
				<span class="enscript-keyword">if</span> ((cpus_to_respond &amp; cpu_bit) != 0) {
					<span class="enscript-keyword">if</span> (!cpu_datap(cpu)-&gt;cpu_running ||
					    cpu_datap(cpu)-&gt;cpu_tlb_invalid == FALSE ||
					    !CPU_CR3_IS_ACTIVE(cpu)) {
						cpus_to_respond &amp;= ~cpu_bit;
					}
					cpu_pause();
				}
				<span class="enscript-keyword">if</span> (cpus_to_respond == 0)
					<span class="enscript-keyword">break</span>;
			}
			<span class="enscript-keyword">if</span> (cpus_to_respond &amp;&amp; (mach_absolute_time() &gt; deadline)) {
				<span class="enscript-keyword">if</span> (machine_timeout_suspended())
					<span class="enscript-keyword">continue</span>;
				<span class="enscript-keyword">if</span> (TLBTimeOut == 0) {
					<span class="enscript-comment">/* cut tracepoint but don't panic */</span>
					<span class="enscript-keyword">if</span> (is_timeout_traced)
						<span class="enscript-keyword">continue</span>;
					PMAP_TRACE_CONSTANT(
						PMAP_CODE(PMAP__FLUSH_TLBS_TO),
				    		pmap, cpus_to_signal, cpus_to_respond, 0, 0);
					is_timeout_traced = TRUE;
					<span class="enscript-keyword">continue</span>;
				}
				pmap_tlb_flush_timeout = TRUE;
				orig_acks = NMIPI_acks;
				mp_cpus_NMIPI(cpus_to_respond);

				panic(<span class="enscript-string">&quot;TLB invalidation IPI timeout: &quot;</span>
				    <span class="enscript-string">&quot;CPU(s) failed to respond to interrupts, unresponsive CPU bitmap: 0x%llx, NMIPI acks: orig: 0x%lx, now: 0x%lx&quot;</span>,
				    cpus_to_respond, orig_acks, NMIPI_acks);
			}
		}
	}

	<span class="enscript-keyword">if</span> (__improbable((pmap == kernel_pmap) &amp;&amp; (flush_self != TRUE))) {
		panic(<span class="enscript-string">&quot;pmap_flush_tlbs: pmap == kernel_pmap &amp;&amp; flush_self != TRUE; kernel CR3: 0x%llX, pmap_cr3: 0x%llx, CPU active CR3: 0x%llX, CPU Task Map: %d&quot;</span>, kernel_pmap-&gt;pm_cr3, pmap_cr3, current_cpu_datap()-&gt;cpu_active_cr3, current_cpu_datap()-&gt;cpu_task_map);
	}

<span class="enscript-reference">out</span>:
	PMAP_TRACE_CONSTANT(event_code | DBG_FUNC_END,
			    pmap, cpus_to_signal, startv, endv, 0);

}

<span class="enscript-type">void</span>
<span class="enscript-function-name">process_pmap_updates</span>(<span class="enscript-type">void</span>)
{
	<span class="enscript-type">int</span> ccpu = cpu_number();
	pmap_assert(ml_get_interrupts_enabled() == 0 || get_preemption_level() != 0);
	<span class="enscript-keyword">if</span> (pmap_pcid_ncpus) {
		pmap_pcid_validate_current();
		<span class="enscript-keyword">if</span> (cpu_datap(ccpu)-&gt;cpu_tlb_invalid_global) {
			cpu_datap(ccpu)-&gt;cpu_tlb_invalid = FALSE;
			tlb_flush_global();
		}
		<span class="enscript-keyword">else</span> {
			cpu_datap(ccpu)-&gt;cpu_tlb_invalid_local = FALSE;
			flush_tlb_raw();
		}
	}
	<span class="enscript-keyword">else</span> {
		current_cpu_datap()-&gt;cpu_tlb_invalid = FALSE;
		flush_tlb_raw();
	}

	mfence();
}

<span class="enscript-type">void</span>
<span class="enscript-function-name">pmap_update_interrupt</span>(<span class="enscript-type">void</span>)
{
        PMAP_TRACE(PMAP_CODE(PMAP__UPDATE_INTERRUPT) | DBG_FUNC_START,
		   0, 0, 0, 0, 0);

	<span class="enscript-keyword">if</span> (current_cpu_datap()-&gt;cpu_tlb_invalid)
		process_pmap_updates();

        PMAP_TRACE(PMAP_CODE(PMAP__UPDATE_INTERRUPT) | DBG_FUNC_END,
		   0, 0, 0, 0, 0);
}

#<span class="enscript-reference">include</span> <span class="enscript-string">&lt;mach/mach_vm.h&gt;</span>	<span class="enscript-comment">/* mach_vm_region_recurse() */</span>
<span class="enscript-comment">/* Scan kernel pmap for W+X PTEs, scan kernel VM map for W+X map entries
 * and identify ranges with mismatched VM permissions and PTE permissions
 */</span>
kern_return_t
<span class="enscript-function-name">pmap_permissions_verify</span>(pmap_t ipmap, vm_map_t ivmmap, vm_offset_t sv, vm_offset_t ev) {
	vm_offset_t cv = sv;
	kern_return_t rv = KERN_SUCCESS;
	uint64_t skip4 = 0, skip2 = 0;

	assert(!is_ept_pmap(ipmap));

	sv &amp;= ~PAGE_MASK_64;
	ev &amp;= ~PAGE_MASK_64;
	<span class="enscript-keyword">while</span> (cv &lt; ev) {
		<span class="enscript-keyword">if</span> (__improbable((cv &gt; 0x00007FFFFFFFFFFFULL) &amp;&amp;
			(cv &lt; 0xFFFF800000000000ULL))) {
			cv = 0xFFFF800000000000ULL;
		}
		<span class="enscript-comment">/* Potential inconsistencies from not holding pmap lock
		 * but harmless for the moment.
		 */</span>
		<span class="enscript-keyword">if</span> (((cv &amp; PML4MASK) == 0) &amp;&amp; (pmap64_pml4(ipmap, cv) == 0)) {
			<span class="enscript-keyword">if</span> ((cv + NBPML4) &gt; cv)
				cv += NBPML4;
			<span class="enscript-keyword">else</span>
				<span class="enscript-keyword">break</span>;
			skip4++;
			<span class="enscript-keyword">continue</span>;
		}
		<span class="enscript-keyword">if</span> (((cv &amp; PDMASK) == 0) &amp;&amp; (pmap_pde(ipmap, cv) == 0)) {
			<span class="enscript-keyword">if</span> ((cv + NBPD) &gt; cv)
				cv += NBPD;
			<span class="enscript-keyword">else</span>
				<span class="enscript-keyword">break</span>;
			skip2++;
			<span class="enscript-keyword">continue</span>;
		}

		pt_entry_t *ptep = pmap_pte(ipmap, cv);
		<span class="enscript-keyword">if</span> (ptep &amp;&amp; (*ptep &amp; INTEL_PTE_VALID)) {
			<span class="enscript-keyword">if</span> (*ptep &amp; INTEL_PTE_WRITE) {
				<span class="enscript-keyword">if</span> (!(*ptep &amp; INTEL_PTE_NX)) {
					kprintf(<span class="enscript-string">&quot;W+X PTE at 0x%lx, P4: 0x%llx, P3: 0x%llx, P2: 0x%llx, PT: 0x%llx, VP: %u\n&quot;</span>, cv, *pmap64_pml4(ipmap, cv), *pmap64_pdpt(ipmap, cv), *pmap64_pde(ipmap, cv), *ptep, pmap_valid_page((ppnum_t)(i386_btop(pte_to_pa(*ptep)))));
					rv = KERN_FAILURE;
				}
			}
		}
		cv += PAGE_SIZE;
	}
	kprintf(<span class="enscript-string">&quot;Completed pmap scan\n&quot;</span>);
	cv = sv;

	<span class="enscript-type">struct</span> vm_region_submap_info_64 vbr;
	mach_msg_type_number_t vbrcount = 0;
	mach_vm_size_t	vmsize;
	vm_prot_t	prot;
	uint32_t nesting_depth = 0;
	kern_return_t kret;
	
	<span class="enscript-keyword">while</span> (cv &lt; ev) {
		
		<span class="enscript-keyword">for</span> (;;) {
			vbrcount = VM_REGION_SUBMAP_INFO_COUNT_64;
			<span class="enscript-keyword">if</span>((kret = mach_vm_region_recurse(ivmmap, 
				    (mach_vm_address_t *) &amp;cv, &amp;vmsize, &amp;nesting_depth, 
					(vm_region_recurse_info_t)&amp;vbr,
					&amp;vbrcount)) != KERN_SUCCESS) {
				<span class="enscript-keyword">break</span>;
			}

			<span class="enscript-keyword">if</span>(vbr.is_submap) {
				nesting_depth++;
				<span class="enscript-keyword">continue</span>;
			} <span class="enscript-keyword">else</span> {
				<span class="enscript-keyword">break</span>;
			}
		}

		<span class="enscript-keyword">if</span>(kret != KERN_SUCCESS)
			<span class="enscript-keyword">break</span>;

		prot = vbr.protection;

		<span class="enscript-keyword">if</span> ((prot &amp; (VM_PROT_WRITE | VM_PROT_EXECUTE)) == (VM_PROT_WRITE | VM_PROT_EXECUTE)) {
			kprintf(<span class="enscript-string">&quot;W+X map entry at address 0x%lx\n&quot;</span>, cv);
			rv = KERN_FAILURE;
		}

		<span class="enscript-keyword">if</span> (prot) {
			vm_offset_t pcv;
			<span class="enscript-keyword">for</span> (pcv = cv; pcv &lt; cv + vmsize; pcv += PAGE_SIZE) {
				pt_entry_t *ptep = pmap_pte(ipmap, pcv);
				vm_prot_t tprot;

				<span class="enscript-keyword">if</span> ((ptep == NULL) || !(*ptep &amp; INTEL_PTE_VALID))
					<span class="enscript-keyword">continue</span>;
				tprot = VM_PROT_READ;
				<span class="enscript-keyword">if</span> (*ptep &amp; INTEL_PTE_WRITE)
					tprot |= VM_PROT_WRITE;
				<span class="enscript-keyword">if</span> ((*ptep &amp; INTEL_PTE_NX) == 0)
					tprot |= VM_PROT_EXECUTE;
				<span class="enscript-keyword">if</span> (tprot != prot) {
					kprintf(<span class="enscript-string">&quot;PTE/map entry permissions mismatch at address 0x%lx, pte: 0x%llx, protection: 0x%x\n&quot;</span>, pcv, *ptep, prot);
					rv = KERN_FAILURE;
				}
			}
		}
		cv += vmsize;
	}
	<span class="enscript-keyword">return</span> rv;
}
</pre>
<hr />
</body></html>