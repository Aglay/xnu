<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
    "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
<title>vm_user.c</title>
<style type="text/css">
.enscript-comment { font-style: italic; color: rgb(178,34,34); }
.enscript-function-name { font-weight: bold; color: rgb(0,0,255); }
.enscript-variable-name { font-weight: bold; color: rgb(184,134,11); }
.enscript-keyword { font-weight: bold; color: rgb(160,32,240); }
.enscript-reference { font-weight: bold; color: rgb(95,158,160); }
.enscript-string { font-weight: bold; color: rgb(188,143,143); }
.enscript-builtin { font-weight: bold; color: rgb(218,112,214); }
.enscript-type { font-weight: bold; color: rgb(34,139,34); }
.enscript-highlight { text-decoration: underline; color: 0; }
</style>
</head>
<body id="top">
<h1 style="margin:8px;" id="f1">vm_user.c&nbsp;&nbsp;&nbsp;<span style="font-weight: normal; font-size: 0.5em;">[<a href="?txt">plain text</a>]</span></h1>
<hr/>
<div></div>
<pre>
<span class="enscript-comment">/*
 * Copyright (c) 2000-2007 Apple Inc. All rights reserved.
 *
 * @APPLE_OSREFERENCE_LICENSE_HEADER_START@
 * 
 * This file contains Original Code and/or Modifications of Original Code
 * as defined in and that are subject to the Apple Public Source License
 * Version 2.0 (the 'License'). You may not use this file except in
 * compliance with the License. The rights granted to you under the License
 * may not be used to create, or enable the creation or redistribution of,
 * unlawful or unlicensed copies of an Apple operating system, or to
 * circumvent, violate, or enable the circumvention or violation of, any
 * terms of an Apple operating system software license agreement.
 * 
 * Please obtain a copy of the License at
 * <a href="http://www.opensource.apple.com/apsl/">http://www.opensource.apple.com/apsl/</a> and read it before using this file.
 * 
 * The Original Code and all software distributed under the License are
 * distributed on an 'AS IS' basis, WITHOUT WARRANTY OF ANY KIND, EITHER
 * EXPRESS OR IMPLIED, AND APPLE HEREBY DISCLAIMS ALL SUCH WARRANTIES,
 * INCLUDING WITHOUT LIMITATION, ANY WARRANTIES OF MERCHANTABILITY,
 * FITNESS FOR A PARTICULAR PURPOSE, QUIET ENJOYMENT OR NON-INFRINGEMENT.
 * Please see the License for the specific language governing rights and
 * limitations under the License.
 * 
 * @APPLE_OSREFERENCE_LICENSE_HEADER_END@
 */</span>
<span class="enscript-comment">/*
 * @OSF_COPYRIGHT@
 */</span>
<span class="enscript-comment">/* 
 * Mach Operating System
 * Copyright (c) 1991,1990,1989,1988 Carnegie Mellon University
 * All Rights Reserved.
 * 
 * Permission to use, copy, modify and distribute this software and its
 * documentation is hereby granted, provided that both the copyright
 * notice and this permission notice appear in all copies of the
 * software, derivative works or modified versions, and any portions
 * thereof, and that both notices appear in supporting documentation.
 * 
 * CARNEGIE MELLON ALLOWS FREE USE OF THIS SOFTWARE IN ITS &quot;AS IS&quot;
 * CONDITION.  CARNEGIE MELLON DISCLAIMS ANY LIABILITY OF ANY KIND FOR
 * ANY DAMAGES WHATSOEVER RESULTING FROM THE USE OF THIS SOFTWARE.
 * 
 * Carnegie Mellon requests users of this software to return to
 * 
 *  Software Distribution Coordinator  or  <a href="mailto:Software.Distribution@CS.CMU.EDU">Software.Distribution@CS.CMU.EDU</a>
 *  School of Computer Science
 *  Carnegie Mellon University
 *  Pittsburgh PA 15213-3890
 * 
 * any improvements or extensions that they make and grant Carnegie Mellon
 * the rights to redistribute these changes.
 */</span>
<span class="enscript-comment">/*
 */</span>
<span class="enscript-comment">/*
 *	File:	vm/vm_user.c
 *	Author:	Avadis Tevanian, Jr., Michael Wayne Young
 * 
 *	User-exported virtual memory functions.
 */</span>

<span class="enscript-comment">/*
 * There are three implementations of the &quot;XXX_allocate&quot; functionality in
 * the kernel: mach_vm_allocate (for any task on the platform), vm_allocate
 * (for a task with the same address space size, especially the current task),
 * and vm32_vm_allocate (for the specific case of a 32-bit task). vm_allocate
 * in the kernel should only be used on the kernel_task. vm32_vm_allocate only
 * makes sense on platforms where a user task can either be 32 or 64, or the kernel
 * task can be 32 or 64. mach_vm_allocate makes sense everywhere, and is preferred
 * for new code.
 *
 * The entrypoints into the kernel are more complex. All platforms support a
 * mach_vm_allocate-style API (subsystem 4800) which operates with the largest
 * size types for the platform. On platforms that only support U32/K32,
 * subsystem 4800 is all you need. On platforms that support both U32 and U64,
 * subsystem 3800 is used disambiguate the size of parameters, and they will
 * always be 32-bit and call into the vm32_vm_allocate APIs. On non-U32/K32 platforms,
 * the MIG glue should never call into vm_allocate directly, because the calling
 * task and kernel_task are unlikely to use the same size parameters
 *
 * New VM call implementations should be added here and to mach_vm.defs
 * (subsystem 4800), and use mach_vm_* &quot;wide&quot; types.
 */</span>

#<span class="enscript-reference">include</span> <span class="enscript-string">&lt;debug.h&gt;</span>

#<span class="enscript-reference">include</span> <span class="enscript-string">&lt;vm_cpm.h&gt;</span>
#<span class="enscript-reference">include</span> <span class="enscript-string">&lt;mach/boolean.h&gt;</span>
#<span class="enscript-reference">include</span> <span class="enscript-string">&lt;mach/kern_return.h&gt;</span>
#<span class="enscript-reference">include</span> <span class="enscript-string">&lt;mach/mach_types.h&gt;</span>	<span class="enscript-comment">/* to get vm_address_t */</span>
#<span class="enscript-reference">include</span> <span class="enscript-string">&lt;mach/memory_object.h&gt;</span>
#<span class="enscript-reference">include</span> <span class="enscript-string">&lt;mach/std_types.h&gt;</span>	<span class="enscript-comment">/* to get pointer_t */</span>
#<span class="enscript-reference">include</span> <span class="enscript-string">&lt;mach/upl.h&gt;</span>
#<span class="enscript-reference">include</span> <span class="enscript-string">&lt;mach/vm_attributes.h&gt;</span>
#<span class="enscript-reference">include</span> <span class="enscript-string">&lt;mach/vm_param.h&gt;</span>
#<span class="enscript-reference">include</span> <span class="enscript-string">&lt;mach/vm_statistics.h&gt;</span>
#<span class="enscript-reference">include</span> <span class="enscript-string">&lt;mach/mach_syscalls.h&gt;</span>

#<span class="enscript-reference">include</span> <span class="enscript-string">&lt;mach/host_priv_server.h&gt;</span>
#<span class="enscript-reference">include</span> <span class="enscript-string">&lt;mach/mach_vm_server.h&gt;</span>
#<span class="enscript-reference">include</span> <span class="enscript-string">&lt;mach/vm_map_server.h&gt;</span>

#<span class="enscript-reference">include</span> <span class="enscript-string">&lt;kern/host.h&gt;</span>
#<span class="enscript-reference">include</span> <span class="enscript-string">&lt;kern/kalloc.h&gt;</span>
#<span class="enscript-reference">include</span> <span class="enscript-string">&lt;kern/task.h&gt;</span>
#<span class="enscript-reference">include</span> <span class="enscript-string">&lt;kern/misc_protos.h&gt;</span>
#<span class="enscript-reference">include</span> <span class="enscript-string">&lt;vm/vm_fault.h&gt;</span>
#<span class="enscript-reference">include</span> <span class="enscript-string">&lt;vm/vm_map.h&gt;</span>
#<span class="enscript-reference">include</span> <span class="enscript-string">&lt;vm/vm_object.h&gt;</span>
#<span class="enscript-reference">include</span> <span class="enscript-string">&lt;vm/vm_page.h&gt;</span>
#<span class="enscript-reference">include</span> <span class="enscript-string">&lt;vm/memory_object.h&gt;</span>
#<span class="enscript-reference">include</span> <span class="enscript-string">&lt;vm/vm_pageout.h&gt;</span>
#<span class="enscript-reference">include</span> <span class="enscript-string">&lt;vm/vm_protos.h&gt;</span>
#<span class="enscript-reference">include</span> <span class="enscript-string">&lt;vm/vm_purgeable_internal.h&gt;</span>

vm_size_t        upl_offset_to_pagelist = 0;

#<span class="enscript-reference">if</span>	<span class="enscript-variable-name">VM_CPM</span>
#<span class="enscript-reference">include</span> <span class="enscript-string">&lt;vm/cpm.h&gt;</span>
#<span class="enscript-reference">endif</span>	<span class="enscript-comment">/* VM_CPM */</span>

ipc_port_t	dynamic_pager_control_port=NULL;

<span class="enscript-comment">/*
 *	mach_vm_allocate allocates &quot;zero fill&quot; memory in the specfied
 *	map.
 */</span>
kern_return_t
<span class="enscript-function-name">mach_vm_allocate</span>(
	vm_map_t		map,
	mach_vm_offset_t	*addr,
	mach_vm_size_t	size,
	<span class="enscript-type">int</span>			flags)
{
	vm_map_offset_t map_addr;
	vm_map_size_t	map_size;
	kern_return_t	result;
	boolean_t	anywhere;

	<span class="enscript-comment">/* filter out any kernel-only flags */</span>
	<span class="enscript-keyword">if</span> (flags &amp; ~VM_FLAGS_USER_ALLOCATE)
		<span class="enscript-keyword">return</span> KERN_INVALID_ARGUMENT;

	<span class="enscript-keyword">if</span> (map == VM_MAP_NULL)
		<span class="enscript-keyword">return</span>(KERN_INVALID_ARGUMENT);
	<span class="enscript-keyword">if</span> (size == 0) {
		*addr = 0;
		<span class="enscript-keyword">return</span>(KERN_SUCCESS);
	}

	anywhere = ((VM_FLAGS_ANYWHERE &amp; flags) != 0);
	<span class="enscript-keyword">if</span> (anywhere) {
		<span class="enscript-comment">/*
		 * No specific address requested, so start candidate address
		 * search at the minimum address in the map.  However, if that
		 * minimum is 0, bump it up by PAGE_SIZE.  We want to limit
		 * allocations of PAGEZERO to explicit requests since its
		 * normal use is to catch dereferences of NULL and many
		 * applications also treat pointers with a value of 0 as
		 * special and suddenly having address 0 contain useable
		 * memory would tend to confuse those applications.
		 */</span>
		map_addr = vm_map_min(map);
		<span class="enscript-keyword">if</span> (map_addr == 0)
			map_addr += VM_MAP_PAGE_SIZE(map);
	} <span class="enscript-keyword">else</span>
		map_addr = vm_map_trunc_page(*addr,
					     VM_MAP_PAGE_MASK(map));
	map_size = vm_map_round_page(size,
				     VM_MAP_PAGE_MASK(map));
	<span class="enscript-keyword">if</span> (map_size == 0) {
	  <span class="enscript-keyword">return</span>(KERN_INVALID_ARGUMENT);
	}

	result = vm_map_enter(
			map,
			&amp;map_addr,
			map_size,
			(vm_map_offset_t)0,
			flags,
			VM_OBJECT_NULL,
			(vm_object_offset_t)0,
			FALSE,
			VM_PROT_DEFAULT,
			VM_PROT_ALL,
			VM_INHERIT_DEFAULT);

	*addr = map_addr;
	<span class="enscript-keyword">return</span>(result);
}

<span class="enscript-comment">/*
 *	vm_allocate 
 *	Legacy routine that allocates &quot;zero fill&quot; memory in the specfied
 *	map (which is limited to the same size as the kernel).
 */</span>
kern_return_t
<span class="enscript-function-name">vm_allocate</span>(
	vm_map_t	map,
	vm_offset_t	*addr,
	vm_size_t	size,
	<span class="enscript-type">int</span>		flags)
{
	vm_map_offset_t map_addr;
	vm_map_size_t	map_size;
	kern_return_t	result;
	boolean_t	anywhere;

	<span class="enscript-comment">/* filter out any kernel-only flags */</span>
	<span class="enscript-keyword">if</span> (flags &amp; ~VM_FLAGS_USER_ALLOCATE)
		<span class="enscript-keyword">return</span> KERN_INVALID_ARGUMENT;

	<span class="enscript-keyword">if</span> (map == VM_MAP_NULL)
		<span class="enscript-keyword">return</span>(KERN_INVALID_ARGUMENT);
	<span class="enscript-keyword">if</span> (size == 0) {
		*addr = 0;
		<span class="enscript-keyword">return</span>(KERN_SUCCESS);
	}

	anywhere = ((VM_FLAGS_ANYWHERE &amp; flags) != 0);
	<span class="enscript-keyword">if</span> (anywhere) {
		<span class="enscript-comment">/*
		 * No specific address requested, so start candidate address
		 * search at the minimum address in the map.  However, if that
		 * minimum is 0, bump it up by PAGE_SIZE.  We want to limit
		 * allocations of PAGEZERO to explicit requests since its
		 * normal use is to catch dereferences of NULL and many
		 * applications also treat pointers with a value of 0 as
		 * special and suddenly having address 0 contain useable
		 * memory would tend to confuse those applications.
		 */</span>
		map_addr = vm_map_min(map);
		<span class="enscript-keyword">if</span> (map_addr == 0)
			map_addr += VM_MAP_PAGE_SIZE(map);
	} <span class="enscript-keyword">else</span>
		map_addr = vm_map_trunc_page(*addr,
					     VM_MAP_PAGE_MASK(map));
	map_size = vm_map_round_page(size,
				     VM_MAP_PAGE_MASK(map));
	<span class="enscript-keyword">if</span> (map_size == 0) {
	  <span class="enscript-keyword">return</span>(KERN_INVALID_ARGUMENT);
	}

	result = vm_map_enter(
			map,
			&amp;map_addr,
			map_size,
			(vm_map_offset_t)0,
			flags,
			VM_OBJECT_NULL,
			(vm_object_offset_t)0,
			FALSE,
			VM_PROT_DEFAULT,
			VM_PROT_ALL,
			VM_INHERIT_DEFAULT);

	*addr = CAST_DOWN(vm_offset_t, map_addr);
	<span class="enscript-keyword">return</span>(result);
}

<span class="enscript-comment">/*
 *	mach_vm_deallocate -
 *	deallocates the specified range of addresses in the
 *	specified address map.
 */</span>
kern_return_t
<span class="enscript-function-name">mach_vm_deallocate</span>(
	vm_map_t		map,
	mach_vm_offset_t	start,
	mach_vm_size_t	size)
{
	<span class="enscript-keyword">if</span> ((map == VM_MAP_NULL) || (start + size &lt; start))
		<span class="enscript-keyword">return</span>(KERN_INVALID_ARGUMENT);

	<span class="enscript-keyword">if</span> (size == (mach_vm_offset_t) 0)
		<span class="enscript-keyword">return</span>(KERN_SUCCESS);

	<span class="enscript-keyword">return</span>(vm_map_remove(map,
			     vm_map_trunc_page(start,
					       VM_MAP_PAGE_MASK(map)),
			     vm_map_round_page(start+size,
					       VM_MAP_PAGE_MASK(map)),
			     VM_MAP_NO_FLAGS));
}

<span class="enscript-comment">/*
 *	vm_deallocate -
 *	deallocates the specified range of addresses in the
 *	specified address map (limited to addresses the same
 *	size as the kernel).
 */</span>
kern_return_t
<span class="enscript-function-name">vm_deallocate</span>(
	<span class="enscript-type">register</span> vm_map_t	map,
	vm_offset_t		start,
	vm_size_t		size)
{
	<span class="enscript-keyword">if</span> ((map == VM_MAP_NULL) || (start + size &lt; start))
		<span class="enscript-keyword">return</span>(KERN_INVALID_ARGUMENT);

	<span class="enscript-keyword">if</span> (size == (vm_offset_t) 0)
		<span class="enscript-keyword">return</span>(KERN_SUCCESS);

	<span class="enscript-keyword">return</span>(vm_map_remove(map,
			     vm_map_trunc_page(start,
					       VM_MAP_PAGE_MASK(map)),
			     vm_map_round_page(start+size,
					       VM_MAP_PAGE_MASK(map)),
			     VM_MAP_NO_FLAGS));
}

<span class="enscript-comment">/*
 *	mach_vm_inherit -
 *	Sets the inheritance of the specified range in the
 *	specified map.
 */</span>
kern_return_t
<span class="enscript-function-name">mach_vm_inherit</span>(
	vm_map_t		map,
	mach_vm_offset_t	start,
	mach_vm_size_t	size,
	vm_inherit_t		new_inheritance)
{
	<span class="enscript-keyword">if</span> ((map == VM_MAP_NULL) || (start + size &lt; start) ||
	    (new_inheritance &gt; VM_INHERIT_LAST_VALID))
                <span class="enscript-keyword">return</span>(KERN_INVALID_ARGUMENT);

	<span class="enscript-keyword">if</span> (size == 0)
		<span class="enscript-keyword">return</span> KERN_SUCCESS;

	<span class="enscript-keyword">return</span>(vm_map_inherit(map,
			      vm_map_trunc_page(start,
						VM_MAP_PAGE_MASK(map)),
			      vm_map_round_page(start+size,
						VM_MAP_PAGE_MASK(map)),
			      new_inheritance));
}

<span class="enscript-comment">/*
 *	vm_inherit -
 *	Sets the inheritance of the specified range in the
 *	specified map (range limited to addresses
 */</span>
kern_return_t
<span class="enscript-function-name">vm_inherit</span>(
	<span class="enscript-type">register</span> vm_map_t	map,
	vm_offset_t		start,
	vm_size_t		size,
	vm_inherit_t		new_inheritance)
{
	<span class="enscript-keyword">if</span> ((map == VM_MAP_NULL) || (start + size &lt; start) ||
	    (new_inheritance &gt; VM_INHERIT_LAST_VALID))
                <span class="enscript-keyword">return</span>(KERN_INVALID_ARGUMENT);

	<span class="enscript-keyword">if</span> (size == 0)
		<span class="enscript-keyword">return</span> KERN_SUCCESS;

	<span class="enscript-keyword">return</span>(vm_map_inherit(map,
			      vm_map_trunc_page(start,
						VM_MAP_PAGE_MASK(map)),
			      vm_map_round_page(start+size,
						VM_MAP_PAGE_MASK(map)),
			      new_inheritance));
}

<span class="enscript-comment">/*
 *	mach_vm_protect -
 *	Sets the protection of the specified range in the
 *	specified map.
 */</span>

kern_return_t
<span class="enscript-function-name">mach_vm_protect</span>(
	vm_map_t		map,
	mach_vm_offset_t	start,
	mach_vm_size_t	size,
	boolean_t		set_maximum,
	vm_prot_t		new_protection)
{
	<span class="enscript-keyword">if</span> ((map == VM_MAP_NULL) || (start + size &lt; start) ||
	    (new_protection &amp; ~(VM_PROT_ALL | VM_PROT_COPY)))
		<span class="enscript-keyword">return</span>(KERN_INVALID_ARGUMENT);

	<span class="enscript-keyword">if</span> (size == 0)
		<span class="enscript-keyword">return</span> KERN_SUCCESS;

	<span class="enscript-keyword">return</span>(vm_map_protect(map,
			      vm_map_trunc_page(start,
						VM_MAP_PAGE_MASK(map)),
			      vm_map_round_page(start+size,
						VM_MAP_PAGE_MASK(map)),
			      new_protection,
			      set_maximum));
}

<span class="enscript-comment">/*
 *	vm_protect -
 *	Sets the protection of the specified range in the
 *	specified map. Addressability of the range limited
 *	to the same size as the kernel.
 */</span>

kern_return_t
<span class="enscript-function-name">vm_protect</span>(
	vm_map_t		map,
	vm_offset_t		start,
	vm_size_t		size,
	boolean_t		set_maximum,
	vm_prot_t		new_protection)
{
	<span class="enscript-keyword">if</span> ((map == VM_MAP_NULL) || (start + size &lt; start) ||
	    (new_protection &amp; ~(VM_PROT_ALL | VM_PROT_COPY)))
		<span class="enscript-keyword">return</span>(KERN_INVALID_ARGUMENT);

	<span class="enscript-keyword">if</span> (size == 0)
		<span class="enscript-keyword">return</span> KERN_SUCCESS;

	<span class="enscript-keyword">return</span>(vm_map_protect(map,
			      vm_map_trunc_page(start,
						VM_MAP_PAGE_MASK(map)),
			      vm_map_round_page(start+size,
						VM_MAP_PAGE_MASK(map)),
			      new_protection,
			      set_maximum));
}

<span class="enscript-comment">/*
 * mach_vm_machine_attributes -
 * Handle machine-specific attributes for a mapping, such
 * as cachability, migrability, etc.
 */</span>
kern_return_t
<span class="enscript-function-name">mach_vm_machine_attribute</span>(
	vm_map_t			map,
	mach_vm_address_t		addr,
	mach_vm_size_t		size,
	vm_machine_attribute_t	attribute,
	vm_machine_attribute_val_t* value)		<span class="enscript-comment">/* IN/OUT */</span>
{
	<span class="enscript-keyword">if</span> ((map == VM_MAP_NULL) || (addr + size &lt; addr))
		<span class="enscript-keyword">return</span>(KERN_INVALID_ARGUMENT);

	<span class="enscript-keyword">if</span> (size == 0)
		<span class="enscript-keyword">return</span> KERN_SUCCESS;

	<span class="enscript-keyword">return</span> vm_map_machine_attribute(
		map, 
		vm_map_trunc_page(addr,
				  VM_MAP_PAGE_MASK(map)),
		vm_map_round_page(addr+size,
				  VM_MAP_PAGE_MASK(map)),
		attribute,
		value);
}

<span class="enscript-comment">/*
 * vm_machine_attribute -
 * Handle machine-specific attributes for a mapping, such
 * as cachability, migrability, etc. Limited addressability
 * (same range limits as for the native kernel map).
 */</span>
kern_return_t
<span class="enscript-function-name">vm_machine_attribute</span>(
	vm_map_t	map,
	vm_address_t	addr,
	vm_size_t	size,
	vm_machine_attribute_t	attribute,
	vm_machine_attribute_val_t* value)		<span class="enscript-comment">/* IN/OUT */</span>
{
	<span class="enscript-keyword">if</span> ((map == VM_MAP_NULL) || (addr + size &lt; addr))
		<span class="enscript-keyword">return</span>(KERN_INVALID_ARGUMENT);

	<span class="enscript-keyword">if</span> (size == 0)
		<span class="enscript-keyword">return</span> KERN_SUCCESS;

	<span class="enscript-keyword">return</span> vm_map_machine_attribute(
		map, 
		vm_map_trunc_page(addr,
				  VM_MAP_PAGE_MASK(map)),
		vm_map_round_page(addr+size,
				  VM_MAP_PAGE_MASK(map)),
		attribute,
		value);
}

<span class="enscript-comment">/*
 * mach_vm_read -
 * Read/copy a range from one address space and return it to the caller.
 *
 * It is assumed that the address for the returned memory is selected by
 * the IPC implementation as part of receiving the reply to this call.
 * If IPC isn't used, the caller must deal with the vm_map_copy_t object
 * that gets returned.
 * 
 * JMM - because of mach_msg_type_number_t, this call is limited to a
 * single 4GB region at this time.
 *
 */</span>
kern_return_t
<span class="enscript-function-name">mach_vm_read</span>(
	vm_map_t		map,
	mach_vm_address_t	addr,
	mach_vm_size_t	size,
	pointer_t		*data,
	mach_msg_type_number_t	*data_size)
{
	kern_return_t	error;
	vm_map_copy_t	ipc_address;

	<span class="enscript-keyword">if</span> (map == VM_MAP_NULL)
		<span class="enscript-keyword">return</span>(KERN_INVALID_ARGUMENT);

	<span class="enscript-keyword">if</span> ((mach_msg_type_number_t) size != size)
		<span class="enscript-keyword">return</span> KERN_INVALID_ARGUMENT;
	
	error = vm_map_copyin(map,
			(vm_map_address_t)addr,
			(vm_map_size_t)size,
			FALSE,	<span class="enscript-comment">/* src_destroy */</span>
			&amp;ipc_address);

	<span class="enscript-keyword">if</span> (KERN_SUCCESS == error) {
		*data = (pointer_t) ipc_address;
		*data_size = (mach_msg_type_number_t) size;
		assert(*data_size == size);
	}
	<span class="enscript-keyword">return</span>(error);
}

<span class="enscript-comment">/*
 * vm_read -
 * Read/copy a range from one address space and return it to the caller.
 * Limited addressability (same range limits as for the native kernel map).
 * 
 * It is assumed that the address for the returned memory is selected by
 * the IPC implementation as part of receiving the reply to this call.
 * If IPC isn't used, the caller must deal with the vm_map_copy_t object
 * that gets returned.
 */</span>
kern_return_t
<span class="enscript-function-name">vm_read</span>(
	vm_map_t		map,
	vm_address_t		addr,
	vm_size_t		size,
	pointer_t		*data,
	mach_msg_type_number_t	*data_size)
{
	kern_return_t	error;
	vm_map_copy_t	ipc_address;

	<span class="enscript-keyword">if</span> (map == VM_MAP_NULL)
		<span class="enscript-keyword">return</span>(KERN_INVALID_ARGUMENT);

	<span class="enscript-keyword">if</span> (size &gt; (<span class="enscript-type">unsigned</span>)(mach_msg_type_number_t) -1) {
		<span class="enscript-comment">/*
		 * The kernel could handle a 64-bit &quot;size&quot; value, but
		 * it could not return the size of the data in &quot;*data_size&quot;
		 * without overflowing.
		 * Let's reject this &quot;size&quot; as invalid.
		 */</span>
		<span class="enscript-keyword">return</span> KERN_INVALID_ARGUMENT;
	}

	error = vm_map_copyin(map,
			(vm_map_address_t)addr,
			(vm_map_size_t)size,
			FALSE,	<span class="enscript-comment">/* src_destroy */</span>
			&amp;ipc_address);

	<span class="enscript-keyword">if</span> (KERN_SUCCESS == error) {
		*data = (pointer_t) ipc_address;
		*data_size = (mach_msg_type_number_t) size;
		assert(*data_size == size);
	}
	<span class="enscript-keyword">return</span>(error);
}

<span class="enscript-comment">/* 
 * mach_vm_read_list -
 * Read/copy a list of address ranges from specified map.
 *
 * MIG does not know how to deal with a returned array of
 * vm_map_copy_t structures, so we have to do the copyout
 * manually here.
 */</span>
kern_return_t
<span class="enscript-function-name">mach_vm_read_list</span>(
	vm_map_t			map,
	mach_vm_read_entry_t		data_list,
	natural_t			count)
{
	mach_msg_type_number_t	i;
	kern_return_t	error;
	vm_map_copy_t	copy;

	<span class="enscript-keyword">if</span> (map == VM_MAP_NULL ||
	    count &gt; VM_MAP_ENTRY_MAX)
		<span class="enscript-keyword">return</span>(KERN_INVALID_ARGUMENT);

	error = KERN_SUCCESS;
	<span class="enscript-keyword">for</span>(i=0; i&lt;count; i++) {
		vm_map_address_t map_addr;
		vm_map_size_t map_size;

		map_addr = (vm_map_address_t)(data_list[i].address);
		map_size = (vm_map_size_t)(data_list[i].size);

		<span class="enscript-keyword">if</span>(map_size != 0) {
			error = vm_map_copyin(map,
					map_addr,
					map_size,
					FALSE,	<span class="enscript-comment">/* src_destroy */</span>
					&amp;copy);
			<span class="enscript-keyword">if</span> (KERN_SUCCESS == error) {
				error = vm_map_copyout(
						current_task()-&gt;map, 
						&amp;map_addr,
						copy);
				<span class="enscript-keyword">if</span> (KERN_SUCCESS == error) {
					data_list[i].address = map_addr;
					<span class="enscript-keyword">continue</span>;
				}
				vm_map_copy_discard(copy);
			}
		}
		data_list[i].address = (mach_vm_address_t)0;
		data_list[i].size = (mach_vm_size_t)0;
	}
	<span class="enscript-keyword">return</span>(error);
}

<span class="enscript-comment">/* 
 * vm_read_list -
 * Read/copy a list of address ranges from specified map.
 *
 * MIG does not know how to deal with a returned array of
 * vm_map_copy_t structures, so we have to do the copyout
 * manually here.
 *
 * The source and destination ranges are limited to those
 * that can be described with a vm_address_t (i.e. same
 * size map as the kernel).
 *
 * JMM - If the result of the copyout is an address range
 * that cannot be described with a vm_address_t (i.e. the
 * caller had a larger address space but used this call
 * anyway), it will result in a truncated address being
 * returned (and a likely confused caller).
 */</span>

kern_return_t
<span class="enscript-function-name">vm_read_list</span>(
	vm_map_t		map,
	vm_read_entry_t	data_list,
	natural_t		count)
{
	mach_msg_type_number_t	i;
	kern_return_t	error;
	vm_map_copy_t	copy;

	<span class="enscript-keyword">if</span> (map == VM_MAP_NULL ||
	    count &gt; VM_MAP_ENTRY_MAX)
		<span class="enscript-keyword">return</span>(KERN_INVALID_ARGUMENT);

	error = KERN_SUCCESS;
	<span class="enscript-keyword">for</span>(i=0; i&lt;count; i++) {
		vm_map_address_t map_addr;
		vm_map_size_t map_size;

		map_addr = (vm_map_address_t)(data_list[i].address);
		map_size = (vm_map_size_t)(data_list[i].size);

		<span class="enscript-keyword">if</span>(map_size != 0) {
			error = vm_map_copyin(map,
					map_addr,
					map_size,
					FALSE,	<span class="enscript-comment">/* src_destroy */</span>
					&amp;copy);
			<span class="enscript-keyword">if</span> (KERN_SUCCESS == error) {
				error = vm_map_copyout(current_task()-&gt;map, 
						&amp;map_addr,
						copy);
				<span class="enscript-keyword">if</span> (KERN_SUCCESS == error) {
					data_list[i].address =
						CAST_DOWN(vm_offset_t, map_addr);
					<span class="enscript-keyword">continue</span>;
				}
				vm_map_copy_discard(copy);
			}
		}
		data_list[i].address = (mach_vm_address_t)0;
		data_list[i].size = (mach_vm_size_t)0;
	}
	<span class="enscript-keyword">return</span>(error);
}

<span class="enscript-comment">/*
 * mach_vm_read_overwrite -
 * Overwrite a range of the current map with data from the specified
 * map/address range.
 * 
 * In making an assumption that the current thread is local, it is
 * no longer cluster-safe without a fully supportive local proxy
 * thread/task (but we don't support cluster's anymore so this is moot).
 */</span>

kern_return_t
<span class="enscript-function-name">mach_vm_read_overwrite</span>(
	vm_map_t		map,
	mach_vm_address_t	address,
	mach_vm_size_t	size,
	mach_vm_address_t	data,
	mach_vm_size_t	*data_size)
{
	kern_return_t	error;
	vm_map_copy_t	copy;

	<span class="enscript-keyword">if</span> (map == VM_MAP_NULL)
		<span class="enscript-keyword">return</span>(KERN_INVALID_ARGUMENT);

	error = vm_map_copyin(map, (vm_map_address_t)address,
				(vm_map_size_t)size, FALSE, &amp;copy);

	<span class="enscript-keyword">if</span> (KERN_SUCCESS == error) {
		error = vm_map_copy_overwrite(current_thread()-&gt;map,
 					(vm_map_address_t)data, 
					copy, FALSE);
		<span class="enscript-keyword">if</span> (KERN_SUCCESS == error) {
			*data_size = size;
			<span class="enscript-keyword">return</span> error;
		}
		vm_map_copy_discard(copy);
	}
	<span class="enscript-keyword">return</span>(error);
}

<span class="enscript-comment">/*
 * vm_read_overwrite -
 * Overwrite a range of the current map with data from the specified
 * map/address range.
 * 
 * This routine adds the additional limitation that the source and
 * destination ranges must be describable with vm_address_t values
 * (i.e. the same size address spaces as the kernel, or at least the
 * the ranges are in that first portion of the respective address
 * spaces).
 */</span>

kern_return_t
<span class="enscript-function-name">vm_read_overwrite</span>(
	vm_map_t	map,
	vm_address_t	address,
	vm_size_t	size,
	vm_address_t	data,
	vm_size_t	*data_size)
{
	kern_return_t	error;
	vm_map_copy_t	copy;

	<span class="enscript-keyword">if</span> (map == VM_MAP_NULL)
		<span class="enscript-keyword">return</span>(KERN_INVALID_ARGUMENT);

	error = vm_map_copyin(map, (vm_map_address_t)address,
				(vm_map_size_t)size, FALSE, &amp;copy);

	<span class="enscript-keyword">if</span> (KERN_SUCCESS == error) {
		error = vm_map_copy_overwrite(current_thread()-&gt;map,
 					(vm_map_address_t)data, 
					copy, FALSE);
		<span class="enscript-keyword">if</span> (KERN_SUCCESS == error) {
			*data_size = size;
			<span class="enscript-keyword">return</span> error;
		}
		vm_map_copy_discard(copy);
	}
	<span class="enscript-keyword">return</span>(error);
}


<span class="enscript-comment">/*
 * mach_vm_write -
 * Overwrite the specified address range with the data provided
 * (from the current map).
 */</span>
kern_return_t
<span class="enscript-function-name">mach_vm_write</span>(
	vm_map_t			map,
	mach_vm_address_t		address,
	pointer_t			data,
	__unused mach_msg_type_number_t	size)
{
	<span class="enscript-keyword">if</span> (map == VM_MAP_NULL)
		<span class="enscript-keyword">return</span> KERN_INVALID_ARGUMENT;

	<span class="enscript-keyword">return</span> vm_map_copy_overwrite(map, (vm_map_address_t)address,
		(vm_map_copy_t) data, FALSE <span class="enscript-comment">/* interruptible XXX */</span>);
}

<span class="enscript-comment">/*
 * vm_write -
 * Overwrite the specified address range with the data provided
 * (from the current map).
 *
 * The addressability of the range of addresses to overwrite is
 * limited bu the use of a vm_address_t (same size as kernel map).
 * Either the target map is also small, or the range is in the
 * low addresses within it.
 */</span>
kern_return_t
<span class="enscript-function-name">vm_write</span>(
	vm_map_t			map,
	vm_address_t			address,
	pointer_t			data,
	__unused mach_msg_type_number_t	size)
{
	<span class="enscript-keyword">if</span> (map == VM_MAP_NULL)
		<span class="enscript-keyword">return</span> KERN_INVALID_ARGUMENT;

	<span class="enscript-keyword">return</span> vm_map_copy_overwrite(map, (vm_map_address_t)address,
		(vm_map_copy_t) data, FALSE <span class="enscript-comment">/* interruptible XXX */</span>);
}

<span class="enscript-comment">/*
 * mach_vm_copy -
 * Overwrite one range of the specified map with the contents of
 * another range within that same map (i.e. both address ranges
 * are &quot;over there&quot;).
 */</span>
kern_return_t
<span class="enscript-function-name">mach_vm_copy</span>(
	vm_map_t		map,
	mach_vm_address_t	source_address,
	mach_vm_size_t	size,
	mach_vm_address_t	dest_address)
{
	vm_map_copy_t copy;
	kern_return_t kr;

	<span class="enscript-keyword">if</span> (map == VM_MAP_NULL)
		<span class="enscript-keyword">return</span> KERN_INVALID_ARGUMENT;

	kr = vm_map_copyin(map, (vm_map_address_t)source_address,
			   (vm_map_size_t)size, FALSE, &amp;copy);

	<span class="enscript-keyword">if</span> (KERN_SUCCESS == kr) {
		kr = vm_map_copy_overwrite(map,
				(vm_map_address_t)dest_address,
				copy, FALSE <span class="enscript-comment">/* interruptible XXX */</span>);

		<span class="enscript-keyword">if</span> (KERN_SUCCESS != kr)
			vm_map_copy_discard(copy);
	}
	<span class="enscript-keyword">return</span> kr;
}

kern_return_t
<span class="enscript-function-name">vm_copy</span>(
	vm_map_t	map,
	vm_address_t	source_address,
	vm_size_t	size,
	vm_address_t	dest_address)
{
	vm_map_copy_t copy;
	kern_return_t kr;

	<span class="enscript-keyword">if</span> (map == VM_MAP_NULL)
		<span class="enscript-keyword">return</span> KERN_INVALID_ARGUMENT;

	kr = vm_map_copyin(map, (vm_map_address_t)source_address,
			   (vm_map_size_t)size, FALSE, &amp;copy);

	<span class="enscript-keyword">if</span> (KERN_SUCCESS == kr) {
		kr = vm_map_copy_overwrite(map,
				(vm_map_address_t)dest_address,
				copy, FALSE <span class="enscript-comment">/* interruptible XXX */</span>);

		<span class="enscript-keyword">if</span> (KERN_SUCCESS != kr)
			vm_map_copy_discard(copy);
	}
	<span class="enscript-keyword">return</span> kr;
}

<span class="enscript-comment">/*
 * mach_vm_map -
 * Map some range of an object into an address space.
 *
 * The object can be one of several types of objects:
 *	NULL - anonymous memory
 *	a named entry - a range within another address space
 *	                or a range within a memory object
 *	a whole memory object
 *
 */</span>
kern_return_t
<span class="enscript-function-name">mach_vm_map</span>(
	vm_map_t		target_map,
	mach_vm_offset_t	*address,
	mach_vm_size_t	initial_size,
	mach_vm_offset_t	mask,
	<span class="enscript-type">int</span>			flags,
	ipc_port_t		port,
	vm_object_offset_t	offset,
	boolean_t		copy,
	vm_prot_t		cur_protection,
	vm_prot_t		max_protection,
	vm_inherit_t		inheritance)
{
	kern_return_t		kr;
	vm_map_offset_t 	vmmaddr;

	vmmaddr = (vm_map_offset_t) *address;

	<span class="enscript-comment">/* filter out any kernel-only flags */</span>
	<span class="enscript-keyword">if</span> (flags &amp; ~VM_FLAGS_USER_MAP)
		<span class="enscript-keyword">return</span> KERN_INVALID_ARGUMENT;

	kr = vm_map_enter_mem_object(target_map,
				       &amp;vmmaddr,
				       initial_size,
				       mask,
				       flags,
				       port,
				       offset,
				       copy,
				       cur_protection,
				       max_protection,
				       inheritance);

	*address = vmmaddr;
	<span class="enscript-keyword">return</span> kr;
}


<span class="enscript-comment">/* legacy interface */</span>
kern_return_t
<span class="enscript-function-name">vm_map_64</span>(
	vm_map_t		target_map,
	vm_offset_t		*address,
	vm_size_t		size,
	vm_offset_t		mask,
	<span class="enscript-type">int</span>			flags,
	ipc_port_t		port,
	vm_object_offset_t	offset,
	boolean_t		copy,
	vm_prot_t		cur_protection,
	vm_prot_t		max_protection,
	vm_inherit_t		inheritance)
{
	mach_vm_address_t map_addr;
	mach_vm_size_t map_size;
	mach_vm_offset_t map_mask;
	kern_return_t kr;

	map_addr = (mach_vm_address_t)*address;
	map_size = (mach_vm_size_t)size;
	map_mask = (mach_vm_offset_t)mask;

	kr = mach_vm_map(target_map, &amp;map_addr, map_size, map_mask, flags,
			 port, offset, copy, 
			 cur_protection, max_protection, inheritance);
	*address = CAST_DOWN(vm_offset_t, map_addr);
	<span class="enscript-keyword">return</span> kr;
}

<span class="enscript-comment">/* temporary, until world build */</span>
kern_return_t
<span class="enscript-function-name">vm_map</span>(
	vm_map_t		target_map,
	vm_offset_t		*address,
	vm_size_t		size,
	vm_offset_t		mask,
	<span class="enscript-type">int</span>			flags,
	ipc_port_t		port,
	vm_offset_t		offset,
	boolean_t		copy,
	vm_prot_t		cur_protection,
	vm_prot_t		max_protection,
	vm_inherit_t		inheritance)
{
	mach_vm_address_t map_addr;
	mach_vm_size_t map_size;
	mach_vm_offset_t map_mask;
	vm_object_offset_t obj_offset;
	kern_return_t kr;

	map_addr = (mach_vm_address_t)*address;
	map_size = (mach_vm_size_t)size;
	map_mask = (mach_vm_offset_t)mask;
	obj_offset = (vm_object_offset_t)offset;

	kr = mach_vm_map(target_map, &amp;map_addr, map_size, map_mask, flags,
			 port, obj_offset, copy, 
			 cur_protection, max_protection, inheritance);
	*address = CAST_DOWN(vm_offset_t, map_addr);
	<span class="enscript-keyword">return</span> kr;
}

<span class="enscript-comment">/*
 * mach_vm_remap -
 * Remap a range of memory from one task into another,
 * to another address range within the same task, or
 * over top of itself (with altered permissions and/or
 * as an in-place copy of itself).
 */</span>

kern_return_t
<span class="enscript-function-name">mach_vm_remap</span>(
	vm_map_t		target_map,
	mach_vm_offset_t	*address,
	mach_vm_size_t	size,
	mach_vm_offset_t	mask,
	<span class="enscript-type">int</span>			flags,
	vm_map_t		src_map,
	mach_vm_offset_t	memory_address,
	boolean_t		copy,
	vm_prot_t		*cur_protection,
	vm_prot_t		*max_protection,
	vm_inherit_t		inheritance)
{
	vm_map_offset_t		map_addr;
	kern_return_t		kr;

	<span class="enscript-keyword">if</span> (VM_MAP_NULL == target_map || VM_MAP_NULL == src_map)
		<span class="enscript-keyword">return</span> KERN_INVALID_ARGUMENT;

	<span class="enscript-comment">/* filter out any kernel-only flags */</span>
	<span class="enscript-keyword">if</span> (flags &amp; ~VM_FLAGS_USER_REMAP)
		<span class="enscript-keyword">return</span> KERN_INVALID_ARGUMENT;

	map_addr = (vm_map_offset_t)*address;

	kr = vm_map_remap(target_map,
			  &amp;map_addr,
			  size,
			  mask,
			  flags,
			  src_map,
			  memory_address,
			  copy,
			  cur_protection,
			  max_protection,
			  inheritance);
	*address = map_addr;
	<span class="enscript-keyword">return</span> kr;
}

<span class="enscript-comment">/*
 * vm_remap -
 * Remap a range of memory from one task into another,
 * to another address range within the same task, or
 * over top of itself (with altered permissions and/or
 * as an in-place copy of itself).
 *
 * The addressability of the source and target address
 * range is limited by the size of vm_address_t (in the
 * kernel context).
 */</span>
kern_return_t
<span class="enscript-function-name">vm_remap</span>(
	vm_map_t		target_map,
	vm_offset_t		*address,
	vm_size_t		size,
	vm_offset_t		mask,
	<span class="enscript-type">int</span>			flags,
	vm_map_t		src_map,
	vm_offset_t		memory_address,
	boolean_t		copy,
	vm_prot_t		*cur_protection,
	vm_prot_t		*max_protection,
	vm_inherit_t		inheritance)
{
	vm_map_offset_t		map_addr;
	kern_return_t		kr;

	<span class="enscript-keyword">if</span> (VM_MAP_NULL == target_map || VM_MAP_NULL == src_map)
		<span class="enscript-keyword">return</span> KERN_INVALID_ARGUMENT;

	<span class="enscript-comment">/* filter out any kernel-only flags */</span>
	<span class="enscript-keyword">if</span> (flags &amp; ~VM_FLAGS_USER_REMAP)
		<span class="enscript-keyword">return</span> KERN_INVALID_ARGUMENT;

	map_addr = (vm_map_offset_t)*address;

	kr = vm_map_remap(target_map,
			  &amp;map_addr,
			  size,
			  mask,
			  flags,
			  src_map,
			  memory_address,
			  copy,
			  cur_protection,
			  max_protection,
			  inheritance);
	*address = CAST_DOWN(vm_offset_t, map_addr);
	<span class="enscript-keyword">return</span> kr;
}

<span class="enscript-comment">/*
 * NOTE: these routine (and this file) will no longer require mach_host_server.h
 * when mach_vm_wire and vm_wire are changed to use ledgers.
 */</span>
#<span class="enscript-reference">include</span> <span class="enscript-string">&lt;mach/mach_host_server.h&gt;</span>
<span class="enscript-comment">/*
 *	mach_vm_wire
 *	Specify that the range of the virtual address space
 *	of the target task must not cause page faults for
 *	the indicated accesses.
 *
 *	[ To unwire the pages, specify VM_PROT_NONE. ]
 */</span>
kern_return_t
<span class="enscript-function-name">mach_vm_wire</span>(
	host_priv_t		host_priv,
	vm_map_t		map,
	mach_vm_offset_t	start,
	mach_vm_size_t	size,
	vm_prot_t		access)
{
	kern_return_t		rc;

	<span class="enscript-keyword">if</span> (host_priv == HOST_PRIV_NULL)
		<span class="enscript-keyword">return</span> KERN_INVALID_HOST;

	assert(host_priv == &amp;realhost);

	<span class="enscript-keyword">if</span> (map == VM_MAP_NULL)
		<span class="enscript-keyword">return</span> KERN_INVALID_TASK;

	<span class="enscript-keyword">if</span> (access &amp; ~VM_PROT_ALL || (start + size &lt; start))
		<span class="enscript-keyword">return</span> KERN_INVALID_ARGUMENT;

	<span class="enscript-keyword">if</span> (access != VM_PROT_NONE) {
		rc = vm_map_wire(map,
				 vm_map_trunc_page(start,
						   VM_MAP_PAGE_MASK(map)),
				 vm_map_round_page(start+size,
						   VM_MAP_PAGE_MASK(map)),
				 access | VM_PROT_MEMORY_TAG_MAKE(VM_KERN_MEMORY_MLOCK),
				 TRUE);
	} <span class="enscript-keyword">else</span> {
		rc = vm_map_unwire(map,
				   vm_map_trunc_page(start,
						     VM_MAP_PAGE_MASK(map)),
				   vm_map_round_page(start+size,
						     VM_MAP_PAGE_MASK(map)),
				   TRUE);
	}
	<span class="enscript-keyword">return</span> rc;
}

<span class="enscript-comment">/*
 *	vm_wire -
 *	Specify that the range of the virtual address space
 *	of the target task must not cause page faults for
 *	the indicated accesses.
 *
 *	[ To unwire the pages, specify VM_PROT_NONE. ]
 */</span>
kern_return_t
<span class="enscript-function-name">vm_wire</span>(
	host_priv_t		host_priv,
	<span class="enscript-type">register</span> vm_map_t	map,
	vm_offset_t		start,
	vm_size_t		size,
	vm_prot_t		access)
{
	kern_return_t		rc;

	<span class="enscript-keyword">if</span> (host_priv == HOST_PRIV_NULL)
		<span class="enscript-keyword">return</span> KERN_INVALID_HOST;

	assert(host_priv == &amp;realhost);

	<span class="enscript-keyword">if</span> (map == VM_MAP_NULL)
		<span class="enscript-keyword">return</span> KERN_INVALID_TASK;

	<span class="enscript-keyword">if</span> ((access &amp; ~VM_PROT_ALL) || (start + size &lt; start))
		<span class="enscript-keyword">return</span> KERN_INVALID_ARGUMENT;

	<span class="enscript-keyword">if</span> (size == 0) {
		rc = KERN_SUCCESS;
	} <span class="enscript-keyword">else</span> <span class="enscript-keyword">if</span> (access != VM_PROT_NONE) {
		rc = vm_map_wire(map,
				 vm_map_trunc_page(start,
						   VM_MAP_PAGE_MASK(map)),
				 vm_map_round_page(start+size,
						   VM_MAP_PAGE_MASK(map)),
				 access | VM_PROT_MEMORY_TAG_MAKE(VM_KERN_MEMORY_OSFMK),
				 TRUE);
	} <span class="enscript-keyword">else</span> {
		rc = vm_map_unwire(map,
				   vm_map_trunc_page(start,
						     VM_MAP_PAGE_MASK(map)),
				   vm_map_round_page(start+size,
						     VM_MAP_PAGE_MASK(map)),
				   TRUE);
	}
	<span class="enscript-keyword">return</span> rc;
}

<span class="enscript-comment">/*
 *	vm_msync
 *
 *	Synchronises the memory range specified with its backing store
 *	image by either flushing or cleaning the contents to the appropriate
 *	memory manager.
 *
 *	interpretation of sync_flags
 *	VM_SYNC_INVALIDATE	- discard pages, only return precious
 *				  pages to manager.
 *
 *	VM_SYNC_INVALIDATE &amp; (VM_SYNC_SYNCHRONOUS | VM_SYNC_ASYNCHRONOUS)
 *				- discard pages, write dirty or precious
 *				  pages back to memory manager.
 *
 *	VM_SYNC_SYNCHRONOUS | VM_SYNC_ASYNCHRONOUS
 *				- write dirty or precious pages back to
 *				  the memory manager.
 *
 *	VM_SYNC_CONTIGUOUS	- does everything normally, but if there
 *				  is a hole in the region, and we would
 *				  have returned KERN_SUCCESS, return
 *				  KERN_INVALID_ADDRESS instead.
 *
 *	RETURNS
 *	KERN_INVALID_TASK		Bad task parameter
 *	KERN_INVALID_ARGUMENT		both sync and async were specified.
 *	KERN_SUCCESS			The usual.
 *	KERN_INVALID_ADDRESS		There was a hole in the region.
 */</span>

kern_return_t
<span class="enscript-function-name">mach_vm_msync</span>(
	vm_map_t		map,
	mach_vm_address_t	address,
	mach_vm_size_t	size,
	vm_sync_t		sync_flags)
{

	<span class="enscript-keyword">if</span> (map == VM_MAP_NULL)
		<span class="enscript-keyword">return</span>(KERN_INVALID_TASK);

	<span class="enscript-keyword">return</span> vm_map_msync(map, (vm_map_address_t)address,
			(vm_map_size_t)size, sync_flags);
}
      
<span class="enscript-comment">/*
 *	vm_msync
 *
 *	Synchronises the memory range specified with its backing store
 *	image by either flushing or cleaning the contents to the appropriate
 *	memory manager.
 *
 *	interpretation of sync_flags
 *	VM_SYNC_INVALIDATE	- discard pages, only return precious
 *				  pages to manager.
 *
 *	VM_SYNC_INVALIDATE &amp; (VM_SYNC_SYNCHRONOUS | VM_SYNC_ASYNCHRONOUS)
 *				- discard pages, write dirty or precious
 *				  pages back to memory manager.
 *
 *	VM_SYNC_SYNCHRONOUS | VM_SYNC_ASYNCHRONOUS
 *				- write dirty or precious pages back to
 *				  the memory manager.
 *
 *	VM_SYNC_CONTIGUOUS	- does everything normally, but if there
 *				  is a hole in the region, and we would
 *				  have returned KERN_SUCCESS, return
 *				  KERN_INVALID_ADDRESS instead.
 *
 *	The addressability of the range is limited to that which can
 *	be described by a vm_address_t.
 *
 *	RETURNS
 *	KERN_INVALID_TASK		Bad task parameter
 *	KERN_INVALID_ARGUMENT		both sync and async were specified.
 *	KERN_SUCCESS			The usual.
 *	KERN_INVALID_ADDRESS		There was a hole in the region.
 */</span>

kern_return_t
<span class="enscript-function-name">vm_msync</span>(
	vm_map_t	map,
	vm_address_t	address,
	vm_size_t	size,
	vm_sync_t	sync_flags)
{

	<span class="enscript-keyword">if</span> (map == VM_MAP_NULL)
		<span class="enscript-keyword">return</span>(KERN_INVALID_TASK);

	<span class="enscript-keyword">return</span> vm_map_msync(map, (vm_map_address_t)address,
			(vm_map_size_t)size, sync_flags);
}


<span class="enscript-type">int</span>
<span class="enscript-function-name">vm_toggle_entry_reuse</span>(<span class="enscript-type">int</span> toggle, <span class="enscript-type">int</span> *old_value)
{
	vm_map_t map = current_map();
	
	<span class="enscript-keyword">if</span>(toggle == VM_TOGGLE_GETVALUE &amp;&amp; old_value != NULL){
		*old_value = map-&gt;disable_vmentry_reuse;
	} <span class="enscript-keyword">else</span> <span class="enscript-keyword">if</span>(toggle == VM_TOGGLE_SET){
		vm_map_entry_t map_to_entry;

		vm_map_lock(map);
		vm_map_disable_hole_optimization(map);
		map-&gt;disable_vmentry_reuse = TRUE;
		__IGNORE_WCASTALIGN(map_to_entry = vm_map_to_entry(map));
		<span class="enscript-keyword">if</span> (map-&gt;first_free == map_to_entry) {
			map-&gt;highest_entry_end = vm_map_min(map);
		} <span class="enscript-keyword">else</span> {
			map-&gt;highest_entry_end = map-&gt;first_free-&gt;vme_end;
		}
		vm_map_unlock(map);
	} <span class="enscript-keyword">else</span> <span class="enscript-keyword">if</span> (toggle == VM_TOGGLE_CLEAR){
		vm_map_lock(map);
		map-&gt;disable_vmentry_reuse = FALSE;
		vm_map_unlock(map);
	} <span class="enscript-keyword">else</span>
		<span class="enscript-keyword">return</span> KERN_INVALID_ARGUMENT;

	<span class="enscript-keyword">return</span> KERN_SUCCESS;
}

<span class="enscript-comment">/*
 *	mach_vm_behavior_set 
 *
 *	Sets the paging behavior attribute for the  specified range
 *	in the specified map.
 *
 *	This routine will fail with KERN_INVALID_ADDRESS if any address
 *	in [start,start+size) is not a valid allocated memory region.
 */</span>
kern_return_t 
<span class="enscript-function-name">mach_vm_behavior_set</span>(
	vm_map_t		map,
	mach_vm_offset_t	start,
	mach_vm_size_t	size,
	vm_behavior_t		new_behavior)
{
	<span class="enscript-keyword">if</span> ((map == VM_MAP_NULL) || (start + size &lt; start))
		<span class="enscript-keyword">return</span>(KERN_INVALID_ARGUMENT);

	<span class="enscript-keyword">if</span> (size == 0)
		<span class="enscript-keyword">return</span> KERN_SUCCESS;

	<span class="enscript-keyword">return</span>(vm_map_behavior_set(map,
				   vm_map_trunc_page(start,
						     VM_MAP_PAGE_MASK(map)), 
				   vm_map_round_page(start+size,
						     VM_MAP_PAGE_MASK(map)),
				   new_behavior));
}

<span class="enscript-comment">/*
 *	vm_behavior_set 
 *
 *	Sets the paging behavior attribute for the  specified range
 *	in the specified map.
 *
 *	This routine will fail with KERN_INVALID_ADDRESS if any address
 *	in [start,start+size) is not a valid allocated memory region.
 *
 *	This routine is potentially limited in addressibility by the
 *	use of vm_offset_t (if the map provided is larger than the
 *	kernel's).
 */</span>
kern_return_t 
<span class="enscript-function-name">vm_behavior_set</span>(
	vm_map_t		map,
	vm_offset_t		start,
	vm_size_t		size,
	vm_behavior_t		new_behavior)
{
	<span class="enscript-keyword">if</span> ((map == VM_MAP_NULL) || (start + size &lt; start))
		<span class="enscript-keyword">return</span>(KERN_INVALID_ARGUMENT);

	<span class="enscript-keyword">if</span> (size == 0)
		<span class="enscript-keyword">return</span> KERN_SUCCESS;

	<span class="enscript-keyword">return</span>(vm_map_behavior_set(map,
				   vm_map_trunc_page(start,
						     VM_MAP_PAGE_MASK(map)), 
				   vm_map_round_page(start+size,
						     VM_MAP_PAGE_MASK(map)),
				   new_behavior));
}

<span class="enscript-comment">/*
 *	mach_vm_region:
 *
 *	User call to obtain information about a region in
 *	a task's address map. Currently, only one flavor is
 *	supported.
 *
 *	XXX The reserved and behavior fields cannot be filled
 *	    in until the vm merge from the IK is completed, and
 *	    vm_reserve is implemented.
 *
 *	XXX Dependency: syscall_vm_region() also supports only one flavor.
 */</span>

kern_return_t
<span class="enscript-function-name">mach_vm_region</span>(
	vm_map_t		 map,
	mach_vm_offset_t	*address,		<span class="enscript-comment">/* IN/OUT */</span>
	mach_vm_size_t	*size,			<span class="enscript-comment">/* OUT */</span>
	vm_region_flavor_t	 flavor,		<span class="enscript-comment">/* IN */</span>
	vm_region_info_t	 info,			<span class="enscript-comment">/* OUT */</span>
	mach_msg_type_number_t	*count,			<span class="enscript-comment">/* IN/OUT */</span>
	mach_port_t		*object_name)		<span class="enscript-comment">/* OUT */</span>
{
	vm_map_offset_t 	map_addr;
	vm_map_size_t 		map_size;
	kern_return_t		kr;

	<span class="enscript-keyword">if</span> (VM_MAP_NULL == map)
		<span class="enscript-keyword">return</span> KERN_INVALID_ARGUMENT;

	map_addr = (vm_map_offset_t)*address;
	map_size = (vm_map_size_t)*size;

	<span class="enscript-comment">/* legacy conversion */</span>
	<span class="enscript-keyword">if</span> (VM_REGION_BASIC_INFO == flavor)
		flavor = VM_REGION_BASIC_INFO_64;

	kr = vm_map_region(map,
			   &amp;map_addr, &amp;map_size,
			   flavor, info, count,
			   object_name);

	*address = map_addr;
	*size = map_size;
	<span class="enscript-keyword">return</span> kr;
}

<span class="enscript-comment">/*
 *	vm_region_64 and vm_region:
 *
 *	User call to obtain information about a region in
 *	a task's address map. Currently, only one flavor is
 *	supported.
 *
 *	XXX The reserved and behavior fields cannot be filled
 *	    in until the vm merge from the IK is completed, and
 *	    vm_reserve is implemented.
 *
 *	XXX Dependency: syscall_vm_region() also supports only one flavor.
 */</span>

kern_return_t
<span class="enscript-function-name">vm_region_64</span>(
	vm_map_t		 map,
	vm_offset_t	        *address,		<span class="enscript-comment">/* IN/OUT */</span>
	vm_size_t		*size,			<span class="enscript-comment">/* OUT */</span>
	vm_region_flavor_t	 flavor,		<span class="enscript-comment">/* IN */</span>
	vm_region_info_t	 info,			<span class="enscript-comment">/* OUT */</span>
	mach_msg_type_number_t	*count,			<span class="enscript-comment">/* IN/OUT */</span>
	mach_port_t		*object_name)		<span class="enscript-comment">/* OUT */</span>
{
	vm_map_offset_t 	map_addr;
	vm_map_size_t 		map_size;
	kern_return_t		kr;

	<span class="enscript-keyword">if</span> (VM_MAP_NULL == map)
		<span class="enscript-keyword">return</span> KERN_INVALID_ARGUMENT;

	map_addr = (vm_map_offset_t)*address;
	map_size = (vm_map_size_t)*size;

	<span class="enscript-comment">/* legacy conversion */</span>
	<span class="enscript-keyword">if</span> (VM_REGION_BASIC_INFO == flavor)
		flavor = VM_REGION_BASIC_INFO_64;

	kr = vm_map_region(map,
			   &amp;map_addr, &amp;map_size,
			   flavor, info, count,
			   object_name);

	*address = CAST_DOWN(vm_offset_t, map_addr);
	*size = CAST_DOWN(vm_size_t, map_size);

	<span class="enscript-keyword">if</span> (KERN_SUCCESS == kr &amp;&amp; map_addr + map_size &gt; VM_MAX_ADDRESS)
		<span class="enscript-keyword">return</span> KERN_INVALID_ADDRESS;
	<span class="enscript-keyword">return</span> kr;
}

kern_return_t
<span class="enscript-function-name">vm_region</span>(
	vm_map_t			map,
	vm_address_t	      		*address,	<span class="enscript-comment">/* IN/OUT */</span>
	vm_size_t			*size,		<span class="enscript-comment">/* OUT */</span>
	vm_region_flavor_t	 	flavor,	<span class="enscript-comment">/* IN */</span>
	vm_region_info_t	 	info,		<span class="enscript-comment">/* OUT */</span>
	mach_msg_type_number_t	*count,	<span class="enscript-comment">/* IN/OUT */</span>
	mach_port_t			*object_name)	<span class="enscript-comment">/* OUT */</span>
{
	vm_map_address_t 	map_addr;
	vm_map_size_t 		map_size;
	kern_return_t		kr;

	<span class="enscript-keyword">if</span> (VM_MAP_NULL == map)
		<span class="enscript-keyword">return</span> KERN_INVALID_ARGUMENT;

	map_addr = (vm_map_address_t)*address;
	map_size = (vm_map_size_t)*size;

	kr = vm_map_region(map,
			   &amp;map_addr, &amp;map_size,
			   flavor, info, count,
			   object_name);

	*address = CAST_DOWN(vm_address_t, map_addr);
	*size = CAST_DOWN(vm_size_t, map_size);

	<span class="enscript-keyword">if</span> (KERN_SUCCESS == kr &amp;&amp; map_addr + map_size &gt; VM_MAX_ADDRESS)
		<span class="enscript-keyword">return</span> KERN_INVALID_ADDRESS;
	<span class="enscript-keyword">return</span> kr;
}

<span class="enscript-comment">/*
 *	vm_region_recurse: A form of vm_region which follows the
 *	submaps in a target map
 *
 */</span>
kern_return_t
<span class="enscript-function-name">mach_vm_region_recurse</span>(
	vm_map_t			map,
	mach_vm_address_t		*address,
	mach_vm_size_t		*size,
	uint32_t			*depth,
	vm_region_recurse_info_t	info,
	mach_msg_type_number_t 	*infoCnt)
{
	vm_map_address_t	map_addr;
	vm_map_size_t		map_size;
	kern_return_t		kr;

	<span class="enscript-keyword">if</span> (VM_MAP_NULL == map)
		<span class="enscript-keyword">return</span> KERN_INVALID_ARGUMENT;

	map_addr = (vm_map_address_t)*address;
	map_size = (vm_map_size_t)*size;

	kr = vm_map_region_recurse_64(
			map,
			&amp;map_addr,
			&amp;map_size,
			depth,
			(vm_region_submap_info_64_t)info,
			infoCnt);

	*address = map_addr;
	*size = map_size;
	<span class="enscript-keyword">return</span> kr;
}

<span class="enscript-comment">/*
 *	vm_region_recurse: A form of vm_region which follows the
 *	submaps in a target map
 *
 */</span>
kern_return_t
<span class="enscript-function-name">vm_region_recurse_64</span>(
	vm_map_t			map,
	vm_address_t			*address,
	vm_size_t			*size,
	uint32_t			*depth,
	vm_region_recurse_info_64_t	info,
	mach_msg_type_number_t 	*infoCnt)
{
	vm_map_address_t	map_addr;
	vm_map_size_t		map_size;
	kern_return_t		kr;

	<span class="enscript-keyword">if</span> (VM_MAP_NULL == map)
		<span class="enscript-keyword">return</span> KERN_INVALID_ARGUMENT;

	map_addr = (vm_map_address_t)*address;
	map_size = (vm_map_size_t)*size;

	kr = vm_map_region_recurse_64(
			map,
			&amp;map_addr,
			&amp;map_size,
			depth,
			(vm_region_submap_info_64_t)info,
			infoCnt);

	*address = CAST_DOWN(vm_address_t, map_addr);
	*size = CAST_DOWN(vm_size_t, map_size);

	<span class="enscript-keyword">if</span> (KERN_SUCCESS == kr &amp;&amp; map_addr + map_size &gt; VM_MAX_ADDRESS)
		<span class="enscript-keyword">return</span> KERN_INVALID_ADDRESS;
	<span class="enscript-keyword">return</span> kr;
}

kern_return_t
<span class="enscript-function-name">vm_region_recurse</span>(
	vm_map_t			map,
	vm_offset_t	       	*address,	<span class="enscript-comment">/* IN/OUT */</span>
	vm_size_t			*size,		<span class="enscript-comment">/* OUT */</span>
	natural_t	 		*depth,	<span class="enscript-comment">/* IN/OUT */</span>
	vm_region_recurse_info_t	info32,	<span class="enscript-comment">/* IN/OUT */</span>
	mach_msg_type_number_t	*infoCnt)	<span class="enscript-comment">/* IN/OUT */</span>
{
	vm_region_submap_info_data_64_t info64;
	vm_region_submap_info_t info;
	vm_map_address_t	map_addr;
	vm_map_size_t		map_size;
	kern_return_t		kr;

	<span class="enscript-keyword">if</span> (VM_MAP_NULL == map || *infoCnt &lt; VM_REGION_SUBMAP_INFO_COUNT)
		<span class="enscript-keyword">return</span> KERN_INVALID_ARGUMENT;

	
	map_addr = (vm_map_address_t)*address;
	map_size = (vm_map_size_t)*size;
	info = (vm_region_submap_info_t)info32;
	*infoCnt = VM_REGION_SUBMAP_INFO_COUNT_64;

	kr = vm_map_region_recurse_64(map, &amp;map_addr,&amp;map_size,
				      depth, &amp;info64, infoCnt);

	info-&gt;protection = info64.protection;
	info-&gt;max_protection = info64.max_protection;
	info-&gt;inheritance = info64.inheritance;
	info-&gt;offset = (uint32_t)info64.offset; <span class="enscript-comment">/* trouble-maker */</span>
        info-&gt;user_tag = info64.user_tag;
        info-&gt;pages_resident = info64.pages_resident;
        info-&gt;pages_shared_now_private = info64.pages_shared_now_private;
        info-&gt;pages_swapped_out = info64.pages_swapped_out;
        info-&gt;pages_dirtied = info64.pages_dirtied;
        info-&gt;ref_count = info64.ref_count;
        info-&gt;shadow_depth = info64.shadow_depth;
        info-&gt;external_pager = info64.external_pager;
        info-&gt;share_mode = info64.share_mode;
	info-&gt;is_submap = info64.is_submap;
	info-&gt;behavior = info64.behavior;
	info-&gt;object_id = info64.object_id;
	info-&gt;user_wired_count = info64.user_wired_count; 

	*address = CAST_DOWN(vm_address_t, map_addr);
	*size = CAST_DOWN(vm_size_t, map_size);
	*infoCnt = VM_REGION_SUBMAP_INFO_COUNT;

	<span class="enscript-keyword">if</span> (KERN_SUCCESS == kr &amp;&amp; map_addr + map_size &gt; VM_MAX_ADDRESS)
		<span class="enscript-keyword">return</span> KERN_INVALID_ADDRESS;
	<span class="enscript-keyword">return</span> kr;
}

kern_return_t
<span class="enscript-function-name">mach_vm_purgable_control</span>(
	vm_map_t		map,
	mach_vm_offset_t	address,
	vm_purgable_t		control,
	<span class="enscript-type">int</span>			*state)
{
	<span class="enscript-keyword">if</span> (VM_MAP_NULL == map)
		<span class="enscript-keyword">return</span> KERN_INVALID_ARGUMENT;

	<span class="enscript-keyword">return</span> vm_map_purgable_control(map,
				       vm_map_trunc_page(address, PAGE_MASK),
				       control,
				       state);
}

kern_return_t
<span class="enscript-function-name">vm_purgable_control</span>(
	vm_map_t		map,
	vm_offset_t		address,
	vm_purgable_t		control,
	<span class="enscript-type">int</span>			*state)
{
	<span class="enscript-keyword">if</span> (VM_MAP_NULL == map)
		<span class="enscript-keyword">return</span> KERN_INVALID_ARGUMENT;

	<span class="enscript-keyword">return</span> vm_map_purgable_control(map,
				       vm_map_trunc_page(address, PAGE_MASK),
				       control,
				       state);
}
					

<span class="enscript-comment">/*
 *	Ordinarily, the right to allocate CPM is restricted
 *	to privileged applications (those that can gain access
 *	to the host priv port).  Set this variable to zero if
 *	you want to let any application allocate CPM.
 */</span>
<span class="enscript-type">unsigned</span> <span class="enscript-type">int</span>	vm_allocate_cpm_privileged = 0;

<span class="enscript-comment">/*
 *	Allocate memory in the specified map, with the caveat that
 *	the memory is physically contiguous.  This call may fail
 *	if the system can't find sufficient contiguous memory.
 *	This call may cause or lead to heart-stopping amounts of
 *	paging activity.
 *
 *	Memory obtained from this call should be freed in the
 *	normal way, viz., via vm_deallocate.
 */</span>
kern_return_t
<span class="enscript-function-name">vm_allocate_cpm</span>(
	host_priv_t		host_priv,
	vm_map_t		map,
	vm_address_t		*addr,
	vm_size_t		size,
	<span class="enscript-type">int</span>			flags)
{
	vm_map_address_t	map_addr;
	vm_map_size_t		map_size;
	kern_return_t		kr;

	<span class="enscript-keyword">if</span> (vm_allocate_cpm_privileged &amp;&amp; HOST_PRIV_NULL == host_priv)
		<span class="enscript-keyword">return</span> KERN_INVALID_HOST;

	<span class="enscript-keyword">if</span> (VM_MAP_NULL == map)
		<span class="enscript-keyword">return</span> KERN_INVALID_ARGUMENT;

	map_addr = (vm_map_address_t)*addr;
	map_size = (vm_map_size_t)size;

	kr = vm_map_enter_cpm(map,
			      &amp;map_addr,
			      map_size,
			      flags);

	*addr = CAST_DOWN(vm_address_t, map_addr);
	<span class="enscript-keyword">return</span> kr;
}


kern_return_t
<span class="enscript-function-name">mach_vm_page_query</span>(
	vm_map_t		map,
	mach_vm_offset_t	offset,
	<span class="enscript-type">int</span>			*disposition,
	<span class="enscript-type">int</span>			*ref_count)
{
	<span class="enscript-keyword">if</span> (VM_MAP_NULL == map)
		<span class="enscript-keyword">return</span> KERN_INVALID_ARGUMENT;

	<span class="enscript-keyword">return</span> vm_map_page_query_internal(
		map,
		vm_map_trunc_page(offset, PAGE_MASK),
		disposition, ref_count);
}

kern_return_t
<span class="enscript-function-name">vm_map_page_query</span>(
	vm_map_t		map,
	vm_offset_t		offset,
	<span class="enscript-type">int</span>			*disposition,
	<span class="enscript-type">int</span>			*ref_count)
{
	<span class="enscript-keyword">if</span> (VM_MAP_NULL == map)
		<span class="enscript-keyword">return</span> KERN_INVALID_ARGUMENT;

	<span class="enscript-keyword">return</span> vm_map_page_query_internal(
		map,
		vm_map_trunc_page(offset, PAGE_MASK),
		disposition, ref_count);
}

kern_return_t
<span class="enscript-function-name">mach_vm_page_info</span>(
	vm_map_t		map,
	mach_vm_address_t	address,
	vm_page_info_flavor_t	flavor,
	vm_page_info_t		info,
	mach_msg_type_number_t	*count)
{
	kern_return_t	kr;

	<span class="enscript-keyword">if</span> (map == VM_MAP_NULL) {
		<span class="enscript-keyword">return</span> KERN_INVALID_ARGUMENT;
	}

	kr = vm_map_page_info(map, address, flavor, info, count);
	<span class="enscript-keyword">return</span> kr;
}

<span class="enscript-comment">/* map a (whole) upl into an address space */</span>
kern_return_t
<span class="enscript-function-name">vm_upl_map</span>(
	vm_map_t		map, 
	upl_t			upl, 
	vm_address_t		*dst_addr)
{
	vm_map_offset_t		map_addr;
	kern_return_t		kr;

	<span class="enscript-keyword">if</span> (VM_MAP_NULL == map)
		<span class="enscript-keyword">return</span> KERN_INVALID_ARGUMENT;

	kr = vm_map_enter_upl(map, upl, &amp;map_addr);
	*dst_addr = CAST_DOWN(vm_address_t, map_addr);
	<span class="enscript-keyword">return</span> kr;
}

kern_return_t
<span class="enscript-function-name">vm_upl_unmap</span>(
	vm_map_t		map,
	upl_t 			upl)
{
	<span class="enscript-keyword">if</span> (VM_MAP_NULL == map)
		<span class="enscript-keyword">return</span> KERN_INVALID_ARGUMENT;

	<span class="enscript-keyword">return</span> (vm_map_remove_upl(map, upl));
}

<span class="enscript-comment">/* Retrieve a upl for an object underlying an address range in a map */</span>

kern_return_t
<span class="enscript-function-name">vm_map_get_upl</span>(
	vm_map_t		map,
	vm_map_offset_t		map_offset,
	upl_size_t		*upl_size,
	upl_t			*upl,
	upl_page_info_array_t	page_list,
	<span class="enscript-type">unsigned</span> <span class="enscript-type">int</span>		*count,
	upl_control_flags_t	*flags,
	<span class="enscript-type">int</span>             	force_data_sync)
{
	upl_control_flags_t map_flags;
	kern_return_t	    kr;

	<span class="enscript-keyword">if</span> (VM_MAP_NULL == map)
		<span class="enscript-keyword">return</span> KERN_INVALID_ARGUMENT;

	map_flags = *flags &amp; ~UPL_NOZEROFILL;
	<span class="enscript-keyword">if</span> (force_data_sync)
		map_flags |= UPL_FORCE_DATA_SYNC;

	kr = vm_map_create_upl(map,
			       map_offset,
			       upl_size,
			       upl,
			       page_list,
			       count,
			       &amp;map_flags);

	*flags = (map_flags &amp; ~UPL_FORCE_DATA_SYNC);
	<span class="enscript-keyword">return</span> kr;
}

<span class="enscript-comment">/*
 * mach_make_memory_entry_64
 *
 * Think of it as a two-stage vm_remap() operation.  First
 * you get a handle.  Second, you get map that handle in
 * somewhere else. Rather than doing it all at once (and
 * without needing access to the other whole map).
 */</span>

kern_return_t
<span class="enscript-function-name">mach_make_memory_entry_64</span>(
	vm_map_t		target_map,
	memory_object_size_t	*size,
	memory_object_offset_t offset,
	vm_prot_t		permission,
	ipc_port_t		*object_handle,
	ipc_port_t		parent_handle)
{
	vm_map_version_t	version;
	vm_named_entry_t	parent_entry;
	vm_named_entry_t	user_entry;
	ipc_port_t		user_handle;
	kern_return_t		kr;
	vm_map_t		real_map;

	<span class="enscript-comment">/* needed for call to vm_map_lookup_locked */</span>
	boolean_t		wired;
	boolean_t		iskernel;
	vm_object_offset_t	obj_off;
	vm_prot_t		prot;
	<span class="enscript-type">struct</span> vm_object_fault_info	fault_info;
	vm_object_t		object;
	vm_object_t		shadow_object;

	<span class="enscript-comment">/* needed for direct map entry manipulation */</span>
	vm_map_entry_t		map_entry;
	vm_map_entry_t		next_entry;
	vm_map_t		local_map;
	vm_map_t		original_map = target_map;
	vm_map_size_t		total_size, map_size;
	vm_map_offset_t		map_start, map_end;
	vm_map_offset_t		local_offset;
	vm_object_size_t	mappable_size;

	<span class="enscript-comment">/* 
	 * Stash the offset in the page for use by vm_map_enter_mem_object()
	 * in the VM_FLAGS_RETURN_DATA_ADDR/MAP_MEM_USE_DATA_ADDR case.
	 */</span>
	vm_object_offset_t	offset_in_page;

	<span class="enscript-type">unsigned</span> <span class="enscript-type">int</span>		access;
	vm_prot_t		protections;
	vm_prot_t		original_protections, mask_protections;
	<span class="enscript-type">unsigned</span> <span class="enscript-type">int</span>		wimg_mode;

	boolean_t		force_shadow = FALSE;
	boolean_t 		use_data_addr;
	boolean_t 		use_4K_compat;

	<span class="enscript-keyword">if</span> (((permission &amp; 0x00FF0000) &amp;
	     ~(MAP_MEM_ONLY |
	       MAP_MEM_NAMED_CREATE |
	       MAP_MEM_PURGABLE | 
	       MAP_MEM_NAMED_REUSE |
	       MAP_MEM_USE_DATA_ADDR |
	       MAP_MEM_VM_COPY |
	       MAP_MEM_4K_DATA_ADDR |
	       MAP_MEM_VM_SHARE))) {
		<span class="enscript-comment">/*
		 * Unknown flag: reject for forward compatibility.
		 */</span>
		<span class="enscript-keyword">return</span> KERN_INVALID_VALUE;
	}

	<span class="enscript-keyword">if</span> (parent_handle != IP_NULL &amp;&amp;
	    ip_kotype(parent_handle) == IKOT_NAMED_ENTRY) {
		parent_entry = (vm_named_entry_t) parent_handle-&gt;ip_kobject;
	} <span class="enscript-keyword">else</span> {
		parent_entry = NULL;
	}

	<span class="enscript-keyword">if</span> (parent_entry &amp;&amp; parent_entry-&gt;is_copy) {
		<span class="enscript-keyword">return</span> KERN_INVALID_ARGUMENT;
	}

	original_protections = permission &amp; VM_PROT_ALL;
	protections = original_protections;
	mask_protections = permission &amp; VM_PROT_IS_MASK;
	access = GET_MAP_MEM(permission);
	use_data_addr = ((permission &amp; MAP_MEM_USE_DATA_ADDR) != 0);
	use_4K_compat = ((permission &amp; MAP_MEM_4K_DATA_ADDR) != 0);

	user_handle = IP_NULL;
	user_entry = NULL;

	map_start = vm_map_trunc_page(offset, PAGE_MASK);

	<span class="enscript-keyword">if</span> (permission &amp; MAP_MEM_ONLY) {
		boolean_t		parent_is_object;

		map_end = vm_map_round_page(offset + *size, PAGE_MASK);
		map_size = map_end - map_start;
		
		<span class="enscript-keyword">if</span> (use_data_addr || use_4K_compat || parent_entry == NULL) {
			<span class="enscript-keyword">return</span> KERN_INVALID_ARGUMENT;
		}

		parent_is_object = !(parent_entry-&gt;is_sub_map ||
				     parent_entry-&gt;is_pager);
		object = parent_entry-&gt;backing.object;
		<span class="enscript-keyword">if</span>(parent_is_object &amp;&amp; object != VM_OBJECT_NULL)
			wimg_mode = object-&gt;wimg_bits;
		<span class="enscript-keyword">else</span>
			wimg_mode = VM_WIMG_USE_DEFAULT;
		<span class="enscript-keyword">if</span>((access != GET_MAP_MEM(parent_entry-&gt;protection)) &amp;&amp;
				!(parent_entry-&gt;protection &amp; VM_PROT_WRITE)) { 
			<span class="enscript-keyword">return</span> KERN_INVALID_RIGHT;
		}
		<span class="enscript-keyword">if</span>(access == MAP_MEM_IO) {
		   SET_MAP_MEM(access, parent_entry-&gt;protection);
		   wimg_mode = VM_WIMG_IO;
		} <span class="enscript-keyword">else</span> <span class="enscript-keyword">if</span> (access == MAP_MEM_COPYBACK) {
		   SET_MAP_MEM(access, parent_entry-&gt;protection);
		   wimg_mode = VM_WIMG_USE_DEFAULT;
		} <span class="enscript-keyword">else</span> <span class="enscript-keyword">if</span> (access == MAP_MEM_INNERWBACK) {
		   SET_MAP_MEM(access, parent_entry-&gt;protection);
		   wimg_mode = VM_WIMG_INNERWBACK;
		} <span class="enscript-keyword">else</span> <span class="enscript-keyword">if</span> (access == MAP_MEM_WTHRU) {
		   SET_MAP_MEM(access, parent_entry-&gt;protection);
		   wimg_mode = VM_WIMG_WTHRU;
		} <span class="enscript-keyword">else</span> <span class="enscript-keyword">if</span> (access == MAP_MEM_WCOMB) {
		   SET_MAP_MEM(access, parent_entry-&gt;protection);
		   wimg_mode = VM_WIMG_WCOMB;
		}
		<span class="enscript-keyword">if</span> (parent_is_object &amp;&amp; object &amp;&amp;
			(access != MAP_MEM_NOOP) &amp;&amp; 
			(!(object-&gt;nophyscache))) {

			<span class="enscript-keyword">if</span> (object-&gt;wimg_bits != wimg_mode) {
				vm_object_lock(object);
				vm_object_change_wimg_mode(object, wimg_mode);
				vm_object_unlock(object);
			}
		}
		<span class="enscript-keyword">if</span> (object_handle)
			*object_handle = IP_NULL;
		<span class="enscript-keyword">return</span> KERN_SUCCESS;
	} <span class="enscript-keyword">else</span> <span class="enscript-keyword">if</span> (permission &amp; MAP_MEM_NAMED_CREATE) {
		map_end = vm_map_round_page(offset + *size, PAGE_MASK);
		map_size = map_end - map_start;

		<span class="enscript-keyword">if</span> (use_data_addr || use_4K_compat) {
			<span class="enscript-keyword">return</span> KERN_INVALID_ARGUMENT;
		}

		kr = mach_memory_entry_allocate(&amp;user_entry, &amp;user_handle);
		<span class="enscript-keyword">if</span> (kr != KERN_SUCCESS) {
			<span class="enscript-keyword">return</span> KERN_FAILURE;
		}

		<span class="enscript-comment">/*
		 * Force the creation of the VM object now.
		 */</span>
		<span class="enscript-keyword">if</span> (map_size &gt; (vm_map_size_t) ANON_MAX_SIZE) {
			<span class="enscript-comment">/*
			 * LP64todo - for now, we can only allocate 4GB-4096
			 * internal objects because the default pager can't
			 * page bigger ones.  Remove this when it can.
			 */</span>
			kr = KERN_FAILURE;
			<span class="enscript-keyword">goto</span> <span class="enscript-reference">make_mem_done</span>;
		}

		object = vm_object_allocate(map_size);
		assert(object != VM_OBJECT_NULL);

		<span class="enscript-keyword">if</span> (permission &amp; MAP_MEM_PURGABLE) {
			<span class="enscript-keyword">if</span> (! (permission &amp; VM_PROT_WRITE)) {
				<span class="enscript-comment">/* if we can't write, we can't purge */</span>
				vm_object_deallocate(object);
				kr = KERN_INVALID_ARGUMENT;
				<span class="enscript-keyword">goto</span> <span class="enscript-reference">make_mem_done</span>;
			}
			object-&gt;purgable = VM_PURGABLE_NONVOLATILE;
			assert(object-&gt;vo_purgeable_owner == NULL);
			assert(object-&gt;resident_page_count == 0);
			assert(object-&gt;wired_page_count == 0);
			vm_object_lock(object);
			vm_purgeable_nonvolatile_enqueue(object,
							 current_task());
			vm_object_unlock(object);
		}

		<span class="enscript-comment">/*
		 * The VM object is brand new and nobody else knows about it,
		 * so we don't need to lock it.
		 */</span>

		wimg_mode = object-&gt;wimg_bits;
		<span class="enscript-keyword">if</span> (access == MAP_MEM_IO) {
			wimg_mode = VM_WIMG_IO;
		} <span class="enscript-keyword">else</span> <span class="enscript-keyword">if</span> (access == MAP_MEM_COPYBACK) {
			wimg_mode = VM_WIMG_USE_DEFAULT;
		} <span class="enscript-keyword">else</span> <span class="enscript-keyword">if</span> (access == MAP_MEM_INNERWBACK) {
			wimg_mode = VM_WIMG_INNERWBACK;
		} <span class="enscript-keyword">else</span> <span class="enscript-keyword">if</span> (access == MAP_MEM_WTHRU) {
			wimg_mode = VM_WIMG_WTHRU;
		} <span class="enscript-keyword">else</span> <span class="enscript-keyword">if</span> (access == MAP_MEM_WCOMB) {
			wimg_mode = VM_WIMG_WCOMB;
		}
		<span class="enscript-keyword">if</span> (access != MAP_MEM_NOOP) {
			object-&gt;wimg_bits = wimg_mode;
		}
		<span class="enscript-comment">/* the object has no pages, so no WIMG bits to update here */</span>

		<span class="enscript-comment">/*
		 * XXX
		 * We use this path when we want to make sure that
		 * nobody messes with the object (coalesce, for
		 * example) before we map it.
		 * We might want to use these objects for transposition via
		 * vm_object_transpose() too, so we don't want any copy or
		 * shadow objects either...
		 */</span>
		object-&gt;copy_strategy = MEMORY_OBJECT_COPY_NONE;
		object-&gt;true_share = TRUE;

		user_entry-&gt;backing.object = object;
		user_entry-&gt;internal = TRUE;
		user_entry-&gt;is_sub_map = FALSE;
		user_entry-&gt;is_pager = FALSE;
		user_entry-&gt;offset = 0;
		user_entry-&gt;data_offset = 0;
		user_entry-&gt;protection = protections;
		SET_MAP_MEM(access, user_entry-&gt;protection);
		user_entry-&gt;size = map_size;

		<span class="enscript-comment">/* user_object pager and internal fields are not used */</span>
		<span class="enscript-comment">/* when the object field is filled in.		      */</span>

		*size = CAST_DOWN(vm_size_t, (user_entry-&gt;size -
					      user_entry-&gt;data_offset));
		*object_handle = user_handle;
		<span class="enscript-keyword">return</span> KERN_SUCCESS;
	}

	<span class="enscript-keyword">if</span> (permission &amp; MAP_MEM_VM_COPY) {
		vm_map_copy_t	copy;

		<span class="enscript-keyword">if</span> (target_map == VM_MAP_NULL) {
			<span class="enscript-keyword">return</span> KERN_INVALID_TASK;
		}

		map_end = vm_map_round_page(offset + *size, PAGE_MASK);
		map_size = map_end - map_start;
		<span class="enscript-keyword">if</span> (use_data_addr || use_4K_compat) {
			offset_in_page = offset - map_start;
			<span class="enscript-keyword">if</span> (use_4K_compat)
				offset_in_page &amp;= ~((<span class="enscript-type">signed</span>)(0xFFF));
		} <span class="enscript-keyword">else</span> {
			offset_in_page = 0;
		}

		kr = vm_map_copyin(target_map,
				   map_start,
				   map_size,
				   FALSE,
				   &amp;copy);
		<span class="enscript-keyword">if</span> (kr != KERN_SUCCESS) {
			<span class="enscript-keyword">return</span> kr;
		}
				   
		kr = mach_memory_entry_allocate(&amp;user_entry, &amp;user_handle);
		<span class="enscript-keyword">if</span> (kr != KERN_SUCCESS) {
			vm_map_copy_discard(copy);
			<span class="enscript-keyword">return</span> KERN_FAILURE;
		}

		user_entry-&gt;backing.copy = copy;
		user_entry-&gt;internal = FALSE;
		user_entry-&gt;is_sub_map = FALSE;
		user_entry-&gt;is_pager = FALSE;
		user_entry-&gt;is_copy = TRUE;
		user_entry-&gt;offset = 0;
		user_entry-&gt;protection = protections;
		user_entry-&gt;size = map_size;
		user_entry-&gt;data_offset = offset_in_page;

		*size = CAST_DOWN(vm_size_t, (user_entry-&gt;size -
					      user_entry-&gt;data_offset));
		*object_handle = user_handle;
		<span class="enscript-keyword">return</span> KERN_SUCCESS;
	}

	<span class="enscript-keyword">if</span> (permission &amp; MAP_MEM_VM_SHARE) {
		vm_map_copy_t	copy;
		vm_prot_t	cur_prot, max_prot;

		<span class="enscript-keyword">if</span> (target_map == VM_MAP_NULL) {
			<span class="enscript-keyword">return</span> KERN_INVALID_TASK;
		}

		map_end = vm_map_round_page(offset + *size, PAGE_MASK);
		map_size = map_end - map_start;
		<span class="enscript-keyword">if</span> (use_data_addr || use_4K_compat) {
			offset_in_page = offset - map_start;
			<span class="enscript-keyword">if</span> (use_4K_compat)
				offset_in_page &amp;= ~((<span class="enscript-type">signed</span>)(0xFFF));
		} <span class="enscript-keyword">else</span> {
			offset_in_page = 0;
		}

		kr = vm_map_copy_extract(target_map,
					 map_start,
					 map_size,
					 &amp;copy,
					 &amp;cur_prot,
					 &amp;max_prot);
		<span class="enscript-keyword">if</span> (kr != KERN_SUCCESS) {
			<span class="enscript-keyword">return</span> kr;
		}

		<span class="enscript-keyword">if</span> (mask_protections) {
			<span class="enscript-comment">/*
			 * We just want as much of &quot;original_protections&quot; 
			 * as we can get out of the actual &quot;cur_prot&quot;.
			 */</span>
			protections &amp;= cur_prot;
			<span class="enscript-keyword">if</span> (protections == VM_PROT_NONE) {
				<span class="enscript-comment">/* no access at all: fail */</span>
				vm_map_copy_discard(copy);
				<span class="enscript-keyword">return</span> KERN_PROTECTION_FAILURE;
			}
		} <span class="enscript-keyword">else</span> {
			<span class="enscript-comment">/*
			 * We want exactly &quot;original_protections&quot;
			 * out of &quot;cur_prot&quot;.
			 */</span>
			<span class="enscript-keyword">if</span> ((cur_prot &amp; protections) != protections) {
				vm_map_copy_discard(copy);
				<span class="enscript-keyword">return</span> KERN_PROTECTION_FAILURE;
			}
		}

		kr = mach_memory_entry_allocate(&amp;user_entry, &amp;user_handle);
		<span class="enscript-keyword">if</span> (kr != KERN_SUCCESS) {
			vm_map_copy_discard(copy);
			<span class="enscript-keyword">return</span> KERN_FAILURE;
		}

		user_entry-&gt;backing.copy = copy;
		user_entry-&gt;internal = FALSE;
		user_entry-&gt;is_sub_map = FALSE;
		user_entry-&gt;is_pager = FALSE;
		user_entry-&gt;is_copy = TRUE;
		user_entry-&gt;offset = 0;
		user_entry-&gt;protection = protections;
		user_entry-&gt;size = map_size;
		user_entry-&gt;data_offset = offset_in_page;

		*size = CAST_DOWN(vm_size_t, (user_entry-&gt;size -
					      user_entry-&gt;data_offset));
		*object_handle = user_handle;
		<span class="enscript-keyword">return</span> KERN_SUCCESS;
	}

	<span class="enscript-keyword">if</span> (parent_entry == NULL ||
	    (permission &amp; MAP_MEM_NAMED_REUSE)) {

		map_end = vm_map_round_page(offset + *size, PAGE_MASK);
		map_size = map_end - map_start;
		<span class="enscript-keyword">if</span> (use_data_addr || use_4K_compat) {
			offset_in_page = offset - map_start;
			<span class="enscript-keyword">if</span> (use_4K_compat)
				offset_in_page &amp;= ~((<span class="enscript-type">signed</span>)(0xFFF));
		} <span class="enscript-keyword">else</span> {
			offset_in_page = 0;
		}

		<span class="enscript-comment">/* Create a named object based on address range within the task map */</span>
		<span class="enscript-comment">/* Go find the object at given address */</span>

		<span class="enscript-keyword">if</span> (target_map == VM_MAP_NULL) {
			<span class="enscript-keyword">return</span> KERN_INVALID_TASK;
		}

<span class="enscript-reference">redo_lookup</span>:
		protections = original_protections;
		vm_map_lock_read(target_map);

		<span class="enscript-comment">/* get the object associated with the target address */</span>
		<span class="enscript-comment">/* note we check the permission of the range against */</span>
		<span class="enscript-comment">/* that requested by the caller */</span>

		kr = vm_map_lookup_locked(&amp;target_map, map_start, 
					  protections | mask_protections,
					  OBJECT_LOCK_EXCLUSIVE, &amp;version,
					  &amp;object, &amp;obj_off, &amp;prot, &amp;wired,
					  &amp;fault_info,
					  &amp;real_map);
		<span class="enscript-keyword">if</span> (kr != KERN_SUCCESS) {
			vm_map_unlock_read(target_map);
			<span class="enscript-keyword">goto</span> <span class="enscript-reference">make_mem_done</span>;
		}
		<span class="enscript-keyword">if</span> (mask_protections) {
			<span class="enscript-comment">/*
			 * The caller asked us to use the &quot;protections&quot; as
			 * a mask, so restrict &quot;protections&quot; to what this
			 * mapping actually allows.
			 */</span>
			protections &amp;= prot;
		}
		<span class="enscript-keyword">if</span> (((prot &amp; protections) != protections) 
					|| (object == kernel_object)) {
			kr = KERN_INVALID_RIGHT;
			vm_object_unlock(object);
			vm_map_unlock_read(target_map);
			<span class="enscript-keyword">if</span>(real_map != target_map)
				vm_map_unlock_read(real_map);
			<span class="enscript-keyword">if</span>(object == kernel_object) {
				printf(<span class="enscript-string">&quot;Warning: Attempt to create a named&quot;</span>
					<span class="enscript-string">&quot; entry from the kernel_object\n&quot;</span>);
			}
			<span class="enscript-keyword">goto</span> <span class="enscript-reference">make_mem_done</span>;
		}

		<span class="enscript-comment">/* We have an object, now check to see if this object */</span>
		<span class="enscript-comment">/* is suitable.  If not, create a shadow and share that */</span>

		<span class="enscript-comment">/*
		 * We have to unlock the VM object to avoid deadlocking with
		 * a VM map lock (the lock ordering is map, the object), if we
		 * need to modify the VM map to create a shadow object.  Since
		 * we might release the VM map lock below anyway, we have
		 * to release the VM map lock now.
		 * XXX FBDP There must be a way to avoid this double lookup...
		 *
		 * Take an extra reference on the VM object to make sure it's
		 * not going to disappear.
		 */</span>
		vm_object_reference_locked(object); <span class="enscript-comment">/* extra ref to hold obj */</span>
		vm_object_unlock(object);

		local_map = original_map;
		local_offset = map_start;
		<span class="enscript-keyword">if</span>(target_map != local_map) {
			vm_map_unlock_read(target_map);
			<span class="enscript-keyword">if</span>(real_map != target_map)
				vm_map_unlock_read(real_map);
			vm_map_lock_read(local_map);
			target_map = local_map;
			real_map = local_map;
		}
		<span class="enscript-keyword">while</span>(TRUE) {
		   <span class="enscript-keyword">if</span>(!vm_map_lookup_entry(local_map, 
						local_offset, &amp;map_entry)) {
			kr = KERN_INVALID_ARGUMENT;
                        vm_map_unlock_read(target_map);
			<span class="enscript-keyword">if</span>(real_map != target_map)
				vm_map_unlock_read(real_map);
                        vm_object_deallocate(object); <span class="enscript-comment">/* release extra ref */</span>
			object = VM_OBJECT_NULL;
                        <span class="enscript-keyword">goto</span> <span class="enscript-reference">make_mem_done</span>;
		   }
		   iskernel = (local_map-&gt;pmap == kernel_pmap);
		   <span class="enscript-keyword">if</span>(!(map_entry-&gt;is_sub_map)) {
		      <span class="enscript-keyword">if</span> (VME_OBJECT(map_entry) != object) {
			 kr = KERN_INVALID_ARGUMENT;
                         vm_map_unlock_read(target_map);
			 <span class="enscript-keyword">if</span>(real_map != target_map)
				vm_map_unlock_read(real_map);
                         vm_object_deallocate(object); <span class="enscript-comment">/* release extra ref */</span>
			 object = VM_OBJECT_NULL;
                         <span class="enscript-keyword">goto</span> <span class="enscript-reference">make_mem_done</span>;
	              }
		      <span class="enscript-keyword">break</span>;
		   } <span class="enscript-keyword">else</span> {
			vm_map_t	tmap;
			tmap = local_map;
			local_map = VME_SUBMAP(map_entry);
			
			vm_map_lock_read(local_map);
			vm_map_unlock_read(tmap);
			target_map = local_map;
			real_map = local_map;
			local_offset = local_offset - map_entry-&gt;vme_start;
			local_offset += VME_OFFSET(map_entry);
		   }
		}

		<span class="enscript-comment">/*
		 * We found the VM map entry, lock the VM object again.
		 */</span>
		vm_object_lock(object);
		<span class="enscript-keyword">if</span>(map_entry-&gt;wired_count) {
			 <span class="enscript-comment">/* JMM - The check below should be reworked instead. */</span>
			 object-&gt;true_share = TRUE;
		      }
		<span class="enscript-keyword">if</span> (mask_protections) {
			<span class="enscript-comment">/*
			 * The caller asked us to use the &quot;protections&quot; as
			 * a mask, so restrict &quot;protections&quot; to what this
			 * mapping actually allows.
			 */</span>
			protections &amp;= map_entry-&gt;max_protection;
		}
		<span class="enscript-keyword">if</span>(((map_entry-&gt;max_protection) &amp; protections) != protections) {
			 kr = KERN_INVALID_RIGHT;
                         vm_object_unlock(object);
                         vm_map_unlock_read(target_map);
			 <span class="enscript-keyword">if</span>(real_map != target_map)
				vm_map_unlock_read(real_map);
			 vm_object_deallocate(object);
			 object = VM_OBJECT_NULL;
                         <span class="enscript-keyword">goto</span> <span class="enscript-reference">make_mem_done</span>;
		}

		mappable_size = fault_info.hi_offset - obj_off;
		total_size = map_entry-&gt;vme_end - map_entry-&gt;vme_start;
		<span class="enscript-keyword">if</span>(map_size &gt; mappable_size) {
			<span class="enscript-comment">/* try to extend mappable size if the entries */</span>
			<span class="enscript-comment">/* following are from the same object and are */</span>
			<span class="enscript-comment">/* compatible */</span>
			next_entry = map_entry-&gt;vme_next;
			<span class="enscript-comment">/* lets see if the next map entry is still   */</span>
			<span class="enscript-comment">/* pointing at this object and is contiguous */</span>
			<span class="enscript-keyword">while</span>(map_size &gt; mappable_size) {
				<span class="enscript-keyword">if</span> ((VME_OBJECT(next_entry) == object) &amp;&amp;
				    (next_entry-&gt;vme_start == 
				     next_entry-&gt;vme_prev-&gt;vme_end) &amp;&amp;
				    (VME_OFFSET(next_entry) == 
				     (VME_OFFSET(next_entry-&gt;vme_prev) + 
				      (next_entry-&gt;vme_prev-&gt;vme_end - 
				       next_entry-&gt;vme_prev-&gt;vme_start)))) {
					<span class="enscript-keyword">if</span> (mask_protections) {
						<span class="enscript-comment">/*
						 * The caller asked us to use
						 * the &quot;protections&quot; as a mask,
						 * so restrict &quot;protections&quot; to
						 * what this mapping actually
						 * allows.
						 */</span>
						protections &amp;= next_entry-&gt;max_protection;
					}
					<span class="enscript-keyword">if</span> ((next_entry-&gt;wired_count) &amp;&amp;
					    (map_entry-&gt;wired_count == 0)) {
						<span class="enscript-keyword">break</span>;
					}
					<span class="enscript-keyword">if</span>(((next_entry-&gt;max_protection) 
						&amp; protections) != protections) {
			 			<span class="enscript-keyword">break</span>;
					}
					<span class="enscript-keyword">if</span> (next_entry-&gt;needs_copy !=
					    map_entry-&gt;needs_copy)
						<span class="enscript-keyword">break</span>;
					mappable_size += next_entry-&gt;vme_end
						- next_entry-&gt;vme_start;
					total_size += next_entry-&gt;vme_end
						- next_entry-&gt;vme_start;
					next_entry = next_entry-&gt;vme_next;
				} <span class="enscript-keyword">else</span> {
					<span class="enscript-keyword">break</span>;
				}
			
			}
		}

		<span class="enscript-comment">/* vm_map_entry_should_cow_for_true_share() checks for malloc tags,
		 * never true in kernel */</span> 
		<span class="enscript-keyword">if</span> (!iskernel &amp;&amp; vm_map_entry_should_cow_for_true_share(map_entry) &amp;&amp;
		    object-&gt;vo_size &gt; map_size &amp;&amp;
		    map_size != 0) {
			<span class="enscript-comment">/*
			 * Set up the targeted range for copy-on-write to
			 * limit the impact of &quot;true_share&quot;/&quot;copy_delay&quot; to
			 * that range instead of the entire VM object...
			 */</span>
			
			vm_object_unlock(object);
			<span class="enscript-keyword">if</span> (vm_map_lock_read_to_write(target_map)) {
				vm_object_deallocate(object);
				target_map = original_map;
				<span class="enscript-keyword">goto</span> <span class="enscript-reference">redo_lookup</span>;
			}

			vm_map_clip_start(target_map,
					  map_entry,
					  vm_map_trunc_page(map_start,
							    VM_MAP_PAGE_MASK(target_map)));
			vm_map_clip_end(target_map,
					map_entry,
					(vm_map_round_page(map_end,
							   VM_MAP_PAGE_MASK(target_map))));
			force_shadow = TRUE;

			<span class="enscript-keyword">if</span> ((map_entry-&gt;vme_end - offset) &lt; map_size) {
				map_size = map_entry-&gt;vme_end - map_start;
			}
			total_size = map_entry-&gt;vme_end - map_entry-&gt;vme_start;

			vm_map_lock_write_to_read(target_map);
			vm_object_lock(object);
		}

		<span class="enscript-keyword">if</span> (object-&gt;internal) {
	   		<span class="enscript-comment">/* vm_map_lookup_locked will create a shadow if   */</span>
		 	<span class="enscript-comment">/* needs_copy is set but does not check for the   */</span>
			<span class="enscript-comment">/* other two conditions shown. It is important to */</span> 
			<span class="enscript-comment">/* set up an object which will not be pulled from */</span>
			<span class="enscript-comment">/* under us.  */</span>

	      		<span class="enscript-keyword">if</span> (force_shadow ||
			    ((map_entry-&gt;needs_copy  ||
			      object-&gt;shadowed ||
			      (object-&gt;vo_size &gt; total_size &amp;&amp;
			       (VME_OFFSET(map_entry) != 0 ||
				object-&gt;vo_size &gt;
				vm_map_round_page(total_size,
						  VM_MAP_PAGE_MASK(target_map)))))
			     &amp;&amp; !object-&gt;true_share)) {
				<span class="enscript-comment">/*
				 * We have to unlock the VM object before
				 * trying to upgrade the VM map lock, to
				 * honor lock ordering (map then object).
				 * Otherwise, we would deadlock if another
				 * thread holds a read lock on the VM map and
				 * is trying to acquire the VM object's lock.
				 * We still hold an extra reference on the
				 * VM object, guaranteeing that it won't
				 * disappear.
				 */</span>
				vm_object_unlock(object);

		   		<span class="enscript-keyword">if</span> (vm_map_lock_read_to_write(target_map)) {
					<span class="enscript-comment">/*
					 * We couldn't upgrade our VM map lock
					 * from &quot;read&quot; to &quot;write&quot; and we lost
					 * our &quot;read&quot; lock.
					 * Start all over again...
					 */</span>
					vm_object_deallocate(object); <span class="enscript-comment">/* extra ref */</span>
					target_map = original_map;
		            		<span class="enscript-keyword">goto</span> <span class="enscript-reference">redo_lookup</span>;
		   		}
#<span class="enscript-reference">if</span> 00
				vm_object_lock(object);
#<span class="enscript-reference">endif</span>

				<span class="enscript-comment">/* 
				 * JMM - We need to avoid coming here when the object
				 * is wired by anybody, not just the current map.  Why
				 * couldn't we use the standard vm_object_copy_quickly()
				 * approach here?
				 */</span>
				 
		   		<span class="enscript-comment">/* create a shadow object */</span>
				VME_OBJECT_SHADOW(map_entry, total_size);
				shadow_object = VME_OBJECT(map_entry);
#<span class="enscript-reference">if</span> 00
				vm_object_unlock(object);
#<span class="enscript-reference">endif</span>

				prot = map_entry-&gt;protection &amp; ~VM_PROT_WRITE;

				<span class="enscript-keyword">if</span> (override_nx(target_map,
						VME_ALIAS(map_entry))
				    &amp;&amp; prot)
				        prot |= VM_PROT_EXECUTE;

				vm_object_pmap_protect(
					object, VME_OFFSET(map_entry),
					total_size,
					((map_entry-&gt;is_shared 
					  || target_map-&gt;mapped_in_other_pmaps)
							? PMAP_NULL :
							target_map-&gt;pmap),
					map_entry-&gt;vme_start,
					prot);
				total_size -= (map_entry-&gt;vme_end 
						- map_entry-&gt;vme_start);
				next_entry = map_entry-&gt;vme_next;
				map_entry-&gt;needs_copy = FALSE;

				vm_object_lock(shadow_object);
				<span class="enscript-keyword">while</span> (total_size) {
				    assert((next_entry-&gt;wired_count == 0) ||
					   (map_entry-&gt;wired_count));

				    <span class="enscript-keyword">if</span> (VME_OBJECT(next_entry) == object) {
					vm_object_reference_locked(shadow_object);
					VME_OBJECT_SET(next_entry,
						       shadow_object);
					vm_object_deallocate(object);
					VME_OFFSET_SET(
						next_entry,
						(VME_OFFSET(next_entry-&gt;vme_prev) +
						 (next_entry-&gt;vme_prev-&gt;vme_end 
						  - next_entry-&gt;vme_prev-&gt;vme_start)));
						next_entry-&gt;needs_copy = FALSE;
					} <span class="enscript-keyword">else</span> {
						panic(<span class="enscript-string">&quot;mach_make_memory_entry_64:&quot;</span>
						  <span class="enscript-string">&quot; map entries out of sync\n&quot;</span>);
					}
					total_size -= 
						next_entry-&gt;vme_end 
							- next_entry-&gt;vme_start;
					next_entry = next_entry-&gt;vme_next;
				}

				<span class="enscript-comment">/*
				 * Transfer our extra reference to the
				 * shadow object.
				 */</span>
				vm_object_reference_locked(shadow_object);
				vm_object_deallocate(object); <span class="enscript-comment">/* extra ref */</span>
				object = shadow_object;

				obj_off = ((local_offset - map_entry-&gt;vme_start)
					   + VME_OFFSET(map_entry));

				vm_map_lock_write_to_read(target_map);
	        	}
	   	}

		<span class="enscript-comment">/* note: in the future we can (if necessary) allow for  */</span>
		<span class="enscript-comment">/* memory object lists, this will better support        */</span>
		<span class="enscript-comment">/* fragmentation, but is it necessary?  The user should */</span>
		<span class="enscript-comment">/* be encouraged to create address space oriented       */</span>
		<span class="enscript-comment">/* shared objects from CLEAN memory regions which have  */</span>
		<span class="enscript-comment">/* a known and defined history.  i.e. no inheritence    */</span>
		<span class="enscript-comment">/* share, make this call before making the region the   */</span>
		<span class="enscript-comment">/* target of ipc's, etc.  The code above, protecting    */</span>
		<span class="enscript-comment">/* against delayed copy, etc. is mostly defensive.      */</span>

		wimg_mode = object-&gt;wimg_bits;
		<span class="enscript-keyword">if</span>(!(object-&gt;nophyscache)) {
			<span class="enscript-keyword">if</span>(access == MAP_MEM_IO) {
				wimg_mode = VM_WIMG_IO;
			} <span class="enscript-keyword">else</span> <span class="enscript-keyword">if</span> (access == MAP_MEM_COPYBACK) {
				wimg_mode = VM_WIMG_USE_DEFAULT;
			} <span class="enscript-keyword">else</span> <span class="enscript-keyword">if</span> (access == MAP_MEM_INNERWBACK) {
				wimg_mode = VM_WIMG_INNERWBACK;
			} <span class="enscript-keyword">else</span> <span class="enscript-keyword">if</span> (access == MAP_MEM_WTHRU) {
				wimg_mode = VM_WIMG_WTHRU;
			} <span class="enscript-keyword">else</span> <span class="enscript-keyword">if</span> (access == MAP_MEM_WCOMB) {
				wimg_mode = VM_WIMG_WCOMB;
			}
		}

#<span class="enscript-reference">if</span> <span class="enscript-variable-name">VM_OBJECT_TRACKING_OP_TRUESHARE</span>
		<span class="enscript-keyword">if</span> (!object-&gt;true_share &amp;&amp;
		    vm_object_tracking_inited) {
			<span class="enscript-type">void</span> *bt[VM_OBJECT_TRACKING_BTDEPTH];
			<span class="enscript-type">int</span> num = 0;

			num = OSBacktrace(bt,
					  VM_OBJECT_TRACKING_BTDEPTH);
			btlog_add_entry(vm_object_tracking_btlog,
					object,
					VM_OBJECT_TRACKING_OP_TRUESHARE,
					bt,
					num);
		}
#<span class="enscript-reference">endif</span> <span class="enscript-comment">/* VM_OBJECT_TRACKING_OP_TRUESHARE */</span>

		object-&gt;true_share = TRUE;
		<span class="enscript-keyword">if</span> (object-&gt;copy_strategy == MEMORY_OBJECT_COPY_SYMMETRIC)
			object-&gt;copy_strategy = MEMORY_OBJECT_COPY_DELAY;

		<span class="enscript-comment">/*
		 * The memory entry now points to this VM object and we
		 * need to hold a reference on the VM object.  Use the extra
		 * reference we took earlier to keep the object alive when we
		 * had to unlock it.
		 */</span>

		vm_map_unlock_read(target_map);
		<span class="enscript-keyword">if</span>(real_map != target_map)
			vm_map_unlock_read(real_map);

		<span class="enscript-keyword">if</span> (object-&gt;wimg_bits != wimg_mode)
			vm_object_change_wimg_mode(object, wimg_mode);

		<span class="enscript-comment">/* the size of mapped entry that overlaps with our region */</span>
		<span class="enscript-comment">/* which is targeted for share.                           */</span>
		<span class="enscript-comment">/* (entry_end - entry_start) -                            */</span>
		<span class="enscript-comment">/*                   offset of our beg addr within entry  */</span>
		<span class="enscript-comment">/* it corresponds to this:                                */</span>

		<span class="enscript-keyword">if</span>(map_size &gt; mappable_size)
			map_size = mappable_size;

		<span class="enscript-keyword">if</span> (permission &amp; MAP_MEM_NAMED_REUSE) {
			<span class="enscript-comment">/*
			 * Compare what we got with the &quot;parent_entry&quot;.
			 * If they match, re-use the &quot;parent_entry&quot; instead
			 * of creating a new one.
			 */</span>
			<span class="enscript-keyword">if</span> (parent_entry != NULL &amp;&amp;
			    parent_entry-&gt;backing.object == object &amp;&amp;
			    parent_entry-&gt;internal == object-&gt;internal &amp;&amp;
			    parent_entry-&gt;is_sub_map == FALSE &amp;&amp;
			    parent_entry-&gt;is_pager == FALSE &amp;&amp;
			    parent_entry-&gt;offset == obj_off &amp;&amp;
			    parent_entry-&gt;protection == protections &amp;&amp;
			    parent_entry-&gt;size == map_size &amp;&amp;
			    ((!(use_data_addr || use_4K_compat) &amp;&amp;
			      (parent_entry-&gt;data_offset == 0)) ||  
			     ((use_data_addr || use_4K_compat) &amp;&amp;
			      (parent_entry-&gt;data_offset == offset_in_page)))) {
				<span class="enscript-comment">/*
				 * We have a match: re-use &quot;parent_entry&quot;.
				 */</span>
				<span class="enscript-comment">/* release our extra reference on object */</span>
				vm_object_unlock(object);
				vm_object_deallocate(object);
				<span class="enscript-comment">/* parent_entry-&gt;ref_count++; XXX ? */</span>
				<span class="enscript-comment">/* Get an extra send-right on handle */</span>
				ipc_port_copy_send(parent_handle);

				*size = CAST_DOWN(vm_size_t,
						  (parent_entry-&gt;size -
						   parent_entry-&gt;data_offset));
				*object_handle = parent_handle;
				<span class="enscript-keyword">return</span> KERN_SUCCESS;
			} <span class="enscript-keyword">else</span> {
				<span class="enscript-comment">/*
				 * No match: we need to create a new entry.
				 * fall through...
				 */</span>
			}
		}

		vm_object_unlock(object);
		<span class="enscript-keyword">if</span> (mach_memory_entry_allocate(&amp;user_entry, &amp;user_handle)
		    != KERN_SUCCESS) {
			<span class="enscript-comment">/* release our unused reference on the object */</span>
			vm_object_deallocate(object);
			<span class="enscript-keyword">return</span> KERN_FAILURE;
		}

		user_entry-&gt;backing.object = object;
		user_entry-&gt;internal = object-&gt;internal;
		user_entry-&gt;is_sub_map = FALSE;
		user_entry-&gt;is_pager = FALSE;
		user_entry-&gt;offset = obj_off;
		user_entry-&gt;data_offset = offset_in_page;
		user_entry-&gt;protection = protections;
		SET_MAP_MEM(GET_MAP_MEM(permission), user_entry-&gt;protection);
		user_entry-&gt;size = map_size;

		<span class="enscript-comment">/* user_object pager and internal fields are not used */</span>
		<span class="enscript-comment">/* when the object field is filled in.		      */</span>

		*size = CAST_DOWN(vm_size_t, (user_entry-&gt;size -
					      user_entry-&gt;data_offset));
		*object_handle = user_handle;
		<span class="enscript-keyword">return</span> KERN_SUCCESS;

	} <span class="enscript-keyword">else</span> {
		<span class="enscript-comment">/* The new object will be base on an existing named object */</span>
		<span class="enscript-keyword">if</span> (parent_entry == NULL) {
			kr = KERN_INVALID_ARGUMENT;
			<span class="enscript-keyword">goto</span> <span class="enscript-reference">make_mem_done</span>;
		}

		<span class="enscript-keyword">if</span> (use_data_addr || use_4K_compat) {
			<span class="enscript-comment">/*
			 * submaps and pagers should only be accessible from within
			 * the kernel, which shouldn't use the data address flag, so can fail here.
			 */</span>
			<span class="enscript-keyword">if</span> (parent_entry-&gt;is_pager || parent_entry-&gt;is_sub_map) {
				panic(<span class="enscript-string">&quot;Shouldn't be using data address with a parent entry that is a submap or pager.&quot;</span>);
			}
			<span class="enscript-comment">/*
			 * Account for offset to data in parent entry and
			 * compute our own offset to data.
			 */</span>
			<span class="enscript-keyword">if</span>((offset + *size + parent_entry-&gt;data_offset) &gt; parent_entry-&gt;size) {
				kr = KERN_INVALID_ARGUMENT;
				<span class="enscript-keyword">goto</span> <span class="enscript-reference">make_mem_done</span>;
			}

			map_start = vm_map_trunc_page(offset + parent_entry-&gt;data_offset, PAGE_MASK);
			offset_in_page = (offset + parent_entry-&gt;data_offset) - map_start;
			<span class="enscript-keyword">if</span> (use_4K_compat)
				offset_in_page &amp;= ~((<span class="enscript-type">signed</span>)(0xFFF));
			map_end = vm_map_round_page(offset + parent_entry-&gt;data_offset + *size, PAGE_MASK);
			map_size = map_end - map_start;
		} <span class="enscript-keyword">else</span> {
			map_end = vm_map_round_page(offset + *size, PAGE_MASK);
			map_size = map_end - map_start;
			offset_in_page = 0;

			<span class="enscript-keyword">if</span>((offset + map_size) &gt; parent_entry-&gt;size) {
				kr = KERN_INVALID_ARGUMENT;
				<span class="enscript-keyword">goto</span> <span class="enscript-reference">make_mem_done</span>;
			}
		}

		<span class="enscript-keyword">if</span> (mask_protections) {
			<span class="enscript-comment">/*
			 * The caller asked us to use the &quot;protections&quot; as
			 * a mask, so restrict &quot;protections&quot; to what this
			 * mapping actually allows.
			 */</span>
			protections &amp;= parent_entry-&gt;protection;
		}
		<span class="enscript-keyword">if</span>((protections &amp; parent_entry-&gt;protection) != protections) {
			kr = KERN_PROTECTION_FAILURE;
			<span class="enscript-keyword">goto</span> <span class="enscript-reference">make_mem_done</span>;
		}

		<span class="enscript-keyword">if</span> (mach_memory_entry_allocate(&amp;user_entry, &amp;user_handle)
		    != KERN_SUCCESS) {
			kr = KERN_FAILURE;
			<span class="enscript-keyword">goto</span> <span class="enscript-reference">make_mem_done</span>;
		}

		user_entry-&gt;size = map_size;
		user_entry-&gt;offset = parent_entry-&gt;offset + map_start;
		user_entry-&gt;data_offset = offset_in_page; 
		user_entry-&gt;is_sub_map = parent_entry-&gt;is_sub_map;
		user_entry-&gt;is_pager = parent_entry-&gt;is_pager;
		user_entry-&gt;is_copy = parent_entry-&gt;is_copy;
		user_entry-&gt;internal = parent_entry-&gt;internal;
		user_entry-&gt;protection = protections;

		<span class="enscript-keyword">if</span>(access != MAP_MEM_NOOP) {
		   SET_MAP_MEM(access, user_entry-&gt;protection);
		}

		<span class="enscript-keyword">if</span>(parent_entry-&gt;is_sub_map) {
		   user_entry-&gt;backing.map = parent_entry-&gt;backing.map;
		   vm_map_lock(user_entry-&gt;backing.map);
		   user_entry-&gt;backing.map-&gt;ref_count++;
		   vm_map_unlock(user_entry-&gt;backing.map);
		}
		<span class="enscript-keyword">else</span> <span class="enscript-keyword">if</span> (parent_entry-&gt;is_pager) {
		   user_entry-&gt;backing.pager = parent_entry-&gt;backing.pager;
		   <span class="enscript-comment">/* JMM - don't we need a reference here? */</span>
		} <span class="enscript-keyword">else</span> {
		   object = parent_entry-&gt;backing.object;
		   assert(object != VM_OBJECT_NULL);
		   user_entry-&gt;backing.object = object;
		   <span class="enscript-comment">/* we now point to this object, hold on */</span>
		   vm_object_reference(object); 
		   vm_object_lock(object);
#<span class="enscript-reference">if</span> <span class="enscript-variable-name">VM_OBJECT_TRACKING_OP_TRUESHARE</span>
		<span class="enscript-keyword">if</span> (!object-&gt;true_share &amp;&amp;
		    vm_object_tracking_inited) {
			<span class="enscript-type">void</span> *bt[VM_OBJECT_TRACKING_BTDEPTH];
			<span class="enscript-type">int</span> num = 0;

			num = OSBacktrace(bt,
					  VM_OBJECT_TRACKING_BTDEPTH);
			btlog_add_entry(vm_object_tracking_btlog,
					object,
					VM_OBJECT_TRACKING_OP_TRUESHARE,
					bt,
					num);
		}
#<span class="enscript-reference">endif</span> <span class="enscript-comment">/* VM_OBJECT_TRACKING_OP_TRUESHARE */</span>

		   object-&gt;true_share = TRUE;
		   <span class="enscript-keyword">if</span> (object-&gt;copy_strategy == MEMORY_OBJECT_COPY_SYMMETRIC)
			object-&gt;copy_strategy = MEMORY_OBJECT_COPY_DELAY;
		   vm_object_unlock(object);
		}
		*size = CAST_DOWN(vm_size_t, (user_entry-&gt;size -
					      user_entry-&gt;data_offset));
		*object_handle = user_handle;
		<span class="enscript-keyword">return</span> KERN_SUCCESS;
	}

<span class="enscript-reference">make_mem_done</span>:
	<span class="enscript-keyword">if</span> (user_handle != IP_NULL) {
		<span class="enscript-comment">/*
		 * Releasing &quot;user_handle&quot; causes the kernel object
		 * associated with it (&quot;user_entry&quot; here) to also be
		 * released and freed.
		 */</span>
		mach_memory_entry_port_release(user_handle);
	}
	<span class="enscript-keyword">return</span> kr;
}

kern_return_t
<span class="enscript-function-name">_mach_make_memory_entry</span>(
	vm_map_t		target_map,
	memory_object_size_t	*size,
	memory_object_offset_t	offset,
	vm_prot_t		permission,
	ipc_port_t		*object_handle,
	ipc_port_t		parent_entry)
{
	memory_object_size_t 	mo_size;
	kern_return_t		kr;
	
	mo_size = (memory_object_size_t)*size;
	kr = mach_make_memory_entry_64(target_map, &amp;mo_size, 
			(memory_object_offset_t)offset, permission, object_handle,
			parent_entry);
	*size = mo_size;
	<span class="enscript-keyword">return</span> kr;
}

kern_return_t
<span class="enscript-function-name">mach_make_memory_entry</span>(
	vm_map_t		target_map,
	vm_size_t		*size,
	vm_offset_t		offset,
	vm_prot_t		permission,
	ipc_port_t		*object_handle,
	ipc_port_t		parent_entry)
{	
	memory_object_size_t 	mo_size;
	kern_return_t		kr;
	
	mo_size = (memory_object_size_t)*size;
	kr = mach_make_memory_entry_64(target_map, &amp;mo_size, 
			(memory_object_offset_t)offset, permission, object_handle,
			parent_entry);
	*size = CAST_DOWN(vm_size_t, mo_size);
	<span class="enscript-keyword">return</span> kr;
}

<span class="enscript-comment">/*
 *	task_wire
 *
 *	Set or clear the map's wiring_required flag.  This flag, if set,
 *	will cause all future virtual memory allocation to allocate
 *	user wired memory.  Unwiring pages wired down as a result of
 *	this routine is done with the vm_wire interface.
 */</span>
kern_return_t
<span class="enscript-function-name">task_wire</span>(
	vm_map_t	map,
	boolean_t	must_wire)
{
	<span class="enscript-keyword">if</span> (map == VM_MAP_NULL)
		<span class="enscript-keyword">return</span>(KERN_INVALID_ARGUMENT);

	<span class="enscript-keyword">if</span> (must_wire)
		map-&gt;wiring_required = TRUE;
	<span class="enscript-keyword">else</span>
		map-&gt;wiring_required = FALSE;

	<span class="enscript-keyword">return</span>(KERN_SUCCESS);
}

__private_extern__ kern_return_t
<span class="enscript-function-name">mach_memory_entry_allocate</span>(
	vm_named_entry_t	*user_entry_p,
	ipc_port_t		*user_handle_p)
{
	vm_named_entry_t	user_entry;
	ipc_port_t		user_handle;
	ipc_port_t		previous;

	user_entry = (vm_named_entry_t) kalloc(<span class="enscript-keyword">sizeof</span> *user_entry);
	<span class="enscript-keyword">if</span> (user_entry == NULL)
		<span class="enscript-keyword">return</span> KERN_FAILURE;

	named_entry_lock_init(user_entry);

	user_handle = ipc_port_alloc_kernel();
	<span class="enscript-keyword">if</span> (user_handle == IP_NULL) {
		kfree(user_entry, <span class="enscript-keyword">sizeof</span> *user_entry);
		<span class="enscript-keyword">return</span> KERN_FAILURE;
	}
	ip_lock(user_handle);

	<span class="enscript-comment">/* make a sonce right */</span>
	user_handle-&gt;ip_sorights++;
	ip_reference(user_handle);

	user_handle-&gt;ip_destination = IP_NULL;
	user_handle-&gt;ip_receiver_name = MACH_PORT_NULL;
	user_handle-&gt;ip_receiver = ipc_space_kernel;

	<span class="enscript-comment">/* make a send right */</span>
        user_handle-&gt;ip_mscount++;
        user_handle-&gt;ip_srights++;
        ip_reference(user_handle);

	ipc_port_nsrequest(user_handle, 1, user_handle, &amp;previous);
	<span class="enscript-comment">/* nsrequest unlocks user_handle */</span>

	user_entry-&gt;backing.pager = NULL;
	user_entry-&gt;is_sub_map = FALSE;
	user_entry-&gt;is_pager = FALSE;
	user_entry-&gt;is_copy = FALSE;
	user_entry-&gt;internal = FALSE;
	user_entry-&gt;size = 0;
	user_entry-&gt;offset = 0;
	user_entry-&gt;data_offset = 0;
	user_entry-&gt;protection = VM_PROT_NONE;
	user_entry-&gt;ref_count = 1;

	ipc_kobject_set(user_handle, (ipc_kobject_t) user_entry,
			IKOT_NAMED_ENTRY);

	*user_entry_p = user_entry;
	*user_handle_p = user_handle;

	<span class="enscript-keyword">return</span> KERN_SUCCESS;
}

<span class="enscript-comment">/*
 *	mach_memory_object_memory_entry_64
 *
 *	Create a named entry backed by the provided pager.
 *
 *	JMM - we need to hold a reference on the pager -
 *	and release it when the named entry is destroyed.
 */</span>
kern_return_t
<span class="enscript-function-name">mach_memory_object_memory_entry_64</span>(
	host_t			host,
	boolean_t		internal,
	vm_object_offset_t	size,
	vm_prot_t		permission,
 	memory_object_t		pager,
	ipc_port_t		*entry_handle)
{
	<span class="enscript-type">unsigned</span> <span class="enscript-type">int</span>		access;
	vm_named_entry_t	user_entry;
	ipc_port_t		user_handle;

        <span class="enscript-keyword">if</span> (host == HOST_NULL)
                <span class="enscript-keyword">return</span>(KERN_INVALID_HOST);

	<span class="enscript-keyword">if</span> (mach_memory_entry_allocate(&amp;user_entry, &amp;user_handle)
	    != KERN_SUCCESS) {
		<span class="enscript-keyword">return</span> KERN_FAILURE;
	}

	user_entry-&gt;backing.pager = pager;
	user_entry-&gt;size = size;
	user_entry-&gt;offset = 0;
	user_entry-&gt;protection = permission &amp; VM_PROT_ALL;
	access = GET_MAP_MEM(permission);
	SET_MAP_MEM(access, user_entry-&gt;protection);
	user_entry-&gt;internal = internal;
	user_entry-&gt;is_sub_map = FALSE;
	user_entry-&gt;is_pager = TRUE;
	assert(user_entry-&gt;ref_count == 1);

	*entry_handle = user_handle;
	<span class="enscript-keyword">return</span> KERN_SUCCESS;
}	

kern_return_t
<span class="enscript-function-name">mach_memory_object_memory_entry</span>(
	host_t		host,
	boolean_t	internal,
	vm_size_t	size,
	vm_prot_t	permission,
 	memory_object_t	pager,
	ipc_port_t	*entry_handle)
{
	<span class="enscript-keyword">return</span> mach_memory_object_memory_entry_64( host, internal, 
		(vm_object_offset_t)size, permission, pager, entry_handle);
}


kern_return_t
<span class="enscript-function-name">mach_memory_entry_purgable_control</span>(
	ipc_port_t	entry_port,
	vm_purgable_t	control,
	<span class="enscript-type">int</span>		*state)
{
	kern_return_t		kr;
	vm_named_entry_t	mem_entry;
	vm_object_t		object;

	<span class="enscript-keyword">if</span> (entry_port == IP_NULL ||
	    ip_kotype(entry_port) != IKOT_NAMED_ENTRY) {
		<span class="enscript-keyword">return</span> KERN_INVALID_ARGUMENT;
	}
	<span class="enscript-keyword">if</span> (control != VM_PURGABLE_SET_STATE &amp;&amp;
	    control != VM_PURGABLE_GET_STATE)
		<span class="enscript-keyword">return</span>(KERN_INVALID_ARGUMENT);

	<span class="enscript-keyword">if</span> (control == VM_PURGABLE_SET_STATE &amp;&amp;
	    (((*state &amp; ~(VM_PURGABLE_ALL_MASKS)) != 0) ||
	     ((*state &amp; VM_PURGABLE_STATE_MASK) &gt; VM_PURGABLE_STATE_MASK)))
		<span class="enscript-keyword">return</span>(KERN_INVALID_ARGUMENT);

	mem_entry = (vm_named_entry_t) entry_port-&gt;ip_kobject;

	named_entry_lock(mem_entry);

	<span class="enscript-keyword">if</span> (mem_entry-&gt;is_sub_map ||
	    mem_entry-&gt;is_pager ||
	    mem_entry-&gt;is_copy) {
		named_entry_unlock(mem_entry);
		<span class="enscript-keyword">return</span> KERN_INVALID_ARGUMENT;
	}

	object = mem_entry-&gt;backing.object;
	<span class="enscript-keyword">if</span> (object == VM_OBJECT_NULL) {
		named_entry_unlock(mem_entry);
		<span class="enscript-keyword">return</span> KERN_INVALID_ARGUMENT;
	}

	vm_object_lock(object);

	<span class="enscript-comment">/* check that named entry covers entire object ? */</span>
	<span class="enscript-keyword">if</span> (mem_entry-&gt;offset != 0 || object-&gt;vo_size != mem_entry-&gt;size) {
		vm_object_unlock(object);
		named_entry_unlock(mem_entry);
		<span class="enscript-keyword">return</span> KERN_INVALID_ARGUMENT;
	}

	named_entry_unlock(mem_entry);

	kr = vm_object_purgable_control(object, control, state);

	vm_object_unlock(object);

	<span class="enscript-keyword">return</span> kr;
}

kern_return_t
<span class="enscript-function-name">mach_memory_entry_get_page_counts</span>(
	ipc_port_t	entry_port,
	<span class="enscript-type">unsigned</span> <span class="enscript-type">int</span>	*resident_page_count,
	<span class="enscript-type">unsigned</span> <span class="enscript-type">int</span>	*dirty_page_count)
{
	kern_return_t		kr;
	vm_named_entry_t	mem_entry;
	vm_object_t		object;
	vm_object_offset_t	offset;
	vm_object_size_t	size;

	<span class="enscript-keyword">if</span> (entry_port == IP_NULL ||
	    ip_kotype(entry_port) != IKOT_NAMED_ENTRY) {
		<span class="enscript-keyword">return</span> KERN_INVALID_ARGUMENT;
	}

	mem_entry = (vm_named_entry_t) entry_port-&gt;ip_kobject;

	named_entry_lock(mem_entry);

	<span class="enscript-keyword">if</span> (mem_entry-&gt;is_sub_map ||
	    mem_entry-&gt;is_pager ||
	    mem_entry-&gt;is_copy) {
		named_entry_unlock(mem_entry);
		<span class="enscript-keyword">return</span> KERN_INVALID_ARGUMENT;
	}

	object = mem_entry-&gt;backing.object;
	<span class="enscript-keyword">if</span> (object == VM_OBJECT_NULL) {
		named_entry_unlock(mem_entry);
		<span class="enscript-keyword">return</span> KERN_INVALID_ARGUMENT;
	}

	vm_object_lock(object);

	offset = mem_entry-&gt;offset;
	size = mem_entry-&gt;size;

	named_entry_unlock(mem_entry);

	kr = vm_object_get_page_counts(object, offset, size, resident_page_count, dirty_page_count);

	vm_object_unlock(object);

	<span class="enscript-keyword">return</span> kr;
}

<span class="enscript-comment">/*
 * mach_memory_entry_port_release:
 *
 * Release a send right on a named entry port.  This is the correct
 * way to destroy a named entry.  When the last right on the port is
 * released, ipc_kobject_destroy() will call mach_destroy_memory_entry().
 */</span>
<span class="enscript-type">void</span>
<span class="enscript-function-name">mach_memory_entry_port_release</span>(
	ipc_port_t	port)
{
	assert(ip_kotype(port) == IKOT_NAMED_ENTRY);
	ipc_port_release_send(port);
}

<span class="enscript-comment">/*
 * mach_destroy_memory_entry:
 *
 * Drops a reference on a memory entry and destroys the memory entry if
 * there are no more references on it.
 * NOTE: This routine should not be called to destroy a memory entry from the
 * kernel, as it will not release the Mach port associated with the memory
 * entry.  The proper way to destroy a memory entry in the kernel is to
 * call mach_memort_entry_port_release() to release the kernel's send-right on
 * the memory entry's port.  When the last send right is released, the memory
 * entry will be destroyed via ipc_kobject_destroy().
 */</span>
<span class="enscript-type">void</span>
<span class="enscript-function-name">mach_destroy_memory_entry</span>(
	ipc_port_t	port)
{
	vm_named_entry_t	named_entry;
#<span class="enscript-reference">if</span> <span class="enscript-variable-name">MACH_ASSERT</span>
	assert(ip_kotype(port) == IKOT_NAMED_ENTRY);
#<span class="enscript-reference">endif</span> <span class="enscript-comment">/* MACH_ASSERT */</span>
	named_entry = (vm_named_entry_t)port-&gt;ip_kobject;

	named_entry_lock(named_entry);
	named_entry-&gt;ref_count -= 1;

	<span class="enscript-keyword">if</span>(named_entry-&gt;ref_count == 0) {
		<span class="enscript-keyword">if</span> (named_entry-&gt;is_sub_map) {
			vm_map_deallocate(named_entry-&gt;backing.map);
		} <span class="enscript-keyword">else</span> <span class="enscript-keyword">if</span> (named_entry-&gt;is_pager) {
			<span class="enscript-comment">/* JMM - need to drop reference on pager in that case */</span>
		} <span class="enscript-keyword">else</span> <span class="enscript-keyword">if</span> (named_entry-&gt;is_copy) {
			vm_map_copy_discard(named_entry-&gt;backing.copy);
		} <span class="enscript-keyword">else</span> {
			<span class="enscript-comment">/* release the VM object we've been pointing to */</span>
			vm_object_deallocate(named_entry-&gt;backing.object);
		}

		named_entry_unlock(named_entry);
		named_entry_lock_destroy(named_entry);

		kfree((<span class="enscript-type">void</span> *) port-&gt;ip_kobject,
		      <span class="enscript-keyword">sizeof</span> (<span class="enscript-type">struct</span> vm_named_entry));
	} <span class="enscript-keyword">else</span>
		named_entry_unlock(named_entry);
}

<span class="enscript-comment">/* Allow manipulation of individual page state.  This is actually part of */</span>
<span class="enscript-comment">/* the UPL regimen but takes place on the memory entry rather than on a UPL */</span>

kern_return_t
<span class="enscript-function-name">mach_memory_entry_page_op</span>(
	ipc_port_t		entry_port,
	vm_object_offset_t	offset,
	<span class="enscript-type">int</span>			ops,
	ppnum_t			*phys_entry,
	<span class="enscript-type">int</span>			*flags)
{
	vm_named_entry_t	mem_entry;
	vm_object_t		object;
	kern_return_t		kr;

	<span class="enscript-keyword">if</span> (entry_port == IP_NULL ||
	    ip_kotype(entry_port) != IKOT_NAMED_ENTRY) {
		<span class="enscript-keyword">return</span> KERN_INVALID_ARGUMENT;
	}

	mem_entry = (vm_named_entry_t) entry_port-&gt;ip_kobject;

	named_entry_lock(mem_entry);

	<span class="enscript-keyword">if</span> (mem_entry-&gt;is_sub_map ||
	    mem_entry-&gt;is_pager ||
	    mem_entry-&gt;is_copy) {
		named_entry_unlock(mem_entry);
		<span class="enscript-keyword">return</span> KERN_INVALID_ARGUMENT;
	}

	object = mem_entry-&gt;backing.object;
	<span class="enscript-keyword">if</span> (object == VM_OBJECT_NULL) {
		named_entry_unlock(mem_entry);
		<span class="enscript-keyword">return</span> KERN_INVALID_ARGUMENT;
	}

	vm_object_reference(object);
	named_entry_unlock(mem_entry);

	kr = vm_object_page_op(object, offset, ops, phys_entry, flags);

	vm_object_deallocate(object);	

	<span class="enscript-keyword">return</span> kr;
}

<span class="enscript-comment">/*
 * mach_memory_entry_range_op offers performance enhancement over 
 * mach_memory_entry_page_op for page_op functions which do not require page 
 * level state to be returned from the call.  Page_op was created to provide 
 * a low-cost alternative to page manipulation via UPLs when only a single 
 * page was involved.  The range_op call establishes the ability in the _op 
 * family of functions to work on multiple pages where the lack of page level
 * state handling allows the caller to avoid the overhead of the upl structures.
 */</span>

kern_return_t
<span class="enscript-function-name">mach_memory_entry_range_op</span>(
	ipc_port_t		entry_port,
	vm_object_offset_t	offset_beg,
	vm_object_offset_t	offset_end,
	<span class="enscript-type">int</span>                     ops,
	<span class="enscript-type">int</span>                     *range)
{
	vm_named_entry_t	mem_entry;
	vm_object_t		object;
	kern_return_t		kr;

	<span class="enscript-keyword">if</span> (entry_port == IP_NULL ||
	    ip_kotype(entry_port) != IKOT_NAMED_ENTRY) {
		<span class="enscript-keyword">return</span> KERN_INVALID_ARGUMENT;
	}

	mem_entry = (vm_named_entry_t) entry_port-&gt;ip_kobject;

	named_entry_lock(mem_entry);

	<span class="enscript-keyword">if</span> (mem_entry-&gt;is_sub_map ||
	    mem_entry-&gt;is_pager ||
	    mem_entry-&gt;is_copy) {
		named_entry_unlock(mem_entry);
		<span class="enscript-keyword">return</span> KERN_INVALID_ARGUMENT;
	}

	object = mem_entry-&gt;backing.object;
	<span class="enscript-keyword">if</span> (object == VM_OBJECT_NULL) {
		named_entry_unlock(mem_entry);
		<span class="enscript-keyword">return</span> KERN_INVALID_ARGUMENT;
	}

	vm_object_reference(object);
	named_entry_unlock(mem_entry);

	kr = vm_object_range_op(object,
				offset_beg,
				offset_end,
				ops,
				(uint32_t *) range);

	vm_object_deallocate(object);

	<span class="enscript-keyword">return</span> kr;
}


kern_return_t
<span class="enscript-function-name">set_dp_control_port</span>(
	host_priv_t	host_priv,
	ipc_port_t	control_port)	
{
        <span class="enscript-keyword">if</span> (host_priv == HOST_PRIV_NULL)
                <span class="enscript-keyword">return</span> (KERN_INVALID_HOST);

	<span class="enscript-keyword">if</span> (IP_VALID(dynamic_pager_control_port))
		ipc_port_release_send(dynamic_pager_control_port);

	dynamic_pager_control_port = control_port;
	<span class="enscript-keyword">return</span> KERN_SUCCESS;
}

kern_return_t
<span class="enscript-function-name">get_dp_control_port</span>(
	host_priv_t	host_priv,
	ipc_port_t	*control_port)	
{
        <span class="enscript-keyword">if</span> (host_priv == HOST_PRIV_NULL)
                <span class="enscript-keyword">return</span> (KERN_INVALID_HOST);

	*control_port = ipc_port_copy_send(dynamic_pager_control_port);
	<span class="enscript-keyword">return</span> KERN_SUCCESS;
	
}

<span class="enscript-comment">/* ******* Temporary Internal calls to UPL for BSD ***** */</span>

<span class="enscript-type">extern</span> <span class="enscript-type">int</span> <span class="enscript-function-name">kernel_upl_map</span>(
	vm_map_t        map,
	upl_t           upl,
	vm_offset_t     *dst_addr);

<span class="enscript-type">extern</span> <span class="enscript-type">int</span> <span class="enscript-function-name">kernel_upl_unmap</span>(
	vm_map_t        map,
	upl_t           upl);

<span class="enscript-type">extern</span> <span class="enscript-type">int</span> <span class="enscript-function-name">kernel_upl_commit</span>(
	upl_t                   upl,
	upl_page_info_t         *pl,
	mach_msg_type_number_t	 count);

<span class="enscript-type">extern</span> <span class="enscript-type">int</span> <span class="enscript-function-name">kernel_upl_commit_range</span>(
	upl_t                   upl,
	upl_offset_t             offset,
	upl_size_t		size,
	<span class="enscript-type">int</span>			flags,
	upl_page_info_array_t	pl,
	mach_msg_type_number_t	count);

<span class="enscript-type">extern</span> <span class="enscript-type">int</span> <span class="enscript-function-name">kernel_upl_abort</span>(
	upl_t                   upl,
	<span class="enscript-type">int</span>                     abort_type);

<span class="enscript-type">extern</span> <span class="enscript-type">int</span> <span class="enscript-function-name">kernel_upl_abort_range</span>(
	upl_t                   upl,
	upl_offset_t             offset,
	upl_size_t               size,
	<span class="enscript-type">int</span>                     abort_flags);


kern_return_t
<span class="enscript-function-name">kernel_upl_map</span>(
	vm_map_t	map,
	upl_t		upl,
	vm_offset_t	*dst_addr)
{
	<span class="enscript-keyword">return</span> vm_upl_map(map, upl, dst_addr);
}


kern_return_t
<span class="enscript-function-name">kernel_upl_unmap</span>(
	vm_map_t	map,
	upl_t		upl)
{
	<span class="enscript-keyword">return</span> vm_upl_unmap(map, upl);
}

kern_return_t
<span class="enscript-function-name">kernel_upl_commit</span>(
	upl_t                   upl,
	upl_page_info_t        *pl,
	mach_msg_type_number_t  count)
{
	kern_return_t 	kr;

	kr = upl_commit(upl, pl, count);
	upl_deallocate(upl);
	<span class="enscript-keyword">return</span> kr;
}


kern_return_t
<span class="enscript-function-name">kernel_upl_commit_range</span>(
	upl_t 			upl,
	upl_offset_t		offset,
	upl_size_t		size,
	<span class="enscript-type">int</span>			flags,
	upl_page_info_array_t   pl,
	mach_msg_type_number_t  count)
{
	boolean_t		finished = FALSE;
	kern_return_t 		kr;

	<span class="enscript-keyword">if</span> (flags &amp; UPL_COMMIT_FREE_ON_EMPTY)
		flags |= UPL_COMMIT_NOTIFY_EMPTY;

	<span class="enscript-keyword">if</span> (flags &amp; UPL_COMMIT_KERNEL_ONLY_FLAGS) {
		<span class="enscript-keyword">return</span> KERN_INVALID_ARGUMENT;
	}

	kr = upl_commit_range(upl, offset, size, flags, pl, count, &amp;finished);

	<span class="enscript-keyword">if</span> ((flags &amp; UPL_COMMIT_NOTIFY_EMPTY) &amp;&amp; finished)
		upl_deallocate(upl);

	<span class="enscript-keyword">return</span> kr;
}
	
kern_return_t
<span class="enscript-function-name">kernel_upl_abort_range</span>(
	upl_t			upl,
	upl_offset_t		offset,
	upl_size_t		size,
	<span class="enscript-type">int</span>			abort_flags)
{
	kern_return_t 		kr;
	boolean_t		finished = FALSE;

	<span class="enscript-keyword">if</span> (abort_flags &amp; UPL_COMMIT_FREE_ON_EMPTY)
		abort_flags |= UPL_COMMIT_NOTIFY_EMPTY;

	kr = upl_abort_range(upl, offset, size, abort_flags, &amp;finished);

	<span class="enscript-keyword">if</span> ((abort_flags &amp; UPL_COMMIT_FREE_ON_EMPTY) &amp;&amp; finished)
		upl_deallocate(upl);

	<span class="enscript-keyword">return</span> kr;
}

kern_return_t
<span class="enscript-function-name">kernel_upl_abort</span>(
	upl_t			upl,
	<span class="enscript-type">int</span>			abort_type)
{
	kern_return_t	kr;

	kr = upl_abort(upl, abort_type);
	upl_deallocate(upl);
	<span class="enscript-keyword">return</span> kr;
}

<span class="enscript-comment">/*
 * Now a kernel-private interface (for BootCache
 * use only).  Need a cleaner way to create an
 * empty vm_map() and return a handle to it.
 */</span>

kern_return_t
<span class="enscript-function-name">vm_region_object_create</span>(
	__unused vm_map_t	target_map,
	vm_size_t		size,
	ipc_port_t		*object_handle)
{
	vm_named_entry_t	user_entry;
	ipc_port_t		user_handle;

	vm_map_t	new_map;
	
	<span class="enscript-keyword">if</span> (mach_memory_entry_allocate(&amp;user_entry, &amp;user_handle)
	    != KERN_SUCCESS) {
		<span class="enscript-keyword">return</span> KERN_FAILURE;
	}

	<span class="enscript-comment">/* Create a named object based on a submap of specified size */</span>

	new_map = vm_map_create(PMAP_NULL, VM_MAP_MIN_ADDRESS,
				vm_map_round_page(size,
						  VM_MAP_PAGE_MASK(target_map)),
				TRUE);
	vm_map_set_page_shift(new_map, VM_MAP_PAGE_SHIFT(target_map));

	user_entry-&gt;backing.map = new_map;
	user_entry-&gt;internal = TRUE;
	user_entry-&gt;is_sub_map = TRUE;
	user_entry-&gt;offset = 0;
	user_entry-&gt;protection = VM_PROT_ALL;
	user_entry-&gt;size = size;
	assert(user_entry-&gt;ref_count == 1);

	*object_handle = user_handle;
	<span class="enscript-keyword">return</span> KERN_SUCCESS;

}

ppnum_t <span class="enscript-function-name">vm_map_get_phys_page</span>(		<span class="enscript-comment">/* forward */</span>
	vm_map_t	map,
	vm_offset_t	offset);

ppnum_t
<span class="enscript-function-name">vm_map_get_phys_page</span>(
	vm_map_t		map,
	vm_offset_t		addr)
{
	vm_object_offset_t	offset;
	vm_object_t		object;
	vm_map_offset_t 	map_offset;
	vm_map_entry_t		entry;
	ppnum_t			phys_page = 0;

	map_offset = vm_map_trunc_page(addr, PAGE_MASK);

	vm_map_lock(map);
	<span class="enscript-keyword">while</span> (vm_map_lookup_entry(map, map_offset, &amp;entry)) {

		<span class="enscript-keyword">if</span> (VME_OBJECT(entry) == VM_OBJECT_NULL) {
			vm_map_unlock(map);
			<span class="enscript-keyword">return</span> (ppnum_t) 0;
		}
		<span class="enscript-keyword">if</span> (entry-&gt;is_sub_map) {
			vm_map_t	old_map;
			vm_map_lock(VME_SUBMAP(entry));
			old_map = map;
			map = VME_SUBMAP(entry);
			map_offset = (VME_OFFSET(entry) +
				      (map_offset - entry-&gt;vme_start));
			vm_map_unlock(old_map);
			<span class="enscript-keyword">continue</span>;
		}
		<span class="enscript-keyword">if</span> (VME_OBJECT(entry)-&gt;phys_contiguous) {
			<span class="enscript-comment">/* These are  not standard pageable memory mappings */</span>
			<span class="enscript-comment">/* If they are not present in the object they will  */</span>
			<span class="enscript-comment">/* have to be picked up from the pager through the  */</span>
			<span class="enscript-comment">/* fault mechanism.  */</span>
			<span class="enscript-keyword">if</span> (VME_OBJECT(entry)-&gt;vo_shadow_offset == 0) {
				<span class="enscript-comment">/* need to call vm_fault */</span>
				vm_map_unlock(map);
				vm_fault(map, map_offset, VM_PROT_NONE, 
					FALSE, THREAD_UNINT, NULL, 0);
				vm_map_lock(map);
				<span class="enscript-keyword">continue</span>;
			}
			offset = (VME_OFFSET(entry) +
				  (map_offset - entry-&gt;vme_start));
			phys_page = (ppnum_t)
				((VME_OBJECT(entry)-&gt;vo_shadow_offset 
				  + offset) &gt;&gt; PAGE_SHIFT);
			<span class="enscript-keyword">break</span>;
			
		}
		offset = (VME_OFFSET(entry) + (map_offset - entry-&gt;vme_start));
		object = VME_OBJECT(entry);
		vm_object_lock(object);
		<span class="enscript-keyword">while</span> (TRUE) {
			vm_page_t dst_page = vm_page_lookup(object,offset);
	                <span class="enscript-keyword">if</span>(dst_page == VM_PAGE_NULL) {
				<span class="enscript-keyword">if</span>(object-&gt;shadow) {
					vm_object_t old_object;
					vm_object_lock(object-&gt;shadow);
					old_object = object;
					offset = offset + object-&gt;vo_shadow_offset;
					object = object-&gt;shadow;
					vm_object_unlock(old_object);
				} <span class="enscript-keyword">else</span> {
					vm_object_unlock(object);
					<span class="enscript-keyword">break</span>;
				}
			} <span class="enscript-keyword">else</span> {
				phys_page = (ppnum_t)(dst_page-&gt;phys_page);
				vm_object_unlock(object);
				<span class="enscript-keyword">break</span>;
			}
		}
		<span class="enscript-keyword">break</span>;

	} 

	vm_map_unlock(map);
	<span class="enscript-keyword">return</span> phys_page;
}


#<span class="enscript-reference">if</span> 0
kern_return_t <span class="enscript-function-name">kernel_object_iopl_request</span>(	<span class="enscript-comment">/* forward */</span>
	vm_named_entry_t	named_entry,
	memory_object_offset_t	offset,
	upl_size_t		*upl_size,
	upl_t			*upl_ptr,
	upl_page_info_array_t	user_page_list,
	<span class="enscript-type">unsigned</span> <span class="enscript-type">int</span>		*page_list_count,
	<span class="enscript-type">int</span>			*flags);

kern_return_t
<span class="enscript-function-name">kernel_object_iopl_request</span>(
	vm_named_entry_t	named_entry,
	memory_object_offset_t	offset,
	upl_size_t		*upl_size,
	upl_t			*upl_ptr,
	upl_page_info_array_t	user_page_list,
	<span class="enscript-type">unsigned</span> <span class="enscript-type">int</span>		*page_list_count,
	<span class="enscript-type">int</span>			*flags)
{
	vm_object_t		object;
	kern_return_t		ret;

	<span class="enscript-type">int</span>			caller_flags;

	caller_flags = *flags;

	<span class="enscript-keyword">if</span> (caller_flags &amp; ~UPL_VALID_FLAGS) {
		<span class="enscript-comment">/*
		 * For forward compatibility's sake,
		 * reject any unknown flag.
		 */</span>
		<span class="enscript-keyword">return</span> KERN_INVALID_VALUE;
	}

	<span class="enscript-comment">/* a few checks to make sure user is obeying rules */</span>
	<span class="enscript-keyword">if</span>(*upl_size == 0) {
		<span class="enscript-keyword">if</span>(offset &gt;= named_entry-&gt;size)
			<span class="enscript-keyword">return</span>(KERN_INVALID_RIGHT);
		*upl_size = (upl_size_t) (named_entry-&gt;size - offset);
		<span class="enscript-keyword">if</span> (*upl_size != named_entry-&gt;size - offset)
			<span class="enscript-keyword">return</span> KERN_INVALID_ARGUMENT;
	}
	<span class="enscript-keyword">if</span>(caller_flags &amp; UPL_COPYOUT_FROM) {
		<span class="enscript-keyword">if</span>((named_entry-&gt;protection &amp; VM_PROT_READ) 
					!= VM_PROT_READ) {
			<span class="enscript-keyword">return</span>(KERN_INVALID_RIGHT);
		}
	} <span class="enscript-keyword">else</span> {
		<span class="enscript-keyword">if</span>((named_entry-&gt;protection &amp; 
			(VM_PROT_READ | VM_PROT_WRITE)) 
			!= (VM_PROT_READ | VM_PROT_WRITE)) {
			<span class="enscript-keyword">return</span>(KERN_INVALID_RIGHT);
		}
	}
	<span class="enscript-keyword">if</span>(named_entry-&gt;size &lt; (offset + *upl_size))
		<span class="enscript-keyword">return</span>(KERN_INVALID_ARGUMENT);

	<span class="enscript-comment">/* the callers parameter offset is defined to be the */</span>
	<span class="enscript-comment">/* offset from beginning of named entry offset in object */</span>
	offset = offset + named_entry-&gt;offset;

	<span class="enscript-keyword">if</span> (named_entry-&gt;is_sub_map ||
	    named_entry-&gt;is_copy)
		<span class="enscript-keyword">return</span> KERN_INVALID_ARGUMENT;
		
	named_entry_lock(named_entry);

	<span class="enscript-keyword">if</span> (named_entry-&gt;is_pager) {
		object = vm_object_enter(named_entry-&gt;backing.pager, 
				named_entry-&gt;offset + named_entry-&gt;size, 
				named_entry-&gt;internal, 
				FALSE,
				FALSE);
		<span class="enscript-keyword">if</span> (object == VM_OBJECT_NULL) {
			named_entry_unlock(named_entry);
			<span class="enscript-keyword">return</span>(KERN_INVALID_OBJECT);
		}

		<span class="enscript-comment">/* JMM - drop reference on the pager here? */</span>

		<span class="enscript-comment">/* create an extra reference for the object */</span>
		vm_object_lock(object);
		vm_object_reference_locked(object);
		named_entry-&gt;backing.object = object;
		named_entry-&gt;is_pager = FALSE;
		named_entry_unlock(named_entry);

		<span class="enscript-comment">/* wait for object (if any) to be ready */</span>
		<span class="enscript-keyword">if</span> (!named_entry-&gt;internal) {
			<span class="enscript-keyword">while</span> (!object-&gt;pager_ready) {
				vm_object_wait(object,
					       VM_OBJECT_EVENT_PAGER_READY,
					       THREAD_UNINT);
				vm_object_lock(object);
			}
		}
		vm_object_unlock(object);

	} <span class="enscript-keyword">else</span> {
		<span class="enscript-comment">/* This is the case where we are going to operate */</span>
		<span class="enscript-comment">/* an an already known object.  If the object is */</span>
		<span class="enscript-comment">/* not ready it is internal.  An external     */</span>
		<span class="enscript-comment">/* object cannot be mapped until it is ready  */</span>
		<span class="enscript-comment">/* we can therefore avoid the ready check     */</span>
		<span class="enscript-comment">/* in this case.  */</span>
		object = named_entry-&gt;backing.object;
		vm_object_reference(object);
		named_entry_unlock(named_entry);
	}

	<span class="enscript-keyword">if</span> (!object-&gt;private) {
		<span class="enscript-keyword">if</span> (*upl_size &gt; MAX_UPL_TRANSFER_BYTES)
			*upl_size = MAX_UPL_TRANSFER_BYTES;
		<span class="enscript-keyword">if</span> (object-&gt;phys_contiguous) {
			*flags = UPL_PHYS_CONTIG;
		} <span class="enscript-keyword">else</span> {
			*flags = 0;
		}
	} <span class="enscript-keyword">else</span> {
		*flags = UPL_DEV_MEMORY | UPL_PHYS_CONTIG;
	}

	ret = vm_object_iopl_request(object,
				     offset,
				     *upl_size,
				     upl_ptr,
				     user_page_list,
				     page_list_count,
				     (upl_control_flags_t)(<span class="enscript-type">unsigned</span> <span class="enscript-type">int</span>)caller_flags);
	vm_object_deallocate(object);
	<span class="enscript-keyword">return</span> ret;
}
#<span class="enscript-reference">endif</span>
</pre>
<hr />
</body></html>